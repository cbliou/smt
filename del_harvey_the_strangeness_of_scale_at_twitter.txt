Talk	en	zh-tw
del_harvey_the_strangeness_of_scale_at_twitter	"My job at Twitter is to ensure user trust, protect user rights and keep users safe, both from each other and, at times, from themselves. Let's talk about what scale looks like at Twitter. Back in January 2009, we saw more than two million new tweets each day on the platform. January 2014, more than 500 million. We were seeing two million tweets in less than six minutes. That's a 24,900-percent increase. Now, the vast majority of activity on Twitter puts no one in harm's way. There's no risk involved. My job is to root out and prevent activity that might. Sounds straightforward, right? You might even think it'd be easy, given that I just said the vast majority of activity on Twitter puts no one in harm's way. Why spend so much time searching for potential calamities in innocuous activities? Given the scale that Twitter is at, a one-in-a-million chance happens 500 times a day. It's the same for other companies dealing at this sort of scale. For us, edge cases, those rare situations that are unlikely to occur, are more like norms. Say 99.999 percent of tweets pose no risk to anyone. There's no threat involved. Maybe people are documenting travel landmarks like Australia's Heart Reef, or tweeting about a concert they're attending, or sharing pictures of cute baby animals. After you take out that 99.999 percent, that tiny percentage of tweets remaining works out to roughly 150,000 per month. The sheer scale of what we're dealing with makes for a challenge. You know what else makes my role particularly challenging? People do weird things. (Laughter) And I have to figure out what they're doing, why, and whether or not there's risk involved, often without much in terms of context or background. I'm going to show you some examples that I've run into during my time at Twitter — these are all real examples — of situations that at first seemed cut and dried, but the truth of the matter was something altogether different. The details have been changed to protect the innocent and sometimes the guilty. We'll start off easy. [""Yo bitch""] If you saw a Tweet that only said this, you might think to yourself, ""That looks like abuse."" After all, why would you want to receive the message, ""Yo, bitch."" Now, I try to stay relatively hip to the latest trends and memes, so I knew that ""yo, bitch"" was also often a common greeting between friends, as well as being a popular ""Breaking Bad"" reference. I will admit that I did not expect to encounter a fourth use case. It turns out it is also used on Twitter when people are role-playing as dogs. (Laughter) And in fact, in that case, it's not only not abusive, it's technically just an accurate greeting. (Laughter) So okay, determining whether or not something is abusive without context, definitely hard. Let's look at spam. Here's an example of an account engaged in classic spammer behavior, sending the exact same message to thousands of people. While this is a mockup I put together using my account, we see accounts doing this all the time. Seems pretty straightforward. We should just automatically suspend accounts engaging in this kind of behavior. Turns out there's some exceptions to that rule. Turns out that that message could also be a notification you signed up for that the International Space Station is passing overhead because you wanted to go outside and see if you could see it. You're not going to get that chance if we mistakenly suspend the account thinking it's spam. Okay. Let's make the stakes higher. Back to my account, again exhibiting classic behavior. This time it's sending the same message and link. This is often indicative of  something called phishing, somebody trying to steal another person's account information by directing them to another website. That's pretty clearly not a good thing. We want to, and do, suspend accounts engaging in that kind of behavior. So why are the stakes higher for this? Well, this could also be a bystander at a rally who managed to record a video of a police officer beating a non-violent protester who's trying to let the world know what's happening. We don't want to gamble on potentially silencing that crucial speech by classifying it as spam and suspending it. That means we evaluate hundreds of parameters when looking at account behaviors, and even then, we can still get it wrong and have to reevaluate. Now, given the sorts of challenges I'm up against, it's crucial that I not only predict but also design protections for the unexpected. And that's not just an issue for me, or for Twitter, it's an issue for you. It's an issue for anybody who's building or creating something that you think is going to be amazing and will let people do awesome things. So what do I do? I pause and I think, how could all of this go horribly wrong? I visualize catastrophe. And that's hard. There's a sort of inherent cognitive dissonance in doing that, like when you're writing your wedding vows at the same time as your prenuptial agreement. (Laughter) But you still have to do it, particularly if you're marrying  500 million tweets per day. What do I mean by ""visualize catastrophe?"" I try to think of how something as benign and innocuous as a picture of a cat could lead to death, and what to do to prevent that. Which happens to be my next example. This is my cat, Eli. We wanted to give users the ability to add photos to their tweets. A picture is worth a thousand words. You only get 140 characters. You add a photo to your tweet, look at how much more content you've got now. There's all sorts of great things you can do by adding a photo to a tweet. My job isn't to think of those. It's to think of what could go wrong. How could this picture lead to my death? Well, here's one possibility. There's more in that picture than just a cat. There's geodata. When you take a picture with your smartphone or digital camera, there's a lot of additional information saved along in that image. In fact, this image also contains the equivalent of this, more specifically, this. Sure, it's not likely that someone's going to try to track me down and do me harm based upon image data associated with a picture I took of my cat, but I start by assuming the worst will happen. That's why, when we launched photos on Twitter, we made the decision to strip that geodata out. (Applause) If I start by assuming the worst and work backwards, I can make sure that the protections we build work for both expected and unexpected use cases. Given that I spend my days and nights imagining the worst that could happen, it wouldn't be surprising if  my worldview was gloomy. (Laughter) It's not. The vast majority of interactions I see — and I see a lot, believe me — are positive, people reaching out to help or to connect or share information with each other. It's just that for those of us dealing with scale, for those of us tasked with keeping people safe, we have to assume the worst will happen, because for us, a one-in-a-million chance is pretty good odds. Thank you. (Applause)"	我在推特的工作就是確保使用者對推特的信任，以及保護使用者的權益及安全，不只是使用者之間有時是有關使用者本身的權益及安全。讓我們談談推特訊息的規模。2009 年 1 月，每一天，我們在推特平台上看到超過 200 萬條新訊息。2014 年 1 月，則有超過 5 億條訊息。六分鐘內，就有 200 萬條推文。那是 24,900% 的成長。 今天，絶大部分在推特上的活動不會傷害任何人。沒有任何風險。我的工作則是根除任何可能傷害他人權益的活動。聽起來很簡單，對吧？你或許會認為這個工作很簡單，尤其當我說，推特上絕大部分的動作並不會對任何人造成傷害。那為什麼要花費這麼多時間在無害的網路活動中，尋找可能的危機？以推特的規模來看，百萬分之一的機率，相當於一天會有 500 條可能造成危害的訊息。這個訊息量，是其他公司所要處理的訊息量相同對我們而言，那些稀少罕見，不太可能發生的極端事件，有如家常便飯。假設百分之 99.999% 的推文都不會傷害任何人，不涉及任何風險。也許大家只是在記錄旅遊景點，像是澳洲的心形礁，或是傳些關於他們正在參加的演唱會，或者是分享一些可愛小動物的照片。當你除去那 99.999% 的機率，剩下極微小的百分比粗估下來每月大約有十五萬條訊息。管理這麼龐大的規模，是個挑戰。 你知道還有什麼讓我的工作更具挑戰性的嗎？人會做些奇怪的事。(笑聲)而我則必須搞清楚他們在做什麼，動機是什麼，還有是否有危險性，且通常是在沒有資料或背景的情況下就要去搞清楚。讓我舉幾個我在推特工作時遇到的例子，這些全都是真實的案例，一些原先看來簡單明瞭的情況，但事情的真相又是截然不同。有些細節已被更改，是為了保護無辜的人，有時也包括罪犯。我們從簡單的開始。 [嘿 賤女人] 當你在推特上看到這句話，你可能會認為：「那是一種辱罵」。畢竟，誰會希望收到這樣的訊息：「嘿，賤女人。」現在，我試著跟上趨勢及最新流行用語，所以我知道「嘿，賤女人」也常被用作朋友間的招呼用語是來自於《絕命毒師》的說法。我得承認我沒有想到這句話會有第四種用法。原來在推特上，扮成狗的人也會用這個詞。（笑聲）事實上，在這個情況下，不止沒有辱罵的意味，嚴格說來，這是一個準確的問候用語。（笑聲） 所以，一條沒有來龍去脈的訊息要去判定這個訊息是否有辱罵的意味，絕對是很困難的。 我們來看看垃圾訊息。這是使用者傳送垃圾訊息的典型例子，一直不斷地傳送相同的訊息給上千個人。這是我用自己帳號作出的模擬範例，我們總可以看到使用者傳送這樣的訊息。看起來相當簡單明瞭。我們應該自動封鎖涉及這種行為的帳號。結果總有些例外。這些訊息，也有可能是通知你登記參加國際太空站經過你上空的活動，你希望收到通知，即時走到戶外可以親自目睹。你絶不會因為誤認為這是垃圾訊息而停用這個帳號的情況發生。好。讓我們再把風險的層級提高。再來看我的帳號，在推特上展示特定的行為。這次是在持特上傳送相同的訊息和連結這通常是一種網路釣魚，有人試著去引導他人到另一個網站然後盜用他的帳號很明顯這不是一件好事。我們要，而且必須去阻止可疑的帳號去做這樣的行為。但是，為何這麼做風險更高？這像是遊行人潮當中的旁觀者拿著攝影機，對著警察動手打一個無暴力行為的抗議者攝影，好讓全世界的人知道此事。我們不想冒這個險把有可能很重要的訊息歸類為垃圾訊息，然後停用帳號。那意味著，當我們在觀察使用者行為時我們憑估成千上百個因素，即使是這麼做了，百密仍有一疏，必須再重新評估這些訊息。 現在，面臨各式各樣的挑戰，重要的是，不但要去預測可能發生的事，而且要對可能發生的事，設計一套因應的保護措施。這不僅事關我和推特，這也關係到你。關係到任何想創造美好事物，以及想要讓他人也一起做美好事物的推特使用者。所以我要怎麼做呢？我一再思考這問題這些事情到底怎麼會出錯？我想像發生災難的情形。這很困難，因為這麼做，有點像是內在認知不協調，就像是寫結婚誓言時，同時也寫婚前協議書。（笑聲）但還是必須要去做，特別是每天要處理 5 億條推文。我所說的「想像災難」是什麼意思呢？我試著去想像，像是一張無害的貓咪照片為何可能導致死亡，以及如何避免這種事情發生。正是接下來我要說的例子。這隻是我的貓，叫伊萊。我們盡可能讓推特的使用者在推特上傳送圖片，一張圖勝過千言萬語，而一次推文只能傳送 140 個字。你在推文加入圖片，你會發現推文的內容更加豐富。藉由推特加入圖片的功能，你可以做各種麼美妙的事。我的工作不是去想這些事情。而是去想事情可能會出什麼差錯。 這張圖片如何導致我死亡？有一個可能性。這張圖的資訊不只是一隻貓。還有地理資訊在裡頭。當你以智慧型手機或數位相機拍照，會有許多額外的資訊儲存在照片裡。事實上，這張照片還包含相當於這個的資訊，更具體地說是這個。當然，不太可能有人嘗試根據這張貓照片的相關資訊追蹤我以及傷害我。但我一開始就要假設最壞的情況一定會發生，這就是為什麼我們在開放上傳照片到推特時，就決定把照片裡的地理資訊全刪掉。（掌聲）如果一開始，我就假設可能發生最壞的情況，然後再往前倒推，我可以確定我們建立的保護制度，可以應付意料中以及意料外的事件。 我日夜地想像發生最壞情況的情形，如果因此造成我憂鬱的世界觀，也不會令人感到意外。（笶聲）其實並非如此。我看到的絶大部份互動，我看了很多，相信我，它們都是正面的。人們伸出援手互相幫忙，彼此互相連絡或分享資訊。只是我們要處理龐大的資訊量，承擔保護使用者安全的責任，所以必須假設將發生最壞的情況，對我們來說，百萬分之一的可能性是相當高的機率。 謝謝。 （掌聲）
