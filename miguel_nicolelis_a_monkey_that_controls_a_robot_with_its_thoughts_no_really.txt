Talk	en	zh-tw
miguel_nicolelis_a_monkey_that_controls_a_robot_with_its_thoughts_no_really	"The kind of neuroscience that I do and my colleagues do is almost like the weatherman. We are always chasing storms. We want to see and measure storms — brainstorms, that is. And we all talk about brainstorms in our daily lives, but we rarely see or listen to one. So I always like to start these talks by actually introducing you to one of them. Actually, the first time we recorded more than one neuron — a hundred brain cells simultaneously — we could measure the electrical sparks of a hundred cells in the same animal, this is the first image we got, the first 10 seconds of this recording. So we got a little snippet of a thought, and we could see it in front of us. I always tell the students that we could also call neuroscientists some sort of astronomer, because we are dealing with a system that is only comparable in terms of number of cells to the number of galaxies that we have in the universe. And here we are, out of billions of neurons, just recording, 10 years ago, a hundred. We are doing a thousand now. And we hope to understand something fundamental about our human nature. Because, if you don't know yet, everything that we use to define what human nature is comes from these storms, comes from these storms that roll over the hills and valleys of our brains and define our memories, our beliefs, our feelings, our plans for the future. Everything that we ever do, everything that every human has ever done, do or will do, requires the toil of populations of neurons producing these kinds of storms. And the sound of a brainstorm, if you've never heard one, is somewhat like this. You can put it louder if you can. My son calls this ""making popcorn while listening to a badly-tuned A.M. station."" This is a brain. This is what happens when you route these electrical storms to a loudspeaker and you listen to a hundred brain cells firing, your brain will sound like this — my brain, any brain. And what we want to do as neuroscientists in this time is to actually listen to these symphonies, these brain symphonies, and try to extract from them the messages they carry. In particular, about 12 years ago we created a preparation that we named brain-machine interfaces. And you have a scheme here that describes how it works. The idea is, let's have some sensors that listen to these storms, this electrical firing, and see if you can, in the same time that it takes for this storm to leave the brain and reach the legs or the arms of an animal — about half a second — let's see if we can read these signals, extract the motor messages that are embedded in it, translate it into digital commands and send it to an artificial device that will reproduce the voluntary motor wheel of that brain in real time. And see if we can measure how well we can translate that message when we compare to the way the body does that. And if we can actually provide feedback, sensory signals that go back from this robotic, mechanical, computational actuator that is now under the control of the brain, back to the brain, how the brain deals with that, of receiving messages from an artificial piece of machinery. And that's exactly what we did 10 years ago. We started with a superstar monkey called Aurora that became one of the superstars of this field. And Aurora liked to play video games. As you can see here, she likes to use a joystick, like any one of us, any of our kids, to play this game. And as a good primate, she even tries to cheat before she gets the right answer. So even before a target appears that she's supposed to cross with the cursor that she's controlling with this joystick, Aurora is trying to find the target, no matter where it is. And if she's doing that, because every time she crosses that target with the little cursor, she gets a drop of Brazilian orange juice. And I can tell you, any monkey will do anything for you if you get a little drop of Brazilian orange juice. Actually any primate will do that. Think about that. Well, while Aurora was playing this game, as you saw, and doing a thousand trials a day and getting 97 percent correct and 350 milliliters of orange juice, we are recording the brainstorms that are produced in her head and sending them to a robotic arm that was learning to reproduce the movements that Aurora was making. Because the idea was to actually turn on this brain-machine interface and have Aurora play the game just by thinking, without interference of her body. Her brainstorms would control an arm that would move the cursor and cross the target. And to our shock, that's exactly what Aurora did. She played the game without moving her body. So every trajectory that you see of the cursor now, this is the exact first moment she got that. That's the exact first moment a brain intention was liberated from the physical domains of a body of a primate and could act outside, in that outside world, just by controlling an artificial device. And Aurora kept playing the game, kept finding the little target and getting the orange juice that she wanted to get, that she craved for. Well, she did that because she, at that time, had acquired a new arm. The robotic arm that you see moving here 30 days later, after the first video that I showed to you, is under the control of Aurora's brain and is moving the cursor to get to the target. And Aurora now knows that she can play the game with this robotic arm, but she has not lost the ability to use her biological arms to do what she pleases. She can scratch her back, she can scratch one of us, she can play another game. By all purposes and means, Aurora's brain has incorporated that artificial device as an extension of her body. The model of the self that Aurora had in her mind has been expanded to get one more arm. Well, we did that 10 years ago. Just fast forward 10 years. Just last year we realized that you don't even need to have a robotic device. You can just build a computational body, an avatar, a monkey avatar. And you can actually use it for our monkeys to either interact with them, or you can train them to assume in a virtual world the first-person perspective of that avatar and use her brain activity to control the movements of the avatar's arms or legs. And what we did basically was to train the animals to learn how to control these avatars and explore objects that appear in the virtual world. And these objects are visually identical, but when the avatar crosses the surface of these objects, they send an electrical message that is proportional to the microtactile texture of the object that goes back directly to the monkey's brain, informing the brain what it is the avatar is touching. And in just four weeks, the brain learns to process this new sensation and acquires a new sensory pathway — like a new sense. And you truly liberate the brain now because you are allowing the brain to send motor commands to move this avatar. And the feedback that comes from the avatar is being processed directly by the brain without the interference of the skin. So what you see here is this is the design of the task. You're going to see an animal basically touching these three targets. And he has to select one because only one carries the reward, the orange juice that they want to get. And he has to select it by touch using a virtual arm, an arm that doesn't exist. And that's exactly what they do. This is a complete liberation of the brain from the physical constraints of the body and the motor in a perceptual task. The animal is controlling the avatar to touch the targets. And he's sensing the texture by receiving an electrical message directly in the brain. And the brain is deciding what is the texture associated with the reward. The legends that you see in the movie don't appear for the monkey. And by the way, they don't read English anyway, so they are here just for you to know that the correct target is shifting position. And yet, they can find them by tactile discrimination, and they can press it and select it. So when we look at the brains of these animals, on the top panel you see the alignment of 125 cells showing what happens with the brain activity, the electrical storms, of this sample of neurons in the brain when the animal is using a joystick. And that's a picture that every neurophysiologist knows. The basic alignment shows that these cells are coding for all possible directions. The bottom picture is what happens when the body stops moving and the animal starts controlling either a robotic device or a computational avatar. As fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body. The brain is assimilating that too, as fast as we can measure. So that suggests to us that our sense of self does not end at the last layer of the epithelium of our bodies, but it ends at the last layer of electrons of the tools that we're commanding with our brains. Our violins, our cars, our bicycles, our soccer balls, our clothing — they all become assimilated by this voracious, amazing, dynamic system called the brain. How far can we take it? Well, in an experiment that we ran a few years ago, we took this to the limit. We had an animal running on a treadmill at Duke University on the East Coast of the United States, producing the brainstorms necessary to move. And we had a robotic device, a humanoid robot, in Kyoto, Japan at ATR Laboratories that was dreaming its entire life to be controlled by a brain, a human brain, or a primate brain. What happens here is that the brain activity that generated the movements in the monkey was transmitted to Japan and made this robot walk while footage of this walking was sent back to Duke, so that the monkey could see the legs of this robot walking in front of her. So she could be rewarded, not by what her body was doing but for every correct step of the robot on the other side of the planet controlled by her brain activity. Funny thing, that round trip around the globe took 20 milliseconds less than it takes for that brainstorm to leave its head, the head of the monkey, and reach its own muscle. The monkey was moving a robot that was six times bigger, across the planet. This is one of the experiments in which that robot was able to walk autonomously. This is CB1 fulfilling its dream in Japan under the control of the brain activity of a primate. So where are we taking all this? What are we going to do with all this research, besides studying the properties of this dynamic universe that we have between our ears? Well the idea is to take all this knowledge and technology and try to restore one of the most severe neurological problems that we have in the world. Millions of people have lost the ability to translate these brainstorms into action, into movement. Although their brains continue to produce those storms and code for movements, they cannot cross a barrier that was created by a lesion on the spinal cord. So our idea is to create a bypass, is to use these brain-machine interfaces to read these signals, larger-scale brainstorms that contain the desire to move again, bypass the lesion using computational microengineering and send it to a new body, a whole body called an exoskeleton, a whole robotic suit that will become the new body of these patients. And you can see an image produced by this consortium. This is a nonprofit consortium called the Walk Again Project that is putting together scientists from Europe, from here in the United States, and in Brazil together to work to actually get this new body built — a body that we believe, through the same plastic mechanisms that allow Aurora and other monkeys to use these tools through a brain-machine interface and that allows us to incorporate the tools that we produce and use in our daily life. This same mechanism, we hope, will allow these patients, not only to imagine again the movements that they want to make and translate them into movements of this new body, but for this body to be assimilated as the new body that the brain controls. So I was told about 10 years ago that this would never happen, that this was close to impossible. And I can only tell you that as a scientist, I grew up in southern Brazil in the mid-'60s watching a few crazy guys telling [us] that they would go to the Moon. And I was five years old, and I never understood why NASA didn't hire Captain Kirk and Spock to do the job; after all, they were very proficient — but just seeing that as a kid made me believe, as my grandmother used to tell me, that ""impossible is just the possible that someone has not put in enough effort to make it come true."" So they told me that it's impossible to make someone walk. I think I'm going to follow my grandmother's advice. Thank you. (Applause)"	我和同事們所做的神經科學研究幾乎就像天氣預報員的工作我們總是追逐風暴我們希望目睹及測量風暴－我指的是腦風暴，所謂的腦力激盪我們平日總是談論腦風暴但幾乎不曾實際目睹或聽聞所以我總喜歡以其中一個實例作為演講的開場白 事實上，我們首次記錄超過一個神經元－同時記錄一百個腦細胞我們可以測量同一隻動物的一百個腦細胞電波這是我們首次紀錄的圖像前10秒的圖像紀錄因此我們有了一些想法我們可以將它呈現在眼前 我總是告訴學生我們也可將神經科學家視為某種天文學家因為我們處理的系統以細胞數量來說，是唯一能媲美宇宙中星系數量的系統其中存在超過十億個神經元10年前，我們僅記錄到其中100個現在我們可記錄到1000個我們希望瞭解關於人類特質的基本面因為，如果你還不知道我們定義的一切人類特質均來自於這些風暴來自這些在大腦中四處穿梭的風暴它定義了我們的記憶、我們的信念我們的感覺、我們未來的計劃我們曾經做過的一切每個人曾經做過、正在做或即將做的一切需要眾多神經元賣力地產生這種風暴 腦風暴的聲音，如果你不曾聽過類似這樣你可以將它放大我兒子稱之為「一邊做爆米花一邊聽頻道未調準的AM電台」這是大腦這是當你將電波風暴以擴音器放大時的情況你聽見的是一百個腦細胞發出的聲音你的大腦會發出這樣的聲音－我的大腦、任何人的大腦皆是身為神經科學家的我們目前想做的就是實際聆聽這些交響樂大腦演奏的交響樂試著擷取它們所攜帶的訊息 尤其是，大約12年前我們創造了一個名為腦機介面的裝置這是一張說明其運作方式的流程圖其中的想法是，我們使用一些感應器，聆聽這些風暴、這些電波觀察是否能夠在風暴離開腦部抵達某隻動物的腿或手臂同時大約需要半秒時間－觀察是否能讀取這些訊號擷取其中嵌入的動作訊息將它轉譯成數位指令發送到一個人工裝置中即時重現大腦自主運動的情況觀察是否能測量訊息轉譯程度當我們將它與身體實際運動情形比較時 如果我們確實得到回饋機制即此時在大腦控制下由機器人、機械或計算執行裝置傳回的感覺訊號傳回大腦觀察大腦如何處理來自人工機械裝置的訊息 這正是我們10年前進行的研究我們首先以一隻名為Aurora的明星猴進行實驗她已成為這個領域的超級巨星之一Aurora喜歡玩電子遊戲如你們在圖中所見她喜歡使用搖桿，就像任何人任何孩子一樣，玩這個遊戲身為聰慧的靈長類動物她甚至試著在得到正確答案前做假動作因此，甚至在目標出現之前她已試著用搖桿控制的游標劃過螢幕Aurora試著尋找目標，無論它在何處如果她這麼做因為每當她將小游標劃過目標就能得到一滴巴西橙汁我可以告訴大家，猴子會為你做任何事只要你給牠一小滴巴西橙汁事實上，任何靈長類動物皆是如此想想這一點 好，當Aurora玩這個遊戲時，如各位所見每天重複上千次獲得97 %正確率和350毫升橙汁我們記錄她大腦中產生的腦風暴將它傳送到機械臂中讓它學習重現Aurora所做的動作因為其中的想法是確實將這個腦機介面開啟讓Aurora僅藉由思考進行這個遊戲不需以她的身體為媒介她的腦風暴將控制機械臂使游標移動，劃過目標令我們震驚的是，這正是Aurora所做的她不需移動身體即可進行這個遊戲 因此，現在你所見的每一道游標移動軌跡這正是她首次成功的一刻這是史上第一次靈長類動物體內釋放的大腦意志能表現在外，顯露於體外的世界僅藉由控制某種人工裝置Aurora持續地玩這個遊戲持續地尋找這個小目標得到她想要且渴望的橙汁 好，她這麼做的原因是就在那時，她獲得一條新手臂你在影片中所見的移動機械臂拍攝於我展示的第一部影片後30天它在Aurora大腦控制下將游標移動到目標上Aurora現在知道她可以利用這條機械臂玩遊戲但她並未失去使用原有手臂、進行她想做的事的能力她可以抓背、可以抓我們當中任何一人、可以玩其他遊戲總之Aurora的大腦已和那個人工裝置融為一體將它視為身體的延伸物Aurora腦海裡的自我模型已獲得延伸，得到另一隻手臂 好，這是我們10年前的研究只是迅速回顧一下10年前的進展去年，我們發現你甚至不需使用機械裝置你可以建構一個數位身體一個化身，一個猴子化身事實上，你可以讓猴子與它互動或在虛擬世界當中訓練它以化身呈現第一人稱視角利用她大腦的活動控制化身的手臂或腿部動作 基本上，我們所做的是訓練動物學習如何控制這些化身探索出現在虛擬世界中的物體這些物體外觀相同但當化身劃這些物體的表面時它們將傳送與物體表面紋理相應的電波訊息直接傳回猴子的大腦通知大腦化身所接觸的是什麼在短短4週內，大腦學習處理這種新感覺獲得全新的感知途徑－就像一種新感官現在你真正解放了大腦因為你使大腦發送動作指令，移動這個化身大腦直接處理來自化身的回饋訊號不需以皮膚為媒介 你所見的圖片是這項任務的設計基本上你會看見動物觸摸這三個目標牠必須選擇其中之一因為只有一個帶有獎勵即牠們想得到的橙汁牠必須藉由虛擬手臂的觸摸進行選擇一隻不存在的手臂這正是牠們所做的 這是大腦完全從身體的生理限制解放進行知覺任務中的動作動物控制化身、觸摸目標藉由直接進入大腦的電波訊號感知紋理大腦決定何種紋理帶有獎勵你在電影中所見的傳說不會出現在猴子身上順帶一提，牠們根本看不懂英語因此這些文字只是為了讓你們知道正確目標的位置不斷移動但牠們可藉由觸覺差異找到正確目標牠們可藉由按壓進行選擇 因此，當我們觀察這些動物的大腦上方圖表是由125個細胞組成的陣列顯示在這個例子中，隨著大腦活動大腦中的神經元所產生電波風暴當動物使用搖桿時這是每位神經生理學家都熟知的圖表這個基本陣列顯示這些細胞對應的所有可能方向下方圖表是當身體停止移動動物開始控制機械裝置或數位化身的情形如同重啟電腦般迅速地大腦的活動開始轉移到這項新工具彷彿它也是這隻靈長類動物身體的一部分大腦也如同我們測量般迅速地與其融為一體 因此這讓我們瞭解，我們的自我意識並非終止於身體最外層的上皮細胞而是終止於我們大腦控制的工具之最外層電子我們的小提琴汽車、自行車、足球和服裝全都被這個貪婪、驚人名為大腦的動態系統同化 我們能將這項研究發展到什麼程度？好，在幾年前所做的一個實驗中我們將這項研究發展到極限我們讓一隻動物在跑步機上跑步在美國東岸的杜克大學產生足以傳送的腦風暴我們使用一個機械裝置，一個人形機器人在日本京都的ATR實驗室它畢生的夢想就是藉由大腦的控制行動人類的大腦，或靈長類動物的大腦 圖中所示的情形是由猴子大腦活動產生的動作傳送到日本，使機器人行走行走的畫面同時傳回杜克大學因此猴子可以看見機器人的腿在她面前行走她可以得到獎勵，不是因為她身體的動作而是因為在她大腦活動的控制下使地球另一端的機器人踏出的每一個正確步伐 有趣的是這趟來回繞行大半個地球的旅程所耗時間比腦風暴離開猴子大腦抵達牠本身肌肉所耗時間少了20毫秒猴子使遠在地球另一端體型比牠大6倍的機器人移動這是使機器人自主行走的實驗之一CB1（機器人名稱）在日本實現了夢想在靈長類動物的大腦活動控制下 那麼，我們將如何發展這一切？我們將如何應用這些研究？除了研究這個位於兩耳之間的動態宇宙性質？好，我們的想法是利用這所有的知識和技術試著修復世上最嚴重的神經問題之一數百萬人已失去轉譯這些腦風暴的能力轉譯成動作、行動雖然他們的大腦持續產生這些風暴和動作代碼但它們無法跨越某種脊髓病變產生的障礙 因此我們的想法是，創造另一條路徑利用腦機介面讀取訊號讀取大規模的腦風暴包括再次行動的渴望藉由微型電子裝置繞過病變處將訊號傳送到一個名為外骨骼的新身體一件將成為病患新身體的機械服 你可以看見這個組織提供的圖片這是一個名為「再次行走計畫」的非盈利組織集合了來自歐洲美國和巴西的科學家攜手合作，實際建造這個新身體我們相信，藉由如圖中的塑膠裝置可使Aurora和其他猴子藉由腦機介面使用這些工具也可使我們與日常生活工具融為一體我們希望同樣的裝置能使這些病患不僅是再次想像他們希望做到的動作將其轉譯為這個新身體的動作也能使這個身體成為大腦所控制新身體 因此，大約10年前，有人告訴我這個想法永遠不會成真這幾乎是不可能的任務我只能告訴你，身為科學家我於60年代中期在巴西南部長大目睹一些瘋狂的傢伙說，他們要前往月球當時5歲的我無法理解NASA為何不聘請寇克艦長和史巴克做這項工作畢竟他們非常專業但身為孩子的我，僅是目睹這一切就足以相信，如祖母經常告訴我的「所謂的不可能，很可能只是」「某人並未盡力實現夢想」 因此，當有人告訴我不可能使某人恢復行走能力時我想我會聽從祖母的忠告 謝謝 （掌聲）
