Talk	en	zh-tw
ajit_narayanan_a_word_game_to_communicate_in_any_language	"I work with children with autism. Specifically, I make technologies to help them communicate. Now, many of the problems that children with autism face, they have a common source, and that source is that they find it difficult to understand abstraction, symbolism. And because of this, they have  a lot of difficulty with language. Let me tell you a little bit about why this is. You see that this is a picture of a bowl of soup. All of us can see it. All of us understand this. These are two other pictures of soup, but you can see that these are more abstract These are not quite as concrete. And when you get to language, you see that it becomes a word whose look, the way it looks and the way it sounds, has absolutely nothing to do  with what it started with, or what it represents, which is the bowl of soup. So it's essentially a completely abstract, a completely arbitrary representation of something which is in the real world, and this is something that children with autism have an incredible amount of difficulty with. Now that's why most of the people  that work with children with autism — speech therapists, educators — what they do is, they try to help children with autism communicate not with words, but with pictures. So if a child with autism wanted to say, ""I want soup,"" that child would pick three different pictures, ""I,"" ""want,"" and ""soup,"" and they would put these together, and then the therapist or the parent would understand that this is what the kid wants to say. And this has been incredibly effective; for the last 30, 40 years people have been doing this. In fact, a few years back, I developed an app for the iPad which does exactly this. It's called Avaz, and the way it works is that kids select different pictures. These pictures are sequenced together to form sentences, and these sentences are spoken out. So Avaz is essentially converting pictures, it's a translator, it converts pictures into speech. Now, this was very effective. There are thousands of children using this, you know, all over the world, and I started thinking about what it does and what it doesn't do. And I realized something interesting: Avaz helps children with autism learn words. What it doesn't help them do is to learn word patterns. Let me explain this in a little more detail. Take this sentence: ""I want soup tonight."" Now it's not just the words here that convey the meaning. It's also the way in which these words are arranged, the way these words are modified and arranged. And that's why a sentence like ""I want soup tonight"" is different from a sentence like ""Soup want I tonight,"" which  is completely meaningless. So there is another hidden abstraction here which children with autism find a lot of difficulty coping with, and that's the fact that you can modify words and you can arrange them to have different meanings, to convey different ideas. Now, this is what we call grammar. And grammar is incredibly powerful, because grammar is this one component of language which takes this finite vocabulary that all of us have and allows us to convey an infinite amount of information, an infinite amount of ideas. It's the way in which you can put things together in order to convey anything you want to. And so after I developed Avaz, I worried for a very long time about how I could give grammar  to children with autism. The solution came to me from a very interesting perspective. I happened to chance upon a child with autism conversing with her mom, and this is what happened. Completely out of the blue, very spontaneously, the child got up and said, ""Eat."" Now what was interesting was the way in which the mom was trying to tease out the meaning of what the child wanted to say by talking to her in questions. So she asked, ""Eat what? Do  you want to eat ice cream? You want to eat? Somebody else wants to eat? You want to eat cream now? You want to eat ice cream in the evening?"" And then it struck me that what the mother had done was something incredible. She had been able to get that child to communicate an idea to her without grammar. And it struck me that maybe this is what I was looking for. Instead of arranging words in an order, in sequence, as a sentence, you arrange them in this map, where they're all linked together not by placing them one after the other but in questions, in question-answer pairs. And so if you do this, then what you're conveying is not a sentence in English, but what you're conveying is really a meaning, the meaning of a sentence in English. Now, meaning is really the underbelly, in some sense, of language. It's what comes after thought but before language. And the idea was that this particular representation might convey meaning in its raw form. So I was very excited by this, you know, hopping around all over the place, trying to figure out if I can convert all possible sentences that I hear into this. And I found that this is not enough. Why is this not enough? This is not enough because if you wanted to convey something like negation, you want to say, ""I don't want soup,"" then you can't do that by asking a question. You do that by changing the word ""want."" Again, if you wanted to say, ""I wanted soup yesterday,"" you do that by converting the word ""want"" into ""wanted."" It's a past tense. So this is a flourish which I added to make the system complete. This is a map of words joined together as questions and answers, and with these filters applied on top of them in order to modify them to represent certain nuances. Let me show you this with a different example. Let's take this sentence: ""I told the carpenter I could not pay him."" It's a fairly complicated sentence. The way that this particular system works, you can start with any part of this sentence. I'm going to start with the word ""tell."" So this is the word ""tell."" Now this happened in the past, so I'm going to make that ""told."" Now, what I'm going to do is, I'm going to ask questions. So, who told? I told. I told whom? I told the carpenter. Now we start with a different part of the sentence. We start with the word ""pay,"" and we add the ability filter to it to make it ""can pay."" Then we make it ""can't pay,"" and we can make it ""couldn't pay"" by making it the past tense. So who couldn't pay? I couldn't pay. Couldn't pay whom? I couldn't pay the carpenter. And then you join these two together by asking this question: What did I tell the carpenter? I told the carpenter I could not pay him. Now think about this. This is —(Applause)— this is a representation of this sentence without language. And there are two or three interesting things about this. First of all, I could have started anywhere. I didn't have to start with the word ""tell."" I could have started anywhere in the sentence, and I could have made this entire thing. The second thing is, if I wasn't an English speaker, if I was speaking in some other language, this map would actually hold true in any language. So long as the questions are standardized, the map is actually independent of language. So I call this FreeSpeech, and I was playing with this for many, many months. I was trying out so many different combinations of this. And then I noticed something very interesting about FreeSpeech. I was trying to convert language, convert sentences in English into sentences in FreeSpeech, and vice versa, and back and forth. And I realized that this particular configuration, this particular way of representing language, it allowed me to actually create very concise rules that go between FreeSpeech on one side and English on the other. So I could actually write this set of rules that translates from this particular representation into English. And so I developed this thing. I developed this thing called  the FreeSpeech Engine which takes any FreeSpeech sentence as the input and gives out perfectly grammatical English text. And by putting these two pieces together, the representation and the engine, I was able to create an app, a technology for children with autism, that not only gives them words but also gives them grammar. So I tried this out with kids with autism, and I found that there was an  incredible amount of identification. They were able to create sentences in FreeSpeech which were much more complicated but much more effective than equivalent sentences in English, and I started thinking about why that might be the case. And I had an idea, and I want to  talk to you about this idea next. In about 1997, about 15 years back, there were a group of scientists that were trying to understand how the brain processes language, and they found something very interesting. They found that when you learn a language as a child, as a two-year-old, you learn it with a certain part of your brain, and when you learn a language as an adult — for example, if I wanted to learn Japanese right now — a completely different part of my brain is used. Now I don't know why that's the case, but my guess is that that's because when you learn a language as an adult, you almost invariably learn it through your native language, or through your first language. So what's interesting about FreeSpeech is that when you create a sentence or when you create language, a child with autism creates language with FreeSpeech, they're not using this support language, they're not using this bridge language. They're directly constructing the sentence. And so this gave me this idea. Is it possible to use FreeSpeech not for children with autism but to teach language to people without disabilities? And so I tried a number of experiments. The first thing I did was I built a jigsaw puzzle in which these questions and answers are coded in the form of shapes, in the form of colors, and you have people putting these together and trying to understand how this works. And I built an app out of it, a game out of it, in which children can play with words and with a reinforcement, a sound reinforcement of visual structures, they're able to learn language. And this, this has a lot of potential, a lot of promise, and the government of India recently licensed this technology from us, and they're going to try it out with millions of different children trying to teach them English. And the dream, the hope, the vision, really, is that when they learn English this way, they learn it with the same proficiency as their mother tongue. All right, let's talk about something else. Let's talk about speech. This is speech. So speech is the primary mode of communication delivered between all of us. Now what's interesting about speech is that speech is one-dimensional. Why is it one-dimensional? It's one-dimensional because it's sound. It's also one-dimensional because our mouths are built that way. Our mouths are built to create one-dimensional sound. But if you think about the brain, the thoughts that we have in our heads are not one-dimensional. I mean, we have these rich, complicated, multi-dimensional ideas. Now, it seems to me that language is really the brain's invention to convert this rich, multi-dimensional thought on one hand into speech on the other hand. Now what's interesting is that we do a lot of work in information nowadays, and almost all of that is done in the language domain. Take Google, for example. Google trawls all these countless billions of websites, all of which are in English, and when you want to use Google, you go into Google search, and you type in English, and it matches the English with the English. What if we could do this in FreeSpeech instead? I have a suspicion that if we did this, we'd find that algorithms like searching, like retrieval, all of these things, are much simpler and also more effective, because they don't process the data structure of speech. Instead they're processing the data structure of thought. The data structure of thought. That's a provocative idea. But let's look at this in a little more detail. So this is the FreeSpeech ecosystem. We have the Free Speech representation on one side, and we have the FreeSpeech  Engine, which generates English. Now if you think about it, FreeSpeech, I told you, is completely  language-independent. It doesn't have any specific information in it which is about English. So everything that this system knows about English is actually encoded into the engine. That's a pretty interesting concept in itself. You've encoded an entire human language into a software program. But if you look at what's inside the engine, it's actually not very complicated. It's not very complicated code. And what's more interesting is the fact that the vast majority of the code in that engine is not really English-specific. And that gives this interesting idea. It might be very easy for us to actually create these engines in many, many different languages, in Hindi, in French, in German, in Swahili. And that gives another interesting idea. For example, supposing I was a writer, say, for a newspaper or for a magazine. I could create content in one language, FreeSpeech, and the person who's consuming that content, the person who's reading that particular information could choose any engine, and they could read it in their own mother tongue, in their native language. I mean, this is an incredibly attractive idea, especially for India. We have so many different languages. There's a song about India, and there's a description of the country as, it says, (in Sanskrit). That means ""ever-smiling speaker of beautiful languages."" Language is beautiful. I think it's the most beautiful of human creations. I think it's the loveliest thing that our brains have invented. It entertains, it educates, it enlightens, but what I like the most about language is that it empowers. I want to leave you with this. This is a photograph of my collaborators, my earliest collaborators when I started working on language and autism and various other things. The girl's name is Pavna, and that's her mother, Kalpana. And Pavna's an entrepreneur, but her story is much more remarkable than mine, because Pavna is about 23. She has quadriplegic cerebral palsy, so ever since she was born, she could neither move nor talk. And everything that she's accomplished so far, finishing school, going to college, starting a company, collaborating with me to develop Avaz, all of these things she's done with nothing more than moving her eyes. Daniel Webster said this: He said, ""If all of my possessions were taken from me with one exception, I would choose to keep the power of communication, for with it, I would regain all the rest."" And that's why, of all of these incredible  applications of FreeSpeech, the one that's closest to my heart still remains the ability for this to empower children with disabilities to be able to communicate, the power of communication, to get back all the rest. Thank you. (Applause) Thank you. (Applause) Thank you. Thank you. Thank you. (Applause) Thank you. Thank you. Thank you. (Applause)"	我服務有自閉症的孩子。更確切來說，我發明科技幫助他們溝通。 許多自閉症孩童面臨的問題出自於同樣的因素，那就是他們很難了解抽象概念與象徵性的符號。因此，他們在面對語言時會有很大的困難。 讓我告訴你一些原因。你可以看到這張圖片是一碗湯。我們每個人都看得見，也都了解這是什麼。這是另外兩張湯的圖片，但是你會發現它們比較抽象，不太具體。當你使用語言時，會發現那個字詞看起來、聽起來和它以什麼開頭或是和它代表的意義「那碗湯」完全無關。因此，基本上那是一個完全抽象、存在真實世界中某種事物的一種任意的表述，自閉症的孩子在這方面有很大的困難。那就是為什麼許多協助自閉症孩童的人們——語言治療師、教育人士——他們協助自閉症孩童不是用文字溝通，而是用圖片溝通。因此如果有個自閉症孩童想說：「我想喝湯。」這孩子會拿起三張不同的圖片「我」、「想喝」、「湯」，然後把圖排在一起，那麼治療師或家長就能理解這是孩子想說的話。三四十年來這方法一直都很有效，大家都這麼做。事實上，幾年前我開發了一個 iPad 的應用程式，名為「阿維思」(Avaz)，就是採用此法。操作方式是讓孩子選擇不同的圖片，將圖片排列成句子，然後這些句子會被唸出。因此基本上「阿維思」會轉換圖片，它是翻譯機，能將圖片轉換成言語。 這很有用。有成千上萬的孩子使用它，遍及全世界，於是我開始思考它做了什麼，又漏了什麼。我發現某件很有趣的事：「阿維思」協助有自閉症的孩子學習文字。但沒有教他們文字模式。讓我說明一些細節。以此句為例：「我今晚想喝湯。」這不只是文字傳達了意義，這些文字排列的方式、這些文字修飾與排列的方式也有意義。那就是為什麼像是「我今晚想喝湯」這句話會完全不同於「湯想喝我今晚」這樣無意義的句子。這裡有另一種隱藏的抽象概念，讓自閉症孩童難以處理，那就是你能透過修飾文字、排列文字，讓它有不同的意義，傳達不同的想法。我們稱之為文法。而文法的力量十分強大，因為文法是語言的其中一項要素，讓我們使用所擁有的有限字彙傳達無限種資訊、無限種想法。這種方式能讓你把東西組合在一起來傳達所有你想表達的事。 因此在我開發「阿維思」之後，有件事讓我擔心很久，那就是我要怎麼教自閉症孩童文法。解決方式來自一種非常有趣的觀點。我巧遇自閉症的孩童和她的母親對話，事情就這樣發生了。事發非常突然、不期而遇，那孩子站起來說：「吃。」有趣的是那位媽媽誘導小孩的方式，她讓小孩透過回答她的問題表達出想說的話。因此她問：「吃什麼？」「你想吃冰淇淋？」「你想吃？」「其他人想吃？」「你想現在吃冰淇淋？」「你想晚上吃冰淇淋？」我突然意識到那位母親做了一件非常棒的事。她已經能讓那個孩子不用文法就能傳達想法。我突然想到也許這就是我在找的方式。與其透過按照規則、順序將文字排列成句子，不如將文字排列在這張圖中，文字連結在一起的方式不是透過將它們一個接一個排列，而是透過問題，多組問答題。因此如果你這麼做，那你傳達的不是一個英文句子，你傳達的是一個意義，一個英文句子的意義。從某個層面來說，意義在語言中屬於較深層的部分。意義出現在想法之後，但是在語言之前。而此想法是這種特殊的表述可能是用它的根本樣貌來傳達意義。 這件事讓我很興奮，開心得手舞足蹈，試著確認我是否能將所有聽見的詞句轉換成這樣。我發現這還不夠。為什麼不夠呢？不夠是因為如果你想要傳達否定的句子，比如說：「我不想喝湯。」那麼你就不能用問句完成。你會改變「想」這個字。同樣地，如果你想說：「我昨天本來 想喝湯。」你把「想」轉換成「本來想」。那是過去式。因此我加了這個功能讓系統更完善。這是許多單字的連結圖，以問句和答案組合而成，有了這些篩選功能在上面，就能做修改，呈現出較細微的差異。讓我舉個不同的例子來說明。 以這個句子來說：「我告訴了木工我不能付錢。」這是個蠻複雜的句子。這個特殊系統運作的方式是你可以從句子的任何一處開始。我用「告訴」開頭來做說明。這個字是「告訴」，但這是以前發生的事，所以我要說「告訴了」。現在我想做的是，我開始問問題。是誰「告訴」？是我。我告訴了誰？我告訴了木工。現在我們從句子的另一處開始，以「付錢」開始，我們加上使役動詞，讓它變成「能付錢」，接著我們就能改成「不能付錢」，接著就能更改時態，將它改為過去式。那是誰不能付錢？我不能付錢。不能付錢給誰？我不能付錢給木工。接著你透過問這個問題把這兩個部分連在一起：我告訴了木工什麼？我告訴了木工我不能付錢。 想想看這個問題，（掌聲）這是這個句子要表達的內容，沒有語言。這裡有兩到三件有趣的事。首先，我能從任何一個單字開始，我不一定要從「告訴」開始。我能從句子的任何一部分開始，還是能完成整件事。第二點是，如果我不是說英語的人，如果我說的是別的語言，這個地圖真的在任何語言都管用。只要這個問題符合標準，這個地圖就能獨立於語言使用。因此我稱它為「輕鬆講」 (FreeSpeech)，我已經玩了好幾個月，並試著使用許多不同的組合。 後來，我注意到「輕鬆講」有個有趣的部分。我試著轉換語言，轉換英語句子和「輕鬆講」的句子，來回反覆不斷嘗試。我理解這種特殊的結構，這種表現語言的特殊方式讓我能夠真正地建立很簡要的規則，在「輕鬆講」以及英語之間的規則。我確實能寫下這組規則，讓這個特殊的表述轉換成英語。因此我發明了這項產品，稱為「輕鬆講引擎」，能把任何「輕鬆講」的句子輸入，然後產出有完美文法的英語。透過組合表述與引擎，我就能建立一個應用程式，一個供自閉症孩童用的科技，不只是提供他們文字，也提供他們文法。 我在自閉症孩童身上測試，發現了很驚人的成效。他們用「輕鬆講」建立的句子複雜程度和效用都遠高於用英語講同一句話，我開始思考為什麼會成功。因此，接下來我想與大家分享一個想法。大約在 1997 年時，大約 15 年前，有一群科學家嘗試理解大腦處理語言的方式，他們發現一件很有趣的事情。就是當你學習一種語言，身為一個兩歲小孩，你用大腦的特定部位在學習；而當你身為一名成人──舉例來說，如果我現在想學日語──就會運用完全不同部位的大腦。我不了解為什麼會這樣，但我猜是因為成年時學習語言幾乎無可避免會透過你的母語、習慣語言來學習。「輕鬆講」有趣的是當你建立一個句子，或是建立一種語言，自閉症孩童用「輕鬆講」建立語言，他們不是用它來支援語言，他們不是用它來連結語言，他們是直接建立句子。 這讓我有個想法。有可能讓「輕鬆講」教自閉症孩童語言之外，也教非身障的孩童嗎？因此我嘗試許多實驗。首先我設計了一個拼圖，這些問題和答案都編碼成各種形狀，各種顏色，操作人把這些放在一起，試著了解這是如何運作。我設計了一個應用程式，以此為基礎的遊戲，孩童可以玩文字遊戲，並且有強化的功能，以聽覺強化視覺，他們就能學習語言。這有很大的潛力和前景，而最近印度政府向我們取得這項科技的授權，他們打算讓上百萬名孩童嘗試，試著教他們英語。而這個夢想、希望、願景即是當他們以此學習英語，他們能夠表達流利，就像母語一樣。 接下來，我們來討論另一點。談談說話。這是說話。因此說話是溝通的基礎，在我們之間傳遞訊息。關於說話，有趣的是說話是單面的。為什麼是單面的？因為說話是聲音，所以它是單面的。也因為那是嘴巴的功能。嘴巴的功能即是創造單面的聲音。但是如果你想想大腦，在我們頭腦裡的思想並非一面向的。我的意思是，我們有這些豐富、複雜和多面向的想法。對我來說，語言就是大腦的發明，一方面轉換這豐富、多面向的思想，另一方面轉換成話語。有趣的是現在我們以資訊做許多事，幾乎所有的事情都是在語言的領域中完成。以 Google 為例，Google 網羅千百萬個網站，全都是英語網站，而當你想要用 Google，進入 Google 搜尋功能列，輸入英語，會出現符合你要的英語。有沒有可能我們改用「輕鬆講」這樣做呢？我推測如果我們這麼做，我們會發現一些規則系統，像是搜尋、像是擷取，所有的這些功能都更簡單也更有效，因為他們不是處理說話的資料結構。相反地，他們處理思想的資料結構。思想的資料結構。那是個令人興奮的概念。 讓我們多深入看一點細節。這是「輕鬆講」的生態系統。我們一邊有「輕鬆講」的畫面，另一邊也有「輕鬆講」的引擎產生英語。請想像「輕鬆講」是完全獨立的語言。裡面沒有任何關於英語的特定資訊。因此對這個系統來說，英語都已在引擎中編碼。這之中有個很有趣的概念。你已經將所有的人類語言編碼入一套軟體中。但是如果你看這個引擎的內部，會發現其實不複雜，不是很複雜的編碼。更有趣的是，在那個引擎中大多數的編碼其實都不是只針對英語。因此有了這個有趣的想法，我們也許可以因此輕易地建立很多很多不同語言的引擎，印度語、法語、德語、斯瓦希里語。（註：斯瓦希里語是非洲使用人數最多的語言之一）這引起了另一個有趣的想法。舉例來說，假設我是作家，在報社或雜誌社工作。我的文章可以用一種語言「輕鬆講」來寫，然後有個人買了那則報導，閱讀資訊的那個人可以選擇任何引擎，他們可以用自己的母語閱讀，用他們當地的語言閱讀。我的意思是，這是非常吸引人的想法，尤其是在印度。我們有好多種語言。有首關於印度的歌，其中有一段描述將國家比喻為（梵語）。意謂著「使用美好語言、永遠微笑的講者」。 語言是美好的。我認為語言是人類最美好的創造。我認為語言是人腦發明最可愛的東西。語言能娛樂、教育、啟發，但是我最愛的一點是語言能賦予力量。 我想分享一件事。這是我合作夥伴的照片，我最初的合作夥伴，當我開始研究語言、自閉症和各種不同的事。這位女孩名為帕芙娜，那是她的母親卡派納，帕芙娜是企業家，但是她的故事比我的更非凡，因為帕芙娜大概才 23 歲。她患有四肢型腦性麻庳，因此從她出生以來，她就不能動也不能說話。迄今她所完成的所有事情，完成學業、上大學、開公司，和我合作開發「阿維思」，她要做任何事情都只能移動她的雙眼。 丹尼爾．韋伯斯特說：（註：美國已故政治家）「如果要拿走我的一切，只能留下一種，我會選擇保留溝通的能力，以此，我就能取回全部。」那就是「輕鬆講」的所有美好功能中，最能貼近我心的一種還保留這項能力，賦予身障孩童擁能溝通的能力，擁有溝通的力量，就能取回一切。 謝謝。（掌聲）謝謝。（掌聲）謝謝。（掌聲）謝謝。（掌聲）
