Talk	en	zh-tw
alex_wissner_gross_a_new_equation_for_intelligence	"Intelligence — what is it? If we take a look back at the history of how intelligence has been viewed, one seminal example has been Edsger Dijkstra's famous quote that ""the question of whether a machine can think is about as interesting as the question of whether a submarine can swim."" Now, Edsger Dijkstra, when he wrote this, intended it as a criticism of the early pioneers of computer science, like Alan Turing. However, if you take a look back and think about what have been the most empowering innovations that enabled us to build artificial machines that swim and artificial machines that [fly], you find that it was only through understanding the underlying physical mechanisms of swimming and flight that we were able to build these machines. And so, several years ago, I undertook a program to try to understand the fundamental physical mechanisms underlying intelligence. Let's take a step back. Let's first begin with a thought experiment. Pretend that you're an alien race that doesn't know anything about Earth biology or Earth neuroscience or Earth intelligence, but you have amazing telescopes and you're able to watch the Earth, and you have amazingly long lives, so you're able to watch the Earth over millions, even billions of years. And you observe a really strange effect. You observe that, over the course of the millennia, Earth is continually bombarded with asteroids up until a point, and that at some point, corresponding roughly to our year, 2000 AD, asteroids that are on a collision course with the Earth that otherwise would have collided mysteriously get deflected or they detonate before they can hit the Earth. Now of course, as earthlings, we know the reason would be that we're trying to save ourselves. We're trying to prevent an impact. But if you're an alien race who doesn't know any of this, doesn't have any concept of Earth intelligence, you'd be forced to put together a physical theory that explains how, up until a certain point in time, asteroids that would demolish the surface of a planet mysteriously stop doing that. And so I claim that this is the same question as understanding the physical nature of intelligence. So in this program that I undertook several years ago, I looked at a variety of different threads across science, across a variety of disciplines, that were pointing, I think, towards a single, underlying mechanism for intelligence. In cosmology, for example, there have been a variety of different threads of evidence that our universe appears to be finely tuned for the development of intelligence, and, in particular, for the development of universal states that maximize the diversity of possible futures. In game play, for example, in Go — everyone remembers in 1997 when IBM's Deep Blue beat  Garry Kasparov at chess — fewer people are aware that in the past 10 years or so, the game of Go, arguably a much more challenging game because it has a much higher branching factor, has also started to succumb to computer game players for the same reason: the best techniques right now for computers playing Go are techniques that try to maximize future options during game play. Finally, in robotic motion planning, there have been a variety of recent techniques that have tried to take advantage of abilities of robots to maximize future freedom of action in order to accomplish complex tasks. And so, taking all of these different threads and putting them together, I asked, starting several years ago, is there an underlying mechanism for intelligence that we can factor out of all of these different threads? Is there a single equation for intelligence? And the answer, I believe, is yes. [""F = T ∇ Sτ""] What you're seeing is probably the closest equivalent to an E = mc² for intelligence that I've seen. So what you're seeing here is a statement of correspondence that intelligence is a force, F, that acts so as to maximize future freedom of action. It acts to maximize future freedom of action, or keep options open, with some strength T, with the diversity of possible accessible futures, S, up to some future time horizon, tau. In short, intelligence doesn't like to get trapped. Intelligence tries to maximize future freedom of action and keep options open. And so, given this one equation, it's natural to ask, so what can you do with this? How predictive is it? Does it predict human-level intelligence? Does it predict artificial intelligence? So I'm going to show you now a video that will, I think, demonstrate some of the amazing applications of just this single equation. (Video) Narrator: Recent research in cosmology has suggested that universes that produce more disorder, or ""entropy,"" over their lifetimes should tend to have more favorable conditions for the existence of intelligent beings such as ourselves. But what if that tentative cosmological connection between entropy and intelligence hints at a deeper relationship? What if intelligent behavior doesn't just correlate with the production of long-term entropy, but actually emerges directly from it? To find out, we developed a software engine called Entropica, designed to maximize the production of long-term entropy of any system that it finds itself in. Amazingly, Entropica was able to pass multiple animal intelligence tests, play human games, and even earn money trading stocks, all without being instructed to do so. Here are some examples of Entropica in action. Just like a human standing upright without falling over, here we see Entropica automatically balancing a pole using a cart. This behavior is remarkable in part because we never gave Entropica a goal. It simply decided on its own to balance the pole. This balancing ability will have appliactions for humanoid robotics and human assistive technologies. Just as some animals can use objects in their environments as tools to reach into narrow spaces, here we see that Entropica, again on its own initiative, was able to move a large disk representing an animal around so as to cause a small disk, representing a tool, to reach into a confined space holding a third disk and release the third disk from its initially fixed position. This tool use ability will have applications for smart manufacturing and agriculture. In addition, just as some other animals are able to cooperate by pulling opposite ends of a rope at the same time to release food, here we see that Entropica is able to accomplish a model version of that task. This cooperative ability has interesting implications for economic planning and a variety of other fields. Entropica is broadly applicable to a variety of domains. For example, here we see it successfully playing a game of pong against itself, illustrating its potential for gaming. Here we see Entropica orchestrating new connections on a social network where friends are constantly falling out of touch and successfully keeping the network well connected. This same network orchestration ability also has applications in health care, energy, and intelligence. Here we see Entropica directing the paths of a fleet of ships, successfully discovering and utilizing the Panama Canal to globally extend its reach from the Atlantic to the Pacific. By the same token, Entropica is broadly applicable to problems in autonomous defense, logistics and transportation. Finally, here we see Entropica spontaneously discovering and executing a buy-low, sell-high strategy on a simulated range traded stock, successfully growing assets under management exponentially. This risk management ability will have broad applications in finance and insurance. Alex Wissner-Gross: So what you've just seen is that a variety of signature human intelligent cognitive behaviors such as tool use and walking upright and social cooperation all follow from a single equation, which drives a system to maximize its future freedom of action. Now, there's a profound irony here. Going back to the beginning of the usage of the term robot, the play ""RUR,"" there was always a concept that if we developed machine intelligence, there would be a cybernetic revolt. The machines would rise up against us. One major consequence of this work is that maybe all of these decades, we've had the whole concept of cybernetic revolt in reverse. It's not that machines first become intelligent and then megalomaniacal and try to take over the world. It's quite the opposite, that the urge to take control of all possible futures is a more fundamental principle than that of intelligence, that general intelligence may in fact emerge directly from this sort of control-grabbing, rather than vice versa. Another important consequence is goal seeking. I'm often asked, how does the ability to seek goals follow from this sort of framework? And the answer is, the ability to seek goals will follow directly from this in the following sense: just like you would travel through a tunnel, a bottleneck in your future path space, in order to achieve many other diverse objectives later on, or just like you would invest in a financial security, reducing your short-term liquidity in order to increase your wealth over the long term, goal seeking emerges directly from a long-term drive to increase future freedom of action. Finally, Richard Feynman, famous physicist, once wrote that if human civilization were destroyed and you could pass only a single concept on to our descendants to help them rebuild civilization, that concept should be that all matter around us is made out of tiny elements that attract each other when they're far apart but repel each other when they're close together. My equivalent of that statement to pass on to descendants to help them build artificial intelligences or to help them understand human intelligence, is the following: Intelligence should be viewed as a physical process that tries to maximize future freedom of action and avoid constraints in its own future. Thank you very much. (Applause)"	"智慧，是什麽？如果我們回顧歷史對智慧的定義，有一個基本的例子是，艾茲赫爾·戴克斯特拉說過的一句話：(註：著名電腦科學家)“關於機械是否能思考的問題就有如在問潛水艇是否能游泳一樣有意思。”當艾茲赫爾·戴克斯特拉寫下這句話，是在質疑早期的電腦科學先驅，譬如艾倫·圖靈。然而，如果你回顧並思考，是什麼重大的創新使我們能夠製造出會游泳和會飛的人造機器，你就會發現，唯有透過了解游泳和飛翔的基本物理機制，我們才能製造出這些機器。因此，幾年前，我著手進行一個計劃，試圖去了解什麼是智慧的基本物理機制。 先讓我們退一步，先從一個發想實驗開始。假設你是一個外星人，對地球的生物完全不了解，也不了解地球的神經學和生物智慧，但你有很棒的望遠鏡，可以直接看到地球，而且你有很長很長的壽命，所以你有好幾百萬年甚至好幾十億年的時間來觀察地球。你發現一個很怪異的事情。你發現，在千禧年這個過程中，地球不斷地遭到小行星的撞擊，直到某一天，在某一個時刻，大約就是我們現在的西元兩千年左右，小行星原本運行在會撞擊到地球的軌道上，但是那個軌道神奇地偏移了，或者小行星在撞到地球前爆炸了。當然，身為地球人，我們知道那是因為我們試著拯救人類，試著避免撞擊發生。但如果你是外星人，不知道這些，對地球上的智慧沒有任何概念，那麼你只好勉強拼湊出一個物理理論來解釋，直到某一個時刻，應該毀滅地表一切的小行星神奇地不再發生。而我認為這跟要了解智慧的物理機制是一樣的問題。 因此，在這項我幾年前開始進行的計劃中，我研究各式各樣的想法，橫跨科學以及不同領域，我認為，這些都指向智慧的一個單一基本機制。以宇宙論為例，有各種不同的證據顯示我們所在的宇宙是被精心調整到適合發展出智慧的，尤其是發展出一個普遍性的狀態能使未來的可能性上做最大化。以圍棋為例，大家都記得1997年IBM 的深藍電腦打敗棋王卡斯帕羅夫，但只有少數人知道在過去的十年，圍棋，被視為是非常具挑戰性的遊戲，因為它有更多的分歧因素，同時也開始讓電腦玩家臣服，這些都是同樣的理由：現在讓電腦下棋最好的技巧就是將下棋過程可能發生的事件數最大化。最後，在機器人的行動規劃中，最近的各種技術都是試圖讓機器人在未來能自由行動的可能性做最大化，以完成某些複雜的任務。所以，用這些不同的想法，把它們拼湊在一起，在幾年前我開始問，有沒有一個關於智慧的基本機制是我們可以從這些不同的想法中分解出來的？有沒有一個屬於智慧的方程式？ 我相信答案是，有的。[""F = T ∇ Sτ""]你現在看到的或許是我看過最接近 E = mc²的屬於智慧的方程式。你所看到的是相對應的詮釋，智慧是一種力量，F它的作用是最大化行動的自由度。它的作用會最大化行動的自由度或是一直保有開放的選擇，配合某一強度 T，和可能發生的未來多樣性，S直到未來的某一個時間點，t。簡單地說，智慧不喜歡被約束住。智慧希望最大化未來行動的自由度，保持開放的選項。所以，有了這一個方程式，很自然地就會問，你能用它做甚麼？它的預測能力如何？它能否預測人類的智慧？它能否預測人工智慧？現在我要給各位看一段影片，我認為可以說明一些令人驚訝的應用，而且都只來自這一個方程式。 (影片) 旁白：宇宙學最近的研究推論宇宙會產生愈來愈多的失序，或是熵 (entropy)，應該更容易擁有有利的環境，讓智慧存在。但如果把這個宇宙學待驗證的亂度和智慧的關係再進一步加深會怎樣？如果智慧和長期亂度的增加不只是有正相關性，而且是從中發展出來的呢？為了解答這問題，我們開發了一個軟體叫做 ""Entropica""，可以把任何系統中熵的長期成長最大化。令人驚訝的是，Entropica 能夠通過多項動物智慧測試，玩人類的遊戲，甚至從股票交易中賺到錢，而且事前完全不用去教導它。這裡有幾個 Entropica 的實例。 像人可以直立站著不會跌倒，我們可以看到，Entropica使用一台車來自動平衡桿子。這個表現在某方面很了不起，因為我們從來沒有為Entropica設定一個目標。由它自己決定要去平衡這個桿子。這個平衡的能力可以應用在機器人上，以及人類行動輔助技術。就像有些動物會使用週遭的物品當作工具，以便能伸及到窄小的地方，我們可以再次看到 Entropica由它自己決定，可以移動代表動物的大圓圈，讓代表工具的小圓圈進入一個有第三個圓圈的狹小空間，然後把第三個圓圈從裡面擠出來。這個使用工具的能力可以應用在智慧製造和農業上。另外，就像其它動物會同時合力拉下繩索的兩端，讓食物掉出來，我們看到 Entropica 可以完成模組化後的同樣任務。這個合作的能力可以應用在經濟規劃和其它各樣的領域。 Entropica 可以廣泛的應用在各樣的領域。例如，我們可以看到它成功地和自己玩 ""乓"" (Pong)，代表它能玩遊戲的潛力。我們看到 Entropica 精心地建立起社群的新連結，當朋友們不時地失去聯繫，它會成功地維持這個網絡。這樣的網絡連結能力同樣可以應用在醫療照顧，能源和智慧發展上。這裡我們看到 Entropica為海洋中的船隊指引路徑，成功地發現並使用巴拿馬運河，使它的足跡遍及全球每個角落，從大西洋到太平洋。同樣的，Entropica可以廣泛地應用在自主防衛和物流運輸上。 最後，我們看到 Entropica自己發現並且執行""低買高賣""的策略，在一個區間交易的股票模擬市場中，成功地將管理資產規模指數性成長。這樣的風險管理能力可以應用在財務和保險上。 艾力克斯·威斯奈-格羅斯：以上你們所看到的是一個代表人類智慧的認知行為能力，像是工具的使用、直立行走、以及群體合作，全部都遵行一個方程式，這個方程式驅使一個系統可以最大化未來行動的自由。 然而，有一個很大的諷刺是，回顧最初使用”機器人”這個名詞時，在舞台劇《羅梭的萬能工人》(R.U.R,) 中，一直有一個概念：如果我們發展了人工智慧，機器人將會起義反抗，對抗我們人類。我們這個研究主要的結論之一是，或許在過去這幾十年來，我們在逆向思考""機器人反抗”這個概念。並不是機器先變聰明，然後自大，然後才企圖統治全世界，而是應該反過來看，想要控制所有未來可能性的慾望，比控制智慧是更加基本的原則，一般的智慧或許是直接從操控中產生的，並非反過來。 另一個重要的結論是尋找目標。我經常被問到，尋找目標的能力是如何從這個架構中產生的？答案是，尋找目標的能力會直接來自於以下這個想法：就像你行經一個隧道，一個在你未來道路上的瓶頸，是為了到達許多在未來的不同目的地，或者，就像你在證券上的投資，降低短期的流動性，是為了增加長期的財富，而尋找目標是來自於一個長期的趨動力用來增加未來的行動自由。 最後，知名的物理學家理察費曼曾說，如果人類文明要被毀滅了，而你只能留下一個概念給後世的子孫，以便協助他們重建文明，那麼這個概念應該是：所有我們週遭的物質是是由微小的元素組成，當它們相隔很遠時會互相吸引，但靠近時會互相排斥。而我同樣要留給後世的想法以便幫助他們發展人工智慧，或是幫助他們了解人類的智慧，我會說：智慧應該被視為一個物理程序，它將試著最大化未來的行動自由，避免將自己侷限住。 謝謝大家。 (掌聲)"
