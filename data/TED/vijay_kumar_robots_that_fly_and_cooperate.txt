Talk	en	zh-tw
vijay_kumar_robots_that_fly_and_cooperate	Good morning. I'm here today to talk about autonomous flying beach balls. (Laughter) No, agile aerial robots like this one. I'd like to tell you a little bit about the challenges in building these, and some of the terrific opportunities for applying this technology. So these robots are related to unmanned aerial vehicles. However, the vehicles you see here are big. They weigh thousands of pounds, are not by any means agile. They're not even autonomous. In fact, many of these vehicles are operated by flight crews that can include multiple pilots, operators of sensors, and mission coordinators. What we're interested in is developing robots like this — and here are two other pictures — of robots that you can buy off the shelf. So these are helicopters with four rotors, and they're roughly a meter or so in scale, and weigh several pounds. And so we retrofit these with sensors and processors, and these robots can fly indoors. Without GPS. The robot I'm holding in my hand is this one, and it's been created by two students, Alex and Daniel. So this weighs a little more than a tenth of a pound. It consumes about 15 watts of power. And as you can see, it's about eight inches in diameter. So let me give you just a very quick tutorial on how these robots work. So it has four rotors. If you spin these rotors at the same speed, the robot hovers. If you increase the speed of each of these rotors, then the robot flies up, it accelerates up. Of course, if the robot were tilted, inclined to the horizontal, then it would accelerate in this direction. So to get it to tilt, there's one of two ways of doing it. So in this picture, you see that rotor four is spinning faster and rotor two is spinning slower. And when that happens, there's a moment that causes this robot to roll. And the other way around, if you increase the speed of rotor three and decrease the speed of rotor one, then the robot pitches forward. And then finally, if you spin opposite pairs of rotors faster than the other pair, then the robot yaws about the vertical axis. So an on-board processor essentially looks at what motions need to be executed and combines these motions, and figures out what commands to send to the motors — 600 times a second. That's basically how this thing operates. So one of the advantages of this design is when you scale things down, the robot naturally becomes agile. So here, R is the characteristic length of the robot. It's actually half the diameter. And there are lots of physical parameters that change as you reduce R. The one that's most important is the inertia, or the resistance to motion. So it turns out the inertia, which governs angular motion, scales as a fifth power of R. So the smaller you make R, the more dramatically the inertia reduces. So as a result, the angular acceleration, denoted by the Greek letter alpha here, goes as 1 over R. It's inversely proportional to R. The smaller you make it, the more quickly you can turn. So this should be clear in these videos. On the bottom right, you see a robot performing a 360-degree flip in less than half a second. Multiple flips, a little more time. So here the processes on board are getting feedback from accelerometers and gyros on board, and calculating, like I said before, commands at 600 times a second, to stabilize this robot. So on the left, you see Daniel throwing this robot up into the air, and it shows you how robust the control is. No matter how you throw it, the robot recovers and comes back to him. So why build robots like this? Well, robots like this have many applications. You can send them inside buildings like this, as first responders to look for intruders, maybe look for biochemical leaks, gaseous leaks. You can also use them for applications like construction. So here are robots carrying beams, columns and assembling cube-like structures. I'll tell you a little bit more about this. The robots can be used for transporting cargo. So one of the problems with these small robots is their payload-carrying capacity. So you might want to have multiple robots carry payloads. This is a picture of a recent experiment we did — actually not so recent anymore — in Sendai, shortly after the earthquake. So robots like this could be sent into collapsed buildings, to assess the damage after natural disasters, or sent into reactor buildings, to map radiation levels. So one fundamental problem that the robots have to solve if they are to be autonomous, is essentially figuring out how to get from point A to point B. So this gets a little challenging, because the dynamics of this robot are quite complicated. In fact, they live in a 12-dimensional space. So we use a little trick. We take this curved 12-dimensional space, and transform it into a flat, four-dimensional space. And that four-dimensional space consists of X, Y, Z, and then the yaw angle. And so what the robot does, is it plans what we call a minimum-snap trajectory. So to remind you of physics: You have position, derivative, velocity; then acceleration; and then comes jerk, and then comes snap. So this robot minimizes snap. So what that effectively does, is produce a smooth and graceful motion. And it does that avoiding obstacles. So these minimum-snap trajectories in this flat space are then transformed back into this complicated 12-dimensional space, which the robot must do for control and then execution. So let me show you some examples of what these minimum-snap trajectories look like. And in the first video, you'll see the robot going from point A to point B, through an intermediate point. (Whirring noise) So the robot is obviously capable of executing any curve trajectory. So these are circular trajectories, where the robot pulls about two G's. Here you have overhead motion capture cameras on the top that tell the robot where it is 100 times a second. It also tells the robot where these obstacles are. And the obstacles can be moving. And here, you'll see Daniel throw this hoop into the air, while the robot is calculating the position of the hoop, and trying to figure out how to best go through the hoop. So as an academic, we're always trained to be able to jump through hoops to raise funding for our labs, and we get our robots to do that. (Applause) So another thing the robot can do is it remembers pieces of trajectory that it learns or is pre-programmed. So here, you see the robot combining a motion that builds up momentum, and then changes its orientation and then recovers. So it has to do this because this gap in the window is only slightly larger than the width of the robot. So just like a diver stands on a springboard and then jumps off it to gain momentum, and then does this pirouette, this two and a half somersault through and then gracefully recovers, this robot is basically doing that. So it knows how to combine little bits and pieces of trajectories to do these fairly difficult tasks. So I want change gears. So one of the disadvantages of these small robots is its size. And I told you earlier that we may want to employ lots and lots of robots to overcome the limitations of size. So one difficulty is: How do you coordinate lots of these robots? And so here, we looked to nature. So I want to show you a clip of Aphaenogaster desert ants, in Professor Stephen Pratt's lab, carrying an object. So this is actually a piece of fig. Actually you take any object coated with fig juice, and the ants will carry it back to the nest. So these ants don't have any central coordinator. They sense their neighbors. There's no explicit communication. But because they sense the neighbors and because they sense the object, they have implicit coordination across the group. So this is the kind of coordination we want our robots to have. So when we have a robot which is surrounded by neighbors — and let's look at robot I and robot J — what we want the robots to do, is to monitor the separation between them, as they fly in formation. And then you want to make sure that this separation is within acceptable levels. So again, the robots monitor this error and calculate the control commands 100 times a second, which then translates into motor commands, 600 times a second. So this also has to be done in a decentralized way. Again, if you have lots and lots of robots, it's impossible to coordinate all this information centrally fast enough in order for the robots to accomplish the task. Plus, the robots have to base their actions only on local information — what they sense from their neighbors. And then finally, we insist that the robots be agnostic to who their neighbors are. So this is what we call anonymity. So what I want to show you next is a video of 20 of these little robots, flying in formation. They're monitoring their neighbors' positions. They're maintaining formation. The formations can change. They can be planar formations, they can be three-dimensional formations. As you can see here, they collapse from a three-dimensional formation into planar formation. And to fly through obstacles, they can adapt the formations on the fly. So again, these robots come really close together. As you can see in this figure-eight flight, they come within inches of each other. And despite the aerodynamic interactions with these propeller blades, they're able to maintain stable flight. (Applause) So once you know how to fly in formation, you can actually pick up objects cooperatively. So this just shows that we can double, triple, quadruple the robots' strength, by just getting them to team with neighbors, as you can see here. One of the disadvantages of doing that is, as you scale things up — so if you have lots of robots carrying the same thing, you're essentially increasing the inertia, and therefore you pay a price; they're not as agile. But you do gain in terms of payload-carrying capacity. Another application I want to show you — again, this is in our lab. This is work done by Quentin Lindsey, who's a graduate student. So his algorithm essentially tells these robots how to autonomously build cubic structures from truss-like elements. So his algorithm tells the robot what part to pick up, when, and where to place it. So in this video you see — and it's sped up 10, 14 times — you see three different structures being built by these robots. And again, everything is autonomous, and all Quentin has to do is to give them a blueprint of the design that he wants to build. So all these experiments you've seen thus far, all these demonstrations, have been done with the help of motion-capture systems. So what happens when you leave your lab, and you go outside into the real world? And what if there's no GPS? So this robot is actually equipped with a camera, and a laser rangefinder, laser scanner. And it uses these sensors to build a map of the environment. What that map consists of are features — like doorways, windows, people, furniture — and it then figures out where its position is, with respect to the features. So there is no global coordinate system. The coordinate system is defined based on the robot, where it is and what it's looking at. And it navigates with respect to those features. So I want to show you a clip of algorithms developed by Frank Shen and Professor Nathan Michael, that shows this robot entering a building for the very first time, and creating this map on the fly. So the robot then figures out what the features are, it builds the map, it figures out where it is with respect to the features, and then estimates its position 100 times a second, allowing us to use the control algorithms that I described to you earlier. So this robot is actually being commanded remotely by Frank, but the robot can also figure out where to go on its own. So suppose I were to send this into a building, and I had no idea what this building looked like. I can ask this robot to go in, create a map, and then come back and tell me what the building looks like. So here, the robot is not only solving the problem of how to go from point A to point B in this map, but it's figuring out what the best point B is at every time. So essentially it knows where to go to look for places that have the least information, and that's how it populates this map. So I want to leave you with one last application. And there are many applications of this technology. I'm a professor, and we're passionate about education. Robots like this can really change the way we do K-12 education. But we're in Southern California, close to Los Angeles, so I have to conclude with something focused on entertainment. I want to conclude with a music video. I want to introduce the creators, Alex and Daniel, who created this video. (Applause) So before I play this video, I want to tell you that they created it in the last three days, after getting a call from Chris. And the robots that play in the video are completely autonomous. You will see nine robots play six different instruments. And of course, it's made exclusively for TED 2012. Let's watch. (Sound of air escaping from valve) (Music) (Whirring sound) (Music) (Applause) (Cheers)	早安。今天我想要來談一談會自動飛行的海灘球。不是啦，是靈巧的飛行機器人，就像這一個。我想告訴大家製作這種東西的挑戰性以及一些很棒的可能性來運用這種技術。這些機器人算是一種無人的飛行器。不過，如你所見，它們的尺寸都比較大。它們都有幾千磅重，一點都不靈巧。它們甚至並不是自動操作的。事實上，大部分這些飛行器是由飛行小組所操作，可能有好幾個駕駛員同時在操控著感應器以及任務協調器。 我們想要開發的機器人是像這個樣子 —左邊這裡另外兩張照片—這些你都可以買到現成的。這些是一種具有四個螺旋槳的直昇機，它們大約是一公尺大小，也有好幾磅重。於是我們將它們進行感應器與處理器的改良，讓這些機器人能夠在室內不靠GPS飛行。 我手中所拿的這個機器人就是這種飛行器，這是由兩位學生所製作的，Alex 以及 Daniel。它的重量大概是十分之一磅左右。它消耗的能量大概是15瓦。如你所見，它的直徑大概是8英吋大。讓我替大家簡單介紹一下這些機器人的原理。 這裡有四個螺旋槳。當這四個螺旋槳速度相同時，機器人就會懸浮在空中。如果這些螺旋槳速度增加，機器人就會飛起來，往上加速。當然，如果機器人傾斜了，相對於水平線來說，它就會往這個方向前進。想讓它傾斜的話，這裡有兩種方法可以辦到。在這圖片中，你可以看見4號螺旋槳轉速變快一點，而2號螺旋槳轉速變慢一點。當這種情況發生時，就會讓機器人進行翻轉。另一種狀況是，當3號螺旋槳的速度上升，1號螺旋槳的速度下降時，機器人就會往前傾斜。 而最後一種可能，當對角線的兩組螺旋槳轉得比另外一組快時，機器人就會在垂直方向偏移。有一個內置處理器一直在監控著該進行什麼動作，並且將這些動作進行組合，然後以每秒600次的速度決定出該對這些螺旋槳下達什麼指令。這就是它操作的基本概念。 這種設計的其中一項優點是，當你將它的尺寸縮小時，機器人自然就會變得很靈巧。這邊的 R代表著機器人特性的長度。事實上是直徑的一半。而當你將 R 縮減時，許多物理係數就會跟著變動。其中最重要的就是慣性或稱為阻止變動的抵抗力。結果，控制了角運動的慣性，大小約是 R 的 5 次方。所以當 R 變小時，慣性會急遽的下降。結果，角加速度，這裡用希臘字母的 α 表示，變成了 1 / R 。它和 R 成反比。當尺寸越小時，它就越容易旋轉。 用這個影片說明會清楚一點。在右下角，你可以看見一個機器人正在進行 360 度翻轉在不到 1/2 秒的時間內。多次的翻轉，只要稍微長一點點的時間。在這種狀況下，內置的處理器接收了加速器以及陀螺儀回傳的資訊，然後進行計算，如先前所說，用每秒600次的速度發出指令，讓機器人保持平衡。在左下角，Daniel 正將機器人拋向空中。這會讓你知道它的操控能力有多強大。不論你怎麼丟，機器人都能恢復平衡然後回到他的手中。 為什麼要將機器人設計成這樣呢？嗯，這種機器人有很多種運用方式。你可以將它派遣到這種建築物裡，擔任先遣部隊去找出侵入者，或是去找尋生化物質洩漏，或是瓦斯洩漏等。你也可以將它們運用在例如建築上面。這裡的機器人正運送著橫梁、柱子，並且組合成立方體形狀的建築物。我再告訴大家詳細一點。這些機器人可以用來運送貨櫃。但這些小機器人的困難在於它們對於重物的負載能力有限。所以如果你可能會希望能有多一點機器人一起來搬運這個重物。這是我們近期實驗的照片 —事實上已經不算是近期了 —在地震過後的仙台市(日本)。這種機器人可以被派遣進入傾倒的建築物裡面去評估天災造成的損害，或是派遣到反應爐裡去勘查輻射等級。 如果這些機器人想有自主能力的話，它們必須先解決這個問題，就是必須能夠判斷怎麼從 A 點到達 B 點。這有一點難度，因為這個機器人的動力學是相當複雜的。事實上，它們活在 12 維空間裡。所以我們運用了一些技巧。我們將這個 12 維空間的曲線轉換成為一個平面的四維空間。在這個四維空間之中，包含了 X, Y, Z 還有偏移的角度。 所以這個機器人所做的是，去找出我們所說的最小震盪軌跡。複習一下物理參數，我們有位置，接著衍生出速度，以及加速度，還有加加速度，然後是震盪。所以機器人將震盪進行最小化。這實際上的結果就是產生出柔順且優美的動作。它還可以用來避開障礙物。而這些最小震盪軌跡在這個平面空間中又會被轉換回這個複雜的 12 維空間，才能夠讓機器人去進行控制以及執行任務。 讓我給大家看一些例子說明這些最小震盪軌跡是什麼樣子。在第一段影片中，你可以看見機器人經過中繼點由 A 點到達 B 點。所以機器人確實可以去執行任何曲線軌跡。這些是環狀軌跡，機器人牽引著大約 2 G 的重力。在上面有個置頂動態影像攝影機，它會以每秒100次的速度告訴機器人自己在哪裡。它也會告訴機器人這些障礙物的位置。這些也可以是移動中的障礙物。你將會看見 Daniel 將這個鐵環丟向空中，機器人會計算鐵環的位置，然後試著去找出穿過鐵環的最佳方式。身為一個學術人員，我們總是被訓練得能夠赴湯蹈火才能籌措研究經費，所以我們也要我們的機器人做到。 (掌聲) 這機器人還能做另一件事，就是去記住軌跡的片段，不論是它自行發現的或是事先輸入的。所以你可以看見機器人會去組合一項動作讓它產生動量，接著改變自己的行進方向在回復過來。它必須這麼做，因為這個窗戶的缺口大小只比機器人的寬度稍微大一點。就像是跳水選手站在跳板上，接著會跳起來用以產生動量，然後快速旋轉，翻轉兩周半進行穿越，最後優雅的回復，這就是機器人所做的事。它懂得如何去結合這些零碎的軌跡以達成這些相當困難的任務。 我想換個話題。這些小機器人的缺點之一就是尺寸。如同先前所提，我們想使用大量的機器人來解決尺寸上的限制。但有個困難點是你要如何去協調這些機器人呢？這部份我們觀察了自然界。我想讓大家看一段影片，關於沙漠盤腹蟻在 Stephen Pratt 教授的實驗室裡搬運東西。事實上這是一小塊無花果。事實上你可以把任何東西沾附一層無花果汁螞蟻們就會將它搬回巢穴裡。這些螞蟻並沒有中樞協調者。它們能感覺到旁邊的鄰居們。不用進行明確的溝通。但因為它們能感覺到鄰居，因為它們能感覺到東西，它們在團體間有著隱性協調能力。 這種協調能力就是我們希望機器人能有的。當我們的一個機器人被周圍的機器人包圍時 —看看機器人 I 和機器人 J —我們希望機器人做的事情是當它們以特定隊形飛行時去偵測它們之間的距離。你期望能夠確保這個距離是在可接受的範圍內。於是機器人們偵測著這個誤差值然後以每秒100次的速度去估算控制指令，接著以每秒600次的速度對螺旋槳進行動作指令。這必須是在沒有中央控制的方式下進行。當你有許許多多機器人的時候，想要以中央協調訊息的方式快速的讓所有機器人完成任務是不可能的。再加上機器人們必須依靠它們自身去偵測到鄰近機器人以獲得訊息來進行動作。最後，我們堅持機器人必須無法預知鄰近機器人會是誰。也就是匿名的方式。 接下來我將要給大家看一段影片關於20個這些小機器人以特定隊形進行飛行。它們正在偵測鄰近機器人的位置。它們正在保持著這個隊形。這些隊形可以改變。可以是平面的隊形，也可以是三維空間的隊形。如你所見的，它們從三維空間的隊形變換成平面的隊形。在穿越障礙物時，它們可以在飛行中調整隊形。這些機器人移動時真的靠得很近。在這個 8 字飛行隊形中，它們的距離只有幾吋而已。儘管在這些螺旋槳葉片之間有著空氣動力的交互影響，它們仍然能維持穩定的飛行。 (掌聲) 一旦你知道要怎麼進行特定飛行隊形，你就能準確的協力拿起物體。而這是要告訴大家藉由將機器人組合成小組後，我們可以將機器人們的力量放大兩倍、三倍、四倍，就像是你將看到的這樣。但這樣做有一個缺點，當你將尺寸放大以後 —如果你有很多這些機器人載運同一個東西，你一定會有效地增加慣性，於是你將會付出代價，它們會失去靈巧性。但你可以相對獲得載運負重能力。 另一項我想給大家看的運用 —這也是在我們的實驗室裡進行的。這是由 Quentin Lindsey 完成的，他是一位研究生。他的演算法告訴這些機器人們如何能夠自主性的將綑狀的材料建造成立體建築。他的演算法告訴機器人該拿起哪一個部份，以及什麼時候該把它放在哪裡。你可以在這短片中看到 —這是以 10 倍、14 倍速播放 —你可以看見這些機器人們建造了三種不同建築。再次提醒，一切都是自主性進行的，而 Quentin 所做的是給這些機器人一張藍圖記載著他想要的建築設計。 你所看見的這些實驗，這些展示，都使用了動作擷取系統。如果離開了實驗室，走進真實世界會變成怎麼樣呢？如果沒有 GPS 會怎樣呢？這個機器人裝置了一具攝影機，一具雷射H搜尋器，雷射掃描器。它使用這些感應器來製作一張周圍的地圖。這地圖然有著一些環境特徵 —例如大門、窗戶、人、家具 —接著它會辨識出相對於這些環境特徵它所處的位置。這裡並沒有整體座標系統。座標系統是機器人自身定義出來的，藉由它所在的位置以及它所看到的東西。接著它對這些環境特徵進行探索。 我想給大家看一段影片，關於 Frank Shen 以及 Nathan Michael 教授所開發出來的演算法，這個機器人第一次進入一個建築物，然後在飛行中製作了這個地圖。於是機器人知道環境特徵是什麼東西。它製作出地圖。它知道自己相對於環境特徵的位置，然後每秒100次的速度估算出自己的位置，讓我們可以利用剛剛說過的控制演算法。事實上這個機器人正被Frank 以遠端遙控的方式下指令。但這個機器人也能自行判斷它應該往哪裡走。假設我把它送進一個建築物，而我完全不知道這個建築物的樣子，我可以命令機器人進入，製作出一張地圖，然後回來告訴我建築物的樣子。所以機器人並不只是解決如何從地圖上的A點到B點這個問題，它甚至知道每一次的最佳B點是哪個位置。於是它知道該往哪裡去以找出還沒有訊息的位置。這就是它如何把地圖裝滿的方法。 最後，我想再給大家看一樣應用。這個技術有許多運用方式。我是一個教授，我們對教育充滿熱情。這種機器人可以改變我們進行12年國教的方式。我們身在南加州，很靠近洛杉磯，所以我想用關於娛樂的例子來作為最後的結尾。我想用一段音樂影片來作為結尾。我要為大家介紹這個影片的作者，Alex 和 Daniel。 (掌聲) 在我播放影片之前，我想告訴大家他們在接到 Chris 電話後的三天內就將這段影片製作完了。影片中演奏的機器人都是完全自主性的進行。你可以看見 9 個機器人們演奏著 6 種不同的樂器。當然，這是為了 TED 2012 特別製作的。讓我們一起來欣賞。 (音樂聲) (掌聲)
