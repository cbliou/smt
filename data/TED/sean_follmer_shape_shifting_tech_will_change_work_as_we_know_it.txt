Talk	en	zh-tw
sean_follmer_shape_shifting_tech_will_change_work_as_we_know_it	"We've evolved with tools, and tools have evolved with us. Our ancestors created these hand axes 1.5 million years ago, shaping them to not only fit the task at hand but also their hand. However, over the years, tools have become more and more specialized. These sculpting tools have evolved through their use, and each one has a different form which matches its function. And they leverage the dexterity of our hands in order to manipulate things with much more precision. But as tools have become more and more complex, we need more complex controls to control them. And so designers have become very adept at creating interfaces that allow you to manipulate parameters while you're attending to other things, such as taking a photograph and changing the focus or the aperture. But the computer has fundamentally changed the way we think about tools because computation is dynamic. So it can do a million different things and run a million different applications. However, computers have the same static physical form for all of these different applications and the same static interface elements as well. And I believe that this is fundamentally a problem, because it doesn't really allow us to interact with our hands and capture the rich dexterity that we have in our bodies. And my belief is that, then, we must need new types of interfaces that can capture these rich abilities that we have and that can physically adapt to us and allow us to interact in new ways. And so that's what I've been doing at the MIT Media Lab and now at Stanford. So with my colleagues, Daniel Leithinger and Hiroshi Ishii, we created inFORM, where the interface can actually come off the screen and you can physically manipulate it. Or you can visualize 3D information physically and touch it and feel it to understand it in new ways. Or you can interact through gestures and direct deformations to sculpt digital clay. Or interface elements can arise out of the surface and change on demand. And the idea is that for each individual application, the physical form can be matched to the application. And I believe this represents a new way that we can interact with information, by making it physical. So the question is, how can we use this? Traditionally, urban planners and architects build physical models of cities and buildings to better understand them. So with Tony Tang at the Media Lab, we created an interface built on inFORM to allow urban planners to design and view entire cities. And now you can walk around it, but it's dynamic, it's physical, and you can also interact directly. Or you can look at different views, such as population or traffic information, but it's made physical. We also believe that these dynamic shape displays can really change the ways that we remotely collaborate with people. So when we're working together in person, I'm not only looking at your face but I'm also gesturing and manipulating objects, and that's really hard to do when you're using tools like Skype. And so using inFORM, you can reach out from the screen and manipulate things at a distance. So we used the pins of the display to represent people's hands, allowing them to actually touch and manipulate objects at a distance. And you can also manipulate and collaborate on 3D data sets as well, so you can gesture around them as well as manipulate them. And that allows people to collaborate on these new types of 3D information in a richer way than might be possible with traditional tools. And so you can also bring in existing objects, and those will be captured on one side and transmitted to the other. Or you can have an object that's linked between two places, so as I move a ball on one side, the ball moves on the other as well. And so we do this by capturing the remote user using a depth-sensing camera like a Microsoft Kinect. Now, you might be wondering how does this all work, and essentially, what it is, is 900 linear actuators that are connected to these mechanical linkages that allow motion down here to be propagated in these pins above. So it's not that complex compared to what's going on at CERN, but it did take a long time for us to build it. And so we started with a single motor, a single linear actuator, and then we had to design a custom circuit board to control them. And then we had to make a lot of them. And so the problem with having 900 of something is that you have to do every step 900 times. And so that meant that we had a lot of work to do. So we sort of set up a mini-sweatshop in the Media Lab and brought undergrads in and convinced them to do ""research"" — (Laughter) and had late nights watching movies, eating pizza and screwing in thousands of screws. You know — research. (Laughter) But anyway, I think that we were really excited by the things that inFORM allowed us to do. Increasingly, we're using mobile devices, and we interact on the go. But mobile devices, just like computers, are used for so many different applications. So you use them to talk on the phone, to surf the web, to play games, to take pictures or even a million different things. But again, they have the same static physical form for each of these applications. And so we wanted to know how can we take some of the same interactions that we developed for inFORM and bring them to mobile devices. So at Stanford, we created this haptic edge display, which is a mobile device with an array of linear actuators that can change shape, so you can feel in your hand where you are as you're reading a book. Or you can feel in your pocket new types of tactile sensations that are richer than the vibration. Or buttons can emerge from the side that allow you to interact where you want them to be. Or you can play games and have actual buttons. And so we were able to do this by embedding 40 small, tiny linear actuators inside the device, and that allow you not only to touch them but also back-drive them as well. But we've also looked at other ways to create more complex shape change. So we've used pneumatic actuation to create a morphing device where you can go from something that looks a lot like a phone ... to a wristband on the go. And so together with Ken Nakagaki at the Media Lab, we created this new high-resolution version that uses an array of servomotors to change from interactive wristband to a touch-input device to a phone. (Laughter) And we're also interested in looking at ways that users can actually deform the interfaces to shape them into the devices that they want to use. So you can make something like a game controller, and then the system will understand what shape it's in and change to that mode. So, where does this point? How do we move forward from here? I think, really, where we are today is in this new age of the Internet of Things, where we have computers everywhere — they're in our pockets, they're in our walls, they're in almost every device that you'll buy in the next five years. But what if we stopped thinking about devices and think instead about environments? And so how can we have smart furniture or smart rooms or smart environments or cities that can adapt to us physically, and allow us to do new ways of collaborating with people and doing new types of tasks? So for the Milan Design Week, we created TRANSFORM, which is an interactive table-scale version of these shape displays, which can move physical objects on the surface; for example, reminding you to take your keys. But it can also transform to fit different ways of interacting. So if you want to work, then it can change to sort of set up your work system. And so as you bring a device over, it creates all the affordances you need and brings other objects to help you accomplish those goals. So, in conclusion, I really think that we need to think about a new, fundamentally different way of interacting with computers. We need computers that can physically adapt to us and adapt to the ways that we want to use them and really harness the rich dexterity that we have of our hands, and our ability to think spatially about information by making it physical. But looking forward, I think we need to go beyond this, beyond devices, to really think about new ways that we can bring people together, and bring our information into the world, and think about smart environments that can adapt to us physically. So with that, I will leave you. Thank you very much. (Applause)"	我們因工具而進化，工具因我們而演進。我們的祖先在 150 萬年前創造了這些手斧，它們的塑形不僅適合工作本身，也適合使用它的「手」。然而，多年來，工具越來越專業。這些雕刻工具隨著它們的使用而發展，而且，針對不同的功能，每一個都有不同的形狀。充分的發揮我們手的靈巧性，使得操控任務時，能達到更高的精確度。但隨著工具變得越來越複雜，我們需要更複雜的操控機制來控制它們。因此，設計者更加擅長建立使用者介面當你參與不同場合時允許你調整參數。譬如拍照，改變焦距或光圈。然而，電腦從根本上改變了我們對工具的看法。因為計算學是強而有力的，所以，它可以做1百萬種不同的事，並執行1百萬個不同的應用程式。然而，對不同的應用程式來說，電腦都提供相同的實體形式和相同不變的介面元素。而且我相信，這會是根本性的一個問題是。因為這些介面元素不是真的可以和我們雙手互動，以展現出我們身體擁有豐富的充靈巧性。而我的信念是，那麼我們必須開發新類型的介面。可以充分展現我們所擁有的豐富能力。而且，是可以為我們動態調整的「實體」，讓我們以新的方式和它互動。所以這就是我在麻省理工學院媒體實驗室一直在做的事，現在則在史丹佛大學。因此，與我的同事，丹尼爾和石井浩，我們開發了inFORM介面，這介面，實際上可以從「屏幕」中跳脫出來，你可以採用「實體」的形態來操控它。或者，你可以看到電腦3D資訊以「實體」的型態來呈現。可以觸摸它、感覺它，以新的方式了解它。或者，你可以透過手勢的互動，指揮變形，當成「數位化粘土」來玩雕刻，或是展現「從表面浮出」的人機介面元素，都可隨指令而改變。這個想法是，對於每支應用程式，都有其「實體」形態可配合。我相信這是我們將電腦訊息「實體」化後與其互動的一個新方法所以，問題是，我們如何使用呢？傳統上，都市規劃者與建築師會建立城市和建物的「實體」模型，以便更加了解他們的設計與規劃。所以，我與東尼．唐，我們在媒體實驗室，建立了 inFORM 介面。讓都市規劃者用它來設計，並觀看整個城市面貌。現在，你可以四處走動，它是動態的、它是「實體」的，你也可以直接和它互動。或者，你可以看看不同瀏覽模式，譬如居民人數、或交通資訊，但它卻是以「實體」來呈現。我們也相信，這些動態外形的顯示真的可以改變我們以遠距離的方式與人合力執行任務的方式。當我們與人實際接觸一起工作時，我不是只盯著你的臉我還與你比手勢，同時操控物件，這種工作方式很難以 Skype 工具來取代。然而使用 inFORM 介面，你可以從屏幕伸出你的「手」去操控遠方的物件。因此，我們使用的顯示器上的「圖針」來代替我們的手，使他們能夠實際接觸物件，並且以遠距離的方式來操控物件。而且你還可以操控和與人合力處理三維空間的資料，所以你可以在周圍比手勢以及操控它們。這使人們能夠和人合力處理三維空間的資料，這比使用傳統工具的處理方式更為豐富。所以，你也可以把現有物件帶入，讓另一方捕捉，再傳送到對方。或者，你可以擁有一個「連結兩方」的物件：所以當我在一側移動一個球時，另一側的球也是會跟著動。我們利用深度感應攝影機捕獲遠程使用者的動作，就像微軟Kinect。(time calibration because of merge and sequence)現在，你可能想知道這一切是如何運作。基本上，它是900個「線性傳動器」連接到這些「機械聯動裝置」，讓底下產生的運動傳遞到上面的「圖針」。並非像CERN協會的核子研究那麼複雜，但是要打造它，確實相當費時。於是我們開始使用單一馬達、單一線性傳動器，然後我們必須訂製設計「線路框」來控制它們。我們必須製造很多套，要製造900 多套的問題是每一步驟必須執行900 多次。這意味著我們有大量的工作要做。所以，有點像是在媒體實驗室設立了迷你血汗工廠，招募大學在校生，說服他們做「研究」 。（笑聲）深夜有電影可看，有披薩可吃，但你得鎖上成千上萬的螺絲。你知道的 - 「研究」。（笑聲）但無論如何，我認為我們興奮的事是inFORM 介面技術可以做到很多事情。我們可應用在更多「隨身攜帶」的的行動裝置，與之互動。但是，行動裝置，像是電腦，可以用在許多不同的應用程式。所以，你用它們來講電話、上網、玩遊戲、拍照，近上百萬種不同的事情。但是，對於這些應用程式，它們仍然具有相同的實體形式。因此，我們想知道如何將我們開發的 inFORM 互動介面應用於行動裝置上。因此，在史丹佛大學，我們建立「觸感邊緣顯示器」，它是一個搭配「線性傳動器」的陣列行動裝置，可改變形狀，你可以在手中感覺到它的變化，因而知道書閱讀至何處。或者；你可以從口袋感受到新觸感，這些會比「振動」更豐富。或從側面出現按鈕，出現在你要的位置，讓你與之互動。或者，讓你在玩遊戲時有真實的按鈕可按。因此，我們能夠做到這一點：在裝置內部嵌入40個微小「線性驅動器」，讓你不僅僅可以觸摸他們，還可以把它們收攏。但我們也想看看其它建立更複雜的形狀變化。我們採用氣動式傳動器建立一個變形裝置，它一開始看起來可以像一支電話...變成隨身的腕帶。所以，我與肯中垣在媒體實驗室建立這個「高解析度」版本，使用一些伺服馬達，改變了不只是互動式腕帶，還有其他如觸摸式輸入裝置、電話...等。（笑聲）而且我們也有興趣地尋找使用者在實際應用上可以隨意變形的方法，可以塑造成他們要的使用裝置。所以，你可以把它變成遊戲操控器，然後系統偵到測目前是處於什麼形狀，就切換到該模式。那麼，我們該如何定位？又該如何由此更加進步？我覺得今天處在物聯網的新時代，一個電腦無所不在的時代。他們在我們的口袋裡、他們在我們的牆壁、他們幾乎存在於未來五年內你會購買的每一個裝置裡。但是，如果我們停止思考裝置，先回頭想想環境呢？那，我們如何才能擁有智能家具、智能房間 或 智能環境或者「實體」上可以隨時被我們調整的城市，找到與人合作的新方法執行新類型的任務？所以在米蘭設計週，我們建立了 《蛻變》 TRANSFORM，這是一個桌面互動的「模形顯示器」版本，可在表面上移動實體物件，例如：提醒你攜帶鑰匙。但它也可以變形以調整不同互動模式。所以，如果你要工作了，那麼，它可以改變成你想要的工作環境。只要把設備帶過來，它建立所有你需要的預設用途，並帶來其他物件幫你實現這些目的。總而言之我真的認為需要思考一下，一個嶄新的、從根本上改變的人和電腦互動的方法。我們需要電腦可以在「實體」上隨時配合我們調整，調整成我們想使用的方式，真正充分利用我們手的豐富靈巧性，並且我們有能力透過「實體」化的呈現，來思考空間資訊。但是，期待未來，我認為我們可以超越這個裝置技術，認真思考如何結合所有人的力量，並把我們的資訊帶入這個世界，想想智能環境，可以隨時配合我們調整。基於上述，後續發展我將留給各位非常感謝大家。（掌聲）
