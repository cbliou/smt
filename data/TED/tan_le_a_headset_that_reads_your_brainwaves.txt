Talk	en	zh-tw
tan_le_a_headset_that_reads_your_brainwaves	"Up until now, our communication with machines has always been limited to conscious and direct forms. Whether it's something simple like turning on the lights with a switch, or even as complex as programming robotics, we have always had to give a command to a machine, or even a series of commands, in order for it to do something for us. Communication between people, on the other hand, is far more complex and a lot more interesting because we take into account so much more than what is explicitly expressed. We observe facial expressions, body language, and we can intuit feelings and emotions from our dialogue with one another. This actually forms a large part of our decision-making process. Our vision is to introduce this whole new realm of human interaction into human-computer interaction so that computers can understand not only what you direct it to do, but it can also respond to your facial expressions and emotional experiences. And what better way to do this than by interpreting the signals naturally produced by our brain, our center for control and experience. Well, it sounds like a pretty good idea, but this task, as Bruno mentioned, isn't an easy one for two main reasons: First, the detection algorithms. Our brain is made up of billions of active neurons, around 170,000 km of combined axon length. When these neurons interact, the chemical reaction emits an electrical impulse, which can be measured. The majority of our functional brain is distributed over the outer surface layer of the brain, and to increase the area that's available for mental capacity, the brain surface is highly folded. Now this cortical folding presents a significant challenge for interpreting surface electrical impulses. Each individual's cortex is folded differently, very much like a fingerprint. So even though a signal may come from the same functional part of the brain, by the time the structure has been folded, its physical location is very different between individuals, even identical twins. There is no longer any consistency in the surface signals. Our breakthrough was to create an algorithm that unfolds the cortex, so that we can map the signals closer to its source, and therefore making it capable of working across a mass population. The second challenge is the actual device for observing brainwaves. EEG measurements typically involve a hairnet with an array of sensors, like the one that you can see here in the photo. A technician will put the electrodes onto the scalp using a conductive gel or paste and usually after a procedure of preparing the scalp by light abrasion. Now this is quite time consuming and isn't the most comfortable process. And on top of that, these systems actually cost in the tens of thousands of dollars. So with that, I'd like to invite onstage Evan Grant, who is one of last year's speakers, who's kindly agreed to help me to demonstrate what we've been able to develop. (Applause) So the device that you see is a 14-channel, high-fidelity EEG acquisition system. It doesn't require any scalp preparation, no conductive gel or paste. It only takes a few minutes to put on and for the signals to settle. It's also wireless, so it gives you the freedom to move around. And compared to the tens of thousands of dollars for a traditional EEG system, this headset only costs a few hundred dollars. Now on to the detection algorithms. So facial expressions — as I mentioned before in emotional experiences — are actually designed to work out of the box with some sensitivity adjustments available for personalization. But with the limited time we have available, I'd like to show you the cognitive suite, which is the ability for you to basically move virtual objects with your mind. Now, Evan is new to this system, so what we have to do first is create a new profile for him. He's obviously not Joanne — so we'll ""add user."" Evan. Okay. So the first thing we need to do with the cognitive suite is to start with training a neutral signal. With neutral, there's nothing in particular that Evan needs to do. He just hangs out. He's relaxed. And the idea is to establish a baseline or normal state for his brain, because every brain is different. It takes eight seconds to do this, and now that that's done, we can choose a movement-based action. So Evan, choose something that you can visualize clearly in your mind. Evan Grant: Let's do ""pull."" Tan Le: Okay, so let's choose ""pull."" So the idea here now is that Evan needs to imagine the object coming forward into the screen, and there's a progress bar that will scroll across the screen while he's doing that. The first time, nothing will happen, because the system has no idea how he thinks about ""pull."" But maintain that thought for the entire duration of the eight seconds. So: one, two, three, go. Okay. So once we accept this, the cube is live. So let's see if Evan can actually try and imagine pulling. Ah, good job! (Applause) That's really amazing. (Applause) So we have a little bit of time available, so I'm going to ask Evan to do a really difficult task. And this one is difficult because it's all about being able to visualize something that doesn't exist in our physical world. This is ""disappear."" So what you want to do — at least with movement-based actions, we do that all the time, so you can visualize it. But with ""disappear,"" there's really no analogies — so Evan, what you want to do here is to imagine the cube slowly fading out, okay. Same sort of drill. So: one, two, three, go. Okay. Let's try that. Oh, my goodness. He's just too good. Let's try that again. EG: Losing concentration. (Laughter) TL: But we can see that it actually works, even though you can only hold it for a little bit of time. As I said, it's a very difficult process to imagine this. And the great thing about it is that we've only given the software one instance of how he thinks about ""disappear."" As there is a machine learning algorithm in this — (Applause) Thank you. Good job. Good job. (Applause) Thank you, Evan, you're a wonderful, wonderful example of the technology. So, as you can see, before, there is a leveling system built into this software so that as Evan, or any user, becomes more familiar with the system, they can continue to add more and more detections, so that the system begins to differentiate between different distinct thoughts. And once you've trained up the detections, these thoughts can be assigned or mapped to any computing platform, application or device. So I'd like to show you a few examples, because there are many possible applications for this new interface. In games and virtual worlds, for example, your facial expressions can naturally and intuitively be used to control an avatar or virtual character. Obviously, you can experience the fantasy of magic and control the world with your mind. And also, colors, lighting, sound and effects can dynamically respond to your emotional state to heighten the experience that you're having, in real time. And moving on to some applications developed by developers and researchers around the world, with robots and simple machines, for example — in this case, flying a toy helicopter simply by thinking ""lift"" with your mind. The technology can also be applied to real world applications — in this example, a smart home. You know, from the user interface of the control system to opening curtains or closing curtains. And of course, also to the lighting — turning them on or off. And finally, to real life-changing applications, such as being able to control an electric wheelchair. In this example, facial expressions are mapped to the movement commands. Man: Now blink right to go right. Now blink left to turn back left. Now smile to go straight. TL: We really — Thank you. (Applause) We are really only scratching the surface of what is possible today, and with the community's input, and also with the involvement of developers and researchers from around the world, we hope that you can help us to shape where the technology goes from here. Thank you so much."	"直到現在，我們與機器的溝通仍局限於有意識和直接的模式不論是一些簡單的事情如用開關開燈或一些複雜的程式來控制機械人我們都要給機器輸入一個甚至一系列的指令才能命令它執行一些動作相反的，人與人的溝通就更加複雜和有趣得多因為我們會考慮到言語未表達的言外之意我們會觀察表情、肢體語言在對話中我們會用直覺來感受對方的感覺和情緒這些都是做決定時一些重要的因素我們的願景是引進全新的人與電腦的互動科技到人類互動的領域這麼一來電腦不只可以明白你指示它所做的事情而且也會對面部表情和情緒經歷作出反應還有什麼比從大腦的情感控制中樞直接解譯大腦產生的電波來得更好呢？ 這聽起來好像是不錯的主意但這個任務，正如Bruno所說並不容易，原因有兩個第一是大腦的偵查演算法我們的腦是由數十億個活躍的神經元所組成如果把神經細胞的軸索連在一起大概有十七萬公里這些神經元互動時產生的化學作用所發射出的電脈衝能夠被測量到大部分功能性腦是分佈在大腦的表層心智能力功能也位於此，為了增加表面積大腦皮質層有非常多的褶皺大腦皮質褶皺對分析電脈衝帶來一個很大的挑戰每個人大腦皮質層的褶皺都不同就像指紋一樣因此電脈衝訊息雖然來自功能腦同樣的區域但大腦皮質褶皺結構早已形成在不同的人的大腦裡即使是雙胞胎訊息發生位置也不同大腦皮質層電脈衝訊息沒有一致性 我們的突破是建立一個演算法攤開大腦皮質層去勘測這些訊息的原點繼而把它運用在大眾身上第二項挑戰是觀察腦電波的儀器腦波測量基本上包括一個有許多感應器的髮網就像現在圖中所看到的技術人員會把電極用導電的膠或漿糊固定在頭皮上這個準備程序需要在頭皮製造輕微的擦傷這個程序既費時又不舒服再加上，這些系統非常昂貴，得花上數萬美金 現在，我邀請Evan Grant去年的演講者上台他很樂意幫忙示範我們所設計的儀器 (鼓掌) 你們所看到的儀器是有十四個頻道，高傳真的腦電波訊號擷取系統不需要任何頭皮準備程序沒有導電的膠或漿糊戴上它，等訊號穩定只要幾分鐘而且是無線的它讓你活動自如比起那些幾萬美元的傳統腦電波系統這個頭戴式耳機只要幾百美金現在來談談大腦感應演算法好，面部表情—如同之前講到的情緒經驗—這套系統有令人意想不到的設計只要做一些敏感度調整就可以運用於個人化的使用但因時間的關係現在只示範認知的部份這套系統能夠讓您只用意念移動虛擬物件 Evan是第一次接觸這個系統因此我們要先建立一個新的檔案他當然不是Joanne， 所以要增加一個用戶Evan，好了!首先要做的是練習發出一個中立的訊號Evan不需要做什麼特別的事就這樣放輕鬆重點是建立一個基準線或是大腦的正常狀態因為每個人的腦都不相同這大概需要八秒的時間完成了我們可以選擇一個有動作的活動Evan，你可選擇一個在你腦海中可以清楚看到的事情 讓我們做一個""拉""的動作 好，點選""拉""我們現在需要Evan想像一件物品在螢幕上往前移動他這樣做的時候螢幕上會出現一個測量棒第一次沒有任何事情發生因為系統還不知道他怎麼想像""拉""的動作在這八秒中持續想著這個念頭一、二、三、開始好了當我們按了接受這個方塊就活了起來讓我們看看Evan能否真的嘗試想像""拉""的動作哇! 非常好!(鼓掌)真是令人驚訝！ (鼓掌) 我們還有一些時間我要請Evan做一些比較困難的動作這個有點難因為要想像在物質界裡不存在的事物就是 ""消失""就動作而言因為經常做這些動作，所以能""看見""它但""消失""沒有任何類似的動作Evan, 現在請你想像這個方塊慢慢消失一樣的練習。 一、二、三、開始可以了，我們試試吧我的天啊！他真的是非常厲害再試一次 （EG儀器:） 失去專注力 (笑聲) 這套系統真的辦到了雖然只維持一段很短的時間我認為想像""消失""真的是非常困難這個系統了不起的是這套軟體只有一次機會知道Evan是怎麼想像""消失""的而這部機器便學會了演算它 (鼓掌) 謝謝很棒！很棒！ (鼓掌) 謝謝，Evan你真的是這項科技最佳的展示人員 正如你們所見這個軟體有一個水準測量系統Evan或其他使用者對這個系統越熟悉就能不斷地增加更多，更多的檢測項目這個系統就能開始分辨不同的明顯想法當你訓練做這些檢測項目這些念頭、想法就能指定或聯繫到任何的電腦平台、應用程式或儀器上 讓我為你們展示幾個例子這個新界面有很多可運用的應用程式例如在遊戲或虛擬世界你可以用臉部表情自然、直覺地操控遊戲角色或虛擬人物無庸置疑，你將會親身體驗幻想的魔力和運用意念來控制世界顏色，燈光聲音和音效也可以不斷地變化來反映你的情緒狀態即時強化你的感受現在來看看應用程式全世界的研發人員發明了不同的機械人和簡單的機器，例如這個例子是操作玩具直昇機只要用意念就可以讓它飛起來 這項科技也可以應用在實際生活中看看智能家居的例子從使用者界面控制系統來打開或關上窗簾當然電燈也可以開或關最後是應用在改善真實生活例如能夠控制電動輪椅這個例子裡面部表情對應於移動方向的指令 男聲: 現在眨右眼右轉眨左眼左轉微笑往前 TL: 我們真的.... 多謝各位。 (鼓掌) 現今我們所做到的只是很小的一部分有研發團隊的投入及全世界的研發和研究人員的參與我們希望這一項科技能夠從這裡一路順利發展。謝謝各位。"
