Talk	en	zh-tw
rodney_brooks_on_robots	"What I want to tell you about today is how I see robots invading our lives at multiple levels, over multiple timescales. And when I look out in the future, I can't imagine a world, 500 years from now, where we don't have robots everywhere. Assuming — despite all the dire predictions from many people about our future — assuming we're still around, I can't imagine the world not being populated with robots. And then the question is, well, if they're going to be here in 500 years, are they going to be everywhere sooner than that? Are they going to be around in 50 years? Yeah, I think that's pretty likely — there's going to be lots of robots everywhere. And in fact I think that's going to be a lot sooner than that. I think we're sort of on the cusp of robots becoming common, and I think we're sort of around 1978 or 1980 in personal computer years, where the first few robots are starting to appear. Computers sort of came around through games and toys. And you know, the first computer most people had in the house may have been a computer to play Pong, a little microprocessor embedded, and then other games that came after that. And we're starting to see that same sort of thing with robots: LEGO Mindstorms, Furbies — who here — did anyone here have a Furby? Yeah, there's 38 million of them sold worldwide. They are pretty common. And they're a little tiny robot, a simple robot with some sensors, a little bit of processing actuation. On the right there is another robot doll, who you could get a couple of years ago. And just as in the early days, when there was a lot of sort of amateur interaction over computers, you can now get various hacking kits, how-to-hack books. And on the left there is a platform from Evolution Robotics, where you put a PC on, and you program this thing with a GUI to wander around your house and do various stuff. And then there's a higher price point sort of robot toys — the Sony Aibo. And on the right there, is one that the NEC developed, the PaPeRo, which I don't think they're going to release. But nevertheless, those sorts of things are out there. And we've seen, over the last two or three years, lawn-mowing robots, Husqvarna on the bottom, Friendly Robotics on top there, an Israeli company. And then in the last 12 months or so we've started to see a bunch of home-cleaning robots appear. The top left one is a very nice home-cleaning robot from a company called Dyson, in the U.K. Except it was so expensive — 3,500 dollars — they didn't release it. But at the bottom left, you see Electrolux, which is on sale. Another one from Karcher. At the bottom right is one that I built in my lab about 10 years ago, and we finally turned that into a product. And let me just show you that. We're going to give this away I think, Chris said, after the talk. This is a robot that you can go out and buy, and that will clean up your floor. And it starts off sort of just going around in ever-increasing circles. If it hits something — you people see that? Now it's doing wall-following, it's following around my feet to clean up around me. Let's see, let's — oh, who stole my Rice Krispies? They stole my Rice Krispies! (Laughter) Don't worry, relax, no, relax, it's a robot, it's smart! (Laughter) See, the three-year-old kids, they don't worry about it. It's grown-ups that get really upset. (Laughter) We'll just put some crap here. (Laughter) Okay. (Laughter) I don't know if you see — so, I put a bunch of Rice Krispies there, I put some pennies, let's just shoot it at that, see if it cleans up. Yeah, OK. So — we'll leave that for later. (Applause) Part of the trick was building a better cleaning mechanism, actually; the intelligence on board was fairly simple. And that's true with a lot of robots. We've all, I think, become, sort of computational chauvinists, and think that computation is everything, but the mechanics still matter. Here's another robot, the PackBot, that we've been building for a bunch of years. It's a military surveillance robot, to go in ahead of troops — looking at caves, for instance. But we had to make it fairly robust, much more robust than the robots we build in our labs. (Laughter) On board that robot is a PC running Linux. It can withstand a 400G shock. The robot has local intelligence: it can flip itself over, can get itself into communication range, can go upstairs by itself, et cetera. Okay, so it's doing local navigation there. A soldier gives it a command to go upstairs, and it does. That was not a controlled descent. (Laughter) Now it's going to head off. And the big breakthrough for these robots, really, was September 11th. We had the robots down at the World Trade Center late that evening. Couldn't do a lot in the main rubble pile, things were just too — there was nothing left to do. But we did go into all the surrounding buildings that had been evacuated, and searched for possible survivors in the buildings that were too dangerous to go into. Let's run this video. Reporter: ...battlefield companions are helping to reduce the combat risks. Nick Robertson has that story. Rodney Brooks: Can we have another one of these? Okay, good. So, this is a corporal who had seen a robot two weeks previously. He's sending robots into caves, looking at what's going on. The robot's being totally autonomous. The worst thing that's happened in the cave so far was one of the robots fell down ten meters. So one year ago, the US military didn't have these robots. Now they're on active duty in Afghanistan every day. And that's one of the reasons they say a robot invasion is happening. There's a sea change happening in how — where technology's going. Thanks. And over the next couple of months, we're going to be sending robots in production down producing oil wells to get that last few years of oil out of the ground. Very hostile environments, 150˚ C, 10,000 PSI. Autonomous robots going down, doing this sort of work. But robots like this, they're a little hard to program. How, in the future, are we going to program our robots and make them easier to use? And I want to actually use a robot here — a robot named Chris — stand up. Yeah. Okay. Come over here. Now notice, he thinks robots have to be a bit stiff. He sort of does that. But I'm going to — Chris Anderson: I'm just British. RB: Oh. (Laughter) (Applause) I'm going to show this robot a task. It's a very complex task. Now notice, he nodded there, he was giving me some indication he was understanding the flow of communication. And if I'd said something completely bizarre he would have looked askance at me, and regulated the conversation. So now I brought this up in front of him. I'd looked at his eyes, and I saw his eyes looked at this bottle top. And I'm doing this task here, and he's checking up. His eyes are going back and forth up to me, to see what I'm looking at — so we've got shared attention. And so I do this task, and he looks, and he looks to me to see what's happening next. And now I'll give him the bottle, and we'll see if he can do the task. Can you do that? (Laughter) Okay. He's pretty good. Yeah. Good, good, good. I didn't show you how to do that. Now see if you can put it back together. (Laughter) And he thinks a robot has to be really slow. Good robot, that's good. So we saw a bunch of things there. We saw when we're interacting, we're trying to show someone how to do something, we direct their visual attention. The other thing communicates their internal state to us, whether he's understanding or not, regulates a social interaction. There was shared attention looking at the same sort of thing, and recognizing socially communicated reinforcement at the end. And we've been trying to put that into our lab robots because we think this is how you're going to want to interact with robots in the future. I just want to show you one technical diagram here. The most important thing for building a robot that you can interact with socially is its visual attention system. Because what it pays attention to is what it's seeing and interacting with, and what you're understanding what it's doing. So in the videos I'm about to show you, you're going to see a visual attention system on a robot which has — it looks for skin tone in HSV space, so it works across all human colorings. It looks for highly saturated colors, from toys. And it looks for things that move around. And it weights those together into an attention window, and it looks for the highest-scoring place — the stuff where the most interesting stuff is happening — and that is what its eyes then segue to. And it looks right at that. At the same time, some top-down sort of stuff: might decide that it's lonely and look for skin tone, or might decide that it's bored and look for a toy to play with. And so these weights change. And over here on the right, this is what we call the Steven Spielberg memorial module. Did people see the movie ""AI""? (Audience: Yes.) RB: Yeah, it was really bad, but — remember, especially when Haley Joel Osment, the little robot, looked at the blue fairy for 2,000 years without taking his eyes off it? Well, this gets rid of that, because this is a habituation Gaussian that gets negative, and more and more intense as it looks at one thing. And it gets bored, so it will then look away at something else. So, once you've got that — and here's a robot, here's Kismet, looking around for a toy. You can tell what it's looking at. You can estimate its gaze direction from those eyeballs covering its camera, and you can tell when it's actually seeing the toy. And it's got a little bit of an emotional response here. (Laughter) But it's still going to pay attention if something more significant comes into its field of view — such as Cynthia Breazeal, the builder of this robot, from the right. It sees her, pays attention to her. Kismet has an underlying, three-dimensional emotional space, a vector space, of where it is emotionally. And at different places in that space, it expresses — can we have the volume on here? Can you hear that now, out there? (Audience: Yeah.) Kismet: Do you really think so? Do you really think so? Do you really think so? RB: So it's expressing its emotion through its face and the prosody in its voice. And when I was dealing with my robot over here, Chris, the robot, was measuring the prosody in my voice, and so we have the robot measure prosody for four basic messages that mothers give their children pre-linguistically. Here we've got naive subjects praising the robot: Voice: Nice robot. You're such a cute little robot. (Laughter) RB: And the robot's reacting appropriately. Voice: ...very good, Kismet. (Laughter) Voice: Look at my smile. RB: It smiles. She imitates the smile. This happens a lot. These are naive subjects. Here we asked them to get the robot's attention and indicate when they have the robot's attention. Voice: Hey, Kismet, ah, there it is. RB: So she realizes she has the robot's attention. Voice: Kismet, do you like the toy? Oh. RB: Now, here they're asked to prohibit the robot, and this first woman really pushes the robot into an emotional corner. Voice: No. No. You're not to do that. No. (Laughter) Not appropriate. No. No. (Laughter) RB: I'm going to leave it at that. We put that together. Then we put in turn taking. When we talk to someone, we talk. Then we sort of raise our eyebrows, move our eyes, give the other person the idea it's their turn to talk. And then they talk, and then we pass the baton back and forth between each other. So we put this in the robot. We got a bunch of naive subjects in, we didn't tell them anything about the robot, sat them down in front of the robot and said, talk to the robot. Now what they didn't know was, the robot wasn't understanding a word they said, and that the robot wasn't speaking English. It was just saying random English phonemes. And I want you to watch carefully, at the beginning of this, where this person, Ritchie, who happened to talk to the robot for 25 minutes — (Laughter) — says, ""I want to show you something. I want to show you my watch."" And he brings the watch center, into the robot's field of vision, points to it, gives it a motion cue, and the robot looks at the watch quite successfully. We don't know whether he understood or not that the robot — Notice the turn-taking. Ritchie: OK, I want to show you something. OK, this is a watch that my girlfriend gave me. Robot: Oh, cool. Ritchie: Yeah, look, it's got a little blue light in it too. I almost lost it this week. (Laughter) RB: So it's making eye contact with him, following his eyes. Ritchie: Can you do the same thing? Robot: Yeah, sure. RB: And they successfully have that sort of communication. And here's another aspect of the sorts of things that Chris and I were doing. This is another robot, Cog. They first make eye contact, and then, when Christie looks over at this toy, the robot estimates her gaze direction and looks at the same thing that she's looking at. (Laughter) So we're going to see more and more of this sort of robot over the next few years in labs. But then the big questions, two big questions that people ask me are: if we make these robots more and more human-like, will we accept them, will we — will they need rights eventually? And the other question people ask me is, will they want to take over? (Laughter) And on the first — you know, this has been a very Hollywood theme with lots of movies. You probably recognize these characters here — where in each of these cases, the robots want more respect. Well, do you ever need to give robots respect? They're just machines, after all. But I think, you know, we have to accept that we are just machines. After all, that's certainly what modern molecular biology says about us. You don't see a description of how, you know, Molecule A, you know, comes up and docks with this other molecule. And it's moving forward, you know, propelled by various charges, and then the soul steps in and tweaks those molecules so that they connect. It's all mechanistic. We are mechanism. If we are machines, then in principle at least, we should be able to build machines out of other stuff, which are just as alive as we are. But I think for us to admit that, we have to give up on our special-ness, in a certain way. And we've had the retreat from special-ness under the barrage of science and technology many times over the last few hundred years, at least. 500 years ago we had to give up the idea that we are the center of the universe when the earth started to go around the sun; 150 years ago, with Darwin, we had to give up the idea we were different from animals. And to imagine — you know, it's always hard for us. Recently we've been battered with the idea that maybe we didn't even have our own creation event, here on earth, which people didn't like much. And then the human genome said, maybe we only have 35,000 genes. And that was really — people didn't like that, we've got more genes than that. We don't like to give up our special-ness, so, you know, having the idea that robots could really have emotions, or that robots could be living creatures — I think is going to be hard for us to accept. But we're going to come to accept it over the next 50 years or so. And the second question is, will the machines want to take over? And here the standard scenario is that we create these things, they grow, we nurture them, they learn a lot from us, and then they start to decide that we're pretty boring, slow. They want to take over from us. And for those of you that have teenagers, you know what that's like. (Laughter) But Hollywood extends it to the robots. And the question is, you know, will someone accidentally build a robot that takes over from us? And that's sort of like this lone guy in the backyard, you know — ""I accidentally built a 747."" I don't think that's going to happen. And I don't think — (Laughter) — I don't think we're going to deliberately build robots that we're uncomfortable with. We'll — you know, they're not going to have a super bad robot. Before that has to come to be a mildly bad robot, and before that a not so bad robot. (Laughter) And we're just not going to let it go that way. (Laughter) So, I think I'm going to leave it at that: the robots are coming, we don't have too much to worry about, it's going to be a lot of fun, and I hope you all enjoy the journey over the next 50 years. (Applause)"	"今天我想告訴大家的是，我認為機器人將會以各種不同方式，不同時間進駐到我們的生活之中。當我估算未來時，我相信五百年後的世界，到處都是機器人，只是假設 — 儘管有許多人對未來有悲觀的預測( 世界末日等 ) —假設我們到時候還活著，我相信世界將會充斥著機器人。接下來的問題是，如果五百年後它們將會存在於世上，它們是否會更早出現呢?它們在未來五十年內是否會存在於我們的生活中呢?是的，我相信大概是如此 — 到時候將會到處都有一堆機器人。事實上我認為會更快就出現一堆機器人了。我想我們正處在機器人普及化的開端了，在1978或1980年代，個人電腦剛出現的時候，一些初期的機器人就已經出現了。 電腦是從遊戲和玩具開始進入我們生活中的。你知道嗎，一開始人們有電腦時大概都是拿來玩 乒乓球 遊戲(最早的電玩)，裡面裝著小小的微處理器，之後其他遊戲才漸漸出來。對於機器人來說，大概也會有類似的狀況：樂高機器人套件中的互動機器人菲比 — 這邊有沒有人擁有菲比?全世界共賣出三千八百萬台。它們很常見，它們是小小機器人，一個裝著許多感應器的簡易機器人。它能處理一些簡單的訊息。 右邊是另一個幾年前就出現的機器娃娃。如同較早之前一般，當時有許多藉由電腦所進行的業餘互動模式，你可以找到很多修改工具以及如何修改的書。左邊是一個 Evolution Robotics 所做的工作平台，你可以將電腦接上去，然後藉由圖形化介面去設定讓它在家裡到處亂走或是做各種事情。這是一個價格較高的某種機器人玩具 —Sony 的 Aibo。在右邊的是 NEC 開發的 PaPeRo，雖然我本來不認為它會被推出。然而，這類型的東西已經出現了。 在過去兩三年之間，我們看見了割草機器人的出現，上面是 Husqvarna 公司製造的，下面則是 以色列 Friendly Robotics 公司所推出的。而在過去十二個月左右的時間，我們開始看見許多家用清潔機器人的出現。左上角的是一個很棒的家用清潔機器人，由英國的一家Dyson公司製造。不過它很貴 —要價三千五百美金 — 他們並沒有販賣它。 左下角是Electrolux，這個就有在販賣。另一個是Karcher公司做的。右下角這個是大約十年前我在實驗室裡做出來的，我們後來終於把它變成商品。讓我展示一下這個。我想 Chris 有說，在演講之後我們會把它送出去。這是一具你可以買到的機器人, 它會幫你清掃地板。然後它開始到處用繞圈的方式移動。如果它撞到東西 — 你看見了嗎？它開始沿著牆壁前進，它正沿著我的腳進行清掃。讓我們看看 —喔，誰偷了我的爆米香?它們偷了我的爆米香。(笑聲)別擔心，放輕鬆，它是一個機器人，它很聰明。(笑聲)看，三歲的小孩都不會擔心。大人反而會覺得不安。(笑聲)先在這裡放一些垃圾。(笑聲)好吧。(笑聲)不知道你們有沒有看見 — 所以我在這邊放一些爆米香，在放幾塊錢，看看它會不會清理乾淨。耶，它做到了。所以 —我們先讓它待在那兒一下。(掌聲) 這些小技巧讓清潔機器人變得更好，事實上，寫在電路板的人工智能相當簡單。對於很多機器人來說都是如此。我想我們都變成了某種計算機的沙文主義者，認為運算就是一切，但是機構仍然是重要的一件事。這是另一個機器人，PackBot，我們花了幾年的時間去製造它。它是軍事偵測機器人，總是走在部隊前方，去進行例如洞穴內偵查的任務。但是我們必須讓它變成更加強壯，比我們實驗室中其他機器人都更加強壯。(笑聲)機器人內部裝置的電腦使用 Linux 系統。它可以承受 400G 的震盪。這個機器人擁有局部智能：它能夠將自己翻轉過來，讓自己抵達通訊範圍內，可以自己爬上樓之類的。好，它正在區域探索。一個士兵給它上樓的指令，它也照做了。那不是命令控制叫它摔下去的。(笑聲)現在它準備繞到前面去。這些機器人在911那天有了重大進展。當晚我們將這些機器人置放於世界貿易中心。在主要的碎石堆中無法做什麼事，狀況太糟糕，已經沒什麼能做的。但是我們進入了周圍已經被淨空的大樓，在那些因為太危險而無法進入的大樓中，找尋可能的生還者。我們來播放這段影片。播報員：戰場幫手正在協助降低人們救援的風險。請 Nick Robertson 告訴我們現場狀況Nick Robertson：能不能再拿一台來？好的，太好了。這是兩個禮拜前那台機器人的殘骸。他將機器人們派遣至洞穴中勘查狀況。這些機器人是全自動運作的。目前最糟的狀況是其中一台機器人在洞穴中跌入了十公尺的地方。 在一年前，美軍還沒有這些機器人。而現在他們每天都在阿富汗執行任務。這是他們說機器人正在進駐的其中一個原因。目前科技的進展有著巨大的改變。謝謝。在未來幾個月內，我們將會把這些機器人送往生產原油的油井之下，去將可以使用好幾年的原油運送出來。在150度C、一萬psi的嚴酷環境下。自主機器人將進入下方，進行這類工作。但這類型機器人的設計有點困難。在未來，我們要如何去設計機器人，該如何讓它們更容易被使用？我想在這裡用一個機器人 —這個機器人叫 Chris — 站起來。對。很好。過來這邊。請注意，他認為機器人應該有點僵硬。他常這樣做。但是我將會 —Chris Anderson：我只是比較英式。RB：喔。(笑聲)(掌聲)我將會指派一個任務給這個機器人。是一個很複雜的任務。請注意，他在點頭，他是在給我一些提示，讓我知道他了解溝通的流程。如果我說了些奇怪的話，他會質疑的看著我，然後調整對話內容。現在我把這個拿到他的前面。我看著他的眼睛，我看見他看著瓶子的頂端。我在這裡指派任務，他正在確認中。他的眼睛正在前後觀望，看看我正在看什麼，現在我們有了共同注意的東西。我指派了這個任務，他正看著，然後看著我，看看之後會發生什麼事。現在我將會把瓶子交給他，然後看看他能不能完成這個任務。你能做到嗎？(笑聲)好的。他做得很好。對，很好很好。我並沒有告訴你怎麼做那件事。現在看看你能不能把他裝回去。(笑聲)他認為機器人必須相當緩慢。好機器人，很棒。 我們看了這兒的一些事情。我們看見當我們互動時，試著去讓某人知道如何做一件事，我們引導它們視覺上的注意。另一件事是要讓它們內部狀態和我們進行溝通，是否它了解如何進行社交互動。這是在參與關注並看著同一個東西，最後去辨識社交訊息。我們試著將這個放進我們實驗室的機器人裡，因為我們認為這將會是未來讓你想要和機器人互動的方式。我給大家看一張技術圖表。要製造一台能夠和你社交性互動的機器人，最重要的是它的視覺關注系統。因為它注意的東西是它所看見，並且互動的東西，以及讓你了解它在做什麼。在接下來給大家看的這段影片中，你將會看見一個具有視覺關注系統的機器人，其中有著 — 它會在 HSV 區間中搜尋皮膚色澤，它會掃過所有的東西，例如人的膚色。它從玩具中搜尋高飽和度的顏色。並且搜尋移動的物體。它將這些放在關注視窗中進行衡量，找出最高分的地方 — 東西進行中的最有意思的東西。那就是它的眼睛的下個目標。它盯著那東西看。同時做出上下看的動作：可能會決定顯現它很寂寞，搜尋著皮膚色澤，或是決定顯現它很無聊，想找玩具來玩。這些衡量持續改變著。 在右邊這個地方，有著我們稱為 Steven Spielberg 記憶模組的東西。你們看過AI這部電影嗎？觀眾：有。 RB：嗯，那部片很爛，但是 — 請記住，尤其是當Haley Joel Osment，那個小機器人，看著那個藍色精靈2000年都沒有移開過視線？嗯，這可以解釋它，因為這是高斯慣性變成了負值，於是當它看著某個東西時就變得更加強烈。當它覺得厭倦時，它將會轉頭去看別的東西。當你了解這點時，這兒是另一個機器人，Kismet，在四周尋找著玩具。你可以知道那是它正在看得東西。你可以藉由眼球下覆蓋的攝影機來估算它的眼神方向，你可以知道它是不是看著玩具。它有一點情緒性反應。(笑聲)不過它仍然在注意著，是否有其它更重要的東西進入視線範圍內 —例如右邊的 Cynthia Breazeal，機器人的製造者。它看見她，注意著她。Kismet 有一個內建的三維模式的情感區間，一個向量區間用以讓它產生情緒。在區間中另一個地方讓它表達出 —我們可以把聲音打開嗎?你們能聽見嗎? 觀眾：可以。 Kismet：你真的這麼認為嗎？真的那麼認為嗎？你真的這麼認為嗎？ RB：它藉由臉部表情以及聲音語調來表達它的情緒。當我在那兒應付我的機器人時，這個機器人，Chris，正量測著我的聲音的語調，如此我們的機器人能夠去量測語調，來了解四種母親們在小孩會說話前所使用的基本訊息。這兒是用純真的內容來讚美機器人， 聲音：好機器人。你是一個可愛的小機器人。(笑聲)然後機器人的反應很恰當。 聲音：很棒，Kismet。(笑聲) 聲音：看著我笑一個。 RB：它笑了。她模仿著笑容。這常會發生。這些純真的事件。接著我們要求他們取得機器人的注意，並且當他們取得機器人注意時給予提示。 聲音：嘿，Kismet，看這邊。 RB：她發現她取得機器人的注意了。聲音：Kismet，你喜歡這個玩具嗎？喔。 RB：現在，被要求去阻止機器人，第一個女士已經將機器人推入情緒的角落。 聲音：不行，你不可以那樣。不可以。(笑聲) 聲音：不行，不可以。(笑聲) RB：就先到這邊為止。 我們將這些都放在一起，然後我們輸入輪流的觀念。當我們和某人說時，我們說著話。然後，我們會揚起眉毛，移動眼睛，告訴另一個人，該你說了。然後就這樣一來一往的開始交談起來。於是我們將這個機制放進機器人中。我們輸入許多常見的話題，我們沒有告訴他們任何關於機器人的事，讓他們坐在機器人面前和機器人聊天。不過他們並不知道，機器人根本不知道他們再說什麼，機器人也不會說英文。它只是隨機說出英文的字句。請注意看一開始的狀況，這位 Ritchie 一不小心就跟機器人聊了 25 分鐘 —(笑聲)— 他說，""我想讓你看樣東西。我讓你看我的手錶。""他把手錶的中心放進了機器人的視野之中，指著它，給機器人一個感覺的提示，機器人成功地看著那支手錶。我們不確定他是否知道這個機器人 —注意的是輪流說話的時機。Ritchie：好了，我要讓你看樣東西。嗯，這是一支手錶，我女朋友給我的。Robot：喔，真酷。Ritchie：是啊，看，上面有微弱的藍光照明。我這裡拜差點把它搞丟了。(笑聲)RB：它正在和他目光接觸，盯著他的眼睛看。Ritchie：你能做一樣的事嗎？機器人：是的，當然嚕。RB：他們成功地進行著這類溝通。 接下來是類似我和 Chris 所做的事情。這是另外一個機器人，Cog。他們一開始也是進行目光接觸，然後當 Christie 看著這個玩具，機器人估算她目光的方向，然後看著她正在看的那個東西。(笑聲)未來幾年中，我們將在這個實驗室製作出更多類似的機器人。但之後的大問題是，兩個人們常問的問題是：如果我們製作出的機器人越來越像人，我們要尊重它們嗎？它們需要機器人權嗎？另一個人們常問的問題是，它們會取代我們嗎？(笑聲)首先 — 你知道，這已經是好萊塢許多電影的內容了。你大概能認得這些角色 —這些例子中，機器人都希望能得到更多的尊重。你曾經需要給予機器人尊重嗎?它們只不過是機器啊。但是，我認為，我們必須接受，我們也只是機器。畢竟，對許多現代分子生物學家來說，就是如此。你不會看見任何說明來告訴你，一個分子是怎麼和另一個分子結合在一起的。它會因為許多因素而移動，而靈魂介入之後，改變了這些分子的連結方式。這些都符合機械原理，我們都是機械的機構。如果我們是機器，那麼理論上，我們應該能夠製造出和我們一樣活生生的機器。但如果我們讓它發生的話，我們在某些方面必須放棄我們的獨特性。在過去至少幾百年中科學與技術多次的衝擊下，我們失去了獨特的特性。五百年前，當人們發現地球繞著太陽轉時，才放棄了地球是宇宙中心的想法；一百五十年前，因為達爾文，我們放棄了自以為和動物不同的想法。想想這個，對人們而言這是相當困難的。近代的人們被，人類並不是獨立被創造出來的，這種觀念給擊垮了，雖然很多人不喜歡這說法。而人類的基因顯示著，也許我們只有35000個基因。這也是人們不喜歡的，我們應該要有更多基因吧。我們不喜歡放棄我們的獨特性，知道機器人也許能夠有情感，或是機器人能變成生物時 —我想這種事很難讓人們接受。但是在未來五十年或更久之後，我們將會接受它。 第二個問題是，機器人是否會想要接管這一切？標準的劇情模式是，我們將會發明機器人，我們培育它們，它們從而學習到許多事情，接著將會覺得我們很無趣，很遲鈍。它們想要取代我們。那些有叛逆期孩子的家長，應該很了解這種感覺。(笑聲)好萊塢將這種劇情延伸到機器人上。問題是，會不會有人不小心做出一個能取代我們而主宰世界的機器人?就像是某個在後院的寂寞男人，告訴你，""我不小心做出了一架波音747。""我不認為這會發生。我不認為 —(笑聲)我不認為我們會故意去創造出讓我們不舒服的機器人。嗯 — 你知道，不會有那種非常糟糕的機器人啦。在那之前會先出現稍微糟糕的機器人，在之前會出現不那麼糟糕的機器人。(笑聲)我們不會讓狀況惡化的。(笑聲)所以我最後的結論是：機器人的時代即將來臨，大家不用擔心太多，那將會帶來很多樂趣，希望大家都能在未來五十年中享受這過程。(掌聲)"
