Talk	en	zh-tw
cynthia_breazeal_the_rise_of_personal_robots	"Ever since I was a little girl seeing ""Star Wars"" for the first time, I've been fascinated by this idea of personal robots. And as a little girl, I loved the idea of a robot that interacted with us much more like a helpful, trusted sidekick — something that would delight us, enrich our lives and help us save a galaxy or two. I knew robots like that didn't really exist, but I knew I wanted to build them. So 20 years pass — I am now a graduate student at MIT studying artificial intelligence, the year is 1997, and NASA has just landed the first robot on Mars. But robots are still not in our home, ironically. And I remember thinking about all the reasons why that was the case. But one really struck me. Robotics had really been about interacting with things, not with people — certainly not in a social way that would be natural for us and would really help people accept robots into our daily lives. For me, that was the white space; that's what robots could not do yet. And so that year, I started to build this robot, Kismet, the world's first social robot. Three years later — a lot of programming, working with other graduate students in the lab — Kismet was ready to start interacting with people. (Video) Scientist: I want to show you something. Kismet: (Nonsense) Scientist: This is a watch that my girlfriend gave me. Kismet: (Nonsense) Scientist: Yeah, look, it's got a little blue light in it too. I almost lost it this week. Cynthia Breazeal: So Kismet interacted with people like kind of a non-verbal child or pre-verbal child, which I assume was fitting because it was really the first of its kind. It didn't speak language, but it didn't matter. This little robot was somehow able to tap into something deeply social within us — and with that, the promise of an entirely new way we could interact with robots. So over the past several years I've been continuing to explore this interpersonal dimension of robots, now at the media lab with my own team of incredibly talented students. And one of my favorite robots is Leonardo. We developed Leonardo in collaboration with Stan Winston Studio. And so I want to show you a special moment for me of Leo. This is Matt Berlin interacting with Leo, introducing Leo to a new object. And because it's new, Leo doesn't really know what to make of it. But sort of like us, he can actually learn about it from watching Matt's reaction. (Video) Matt Berlin: Hello, Leo. Leo, this is Cookie Monster. Can you find Cookie Monster? Leo, Cookie Monster is very bad. He's very bad, Leo. Cookie Monster is very, very bad. He's a scary monster. He wants to get your cookies. (Laughter) CB: All right, so Leo and Cookie might have gotten off to a little bit of a rough start, but they get along great now. So what I've learned through building these systems is that robots are actually a really intriguing social technology, where it's actually their ability to push our social buttons and to interact with us like a partner that is a core part of their functionality. And with that shift in thinking, we can now start to imagine new questions, new possibilities for robots that we might not have thought about otherwise. But what do I mean when I say ""push our social buttons?"" Well, one of the things that we've learned is that, if we design these robots to communicate with us using the same body language, the same sort of non-verbal cues that people use — like Nexi, our humanoid robot, is doing here — what we find is that people respond to robots a lot like they respond to people. People use these cues to determine things like how persuasive someone is, how likable, how engaging, how trustworthy. It turns out it's the same for robots. It's turning out now that robots are actually becoming a really interesting new scientific tool to understand human behavior. To answer questions like, how is it that, from a brief encounter, we're able to make an estimate of how trustworthy another person is? Mimicry's believed to play a role, but how? Is it the mimicking of particular gestures that matters? It turns out it's really hard to learn this or understand this from watching people because when we interact we do all of these cues automatically. We can't carefully control them because they're subconscious for us. But with the robot, you can. And so in this video here — this is a video taken from David DeSteno's lab at Northeastern University. He's a psychologist we've been collaborating with. There's actually a scientist carefully controlling Nexi's cues to be able to study this question. And the bottom line is — the reason why this works is because it turns out people just behave like people even when interacting with a robot. So given that key insight, we can now start to imagine new kinds of applications for robots. For instance, if robots do respond to our non-verbal cues, maybe they would be a cool, new communication technology. So imagine this: What about a robot accessory for your cellphone? You call your friend, she puts her handset in a robot, and, bam! You're a MeBot — you can make eye contact, you can talk with your friends, you can move around, you can gesture — maybe the next best thing to really being there, or is it? To explore this question, my student, Siggy Adalgeirsson, did a study where we brought human participants, people, into our lab to do a collaborative task with a remote collaborator. The task involved things like looking at a set of objects on the table, discussing them in terms of their importance and relevance to performing a certain task — this ended up being a survival task — and then rating them in terms of how valuable and important they thought they were. The remote collaborator was an experimenter from our group who used one of three different technologies to interact with the participants. The first was just the screen. This is just like video conferencing today. The next was to add mobility — so, have the screen on a mobile base. This is like, if you're familiar with any of the telepresence robots today — this is mirroring that situation. And then the fully expressive MeBot. So after the interaction, we asked people to rate their quality of interaction with the technology, with a remote collaborator through this technology, in a number of different ways. We looked at psychological involvement — how much empathy did you feel for the other person? We looked at overall engagement. We looked at their desire to cooperate. And this is what we see when they use just the screen. It turns out, when you add mobility — the ability to roll around the table — you get a little more of a boost. And you get even more of a boost when you add the full expression. So it seems like this physical, social embodiment actually really makes a difference. Now let's try to put this into a little bit of context. Today we know that families are living further and further apart, and that definitely takes a toll on family relationships and family bonds over distance. For me, I have three young boys, and I want them to have a really good relationship with their grandparents. But my parents live thousands of miles away, so they just don't get to see each other that often. We try Skype, we try phone calls, but my boys are little — they don't really want to talk; they want to play. So I love the idea of thinking about robots as a new kind of distance-play technology. I imagine a time not too far from now — my mom can go to her computer, open up a browser and jack into a little robot. And as grandma-bot, she can now play, really play, with my sons, with her grandsons, in the real world with his real toys. I could imagine grandmothers being able to do social-plays with their granddaughters, with their friends, and to be able to share all kinds of other activities around the house, like sharing a bedtime story. And through this technology, being able to be an active participant in their grandchildren's lives in a way that's not possible today. Let's think about some other domains, like maybe health. So in the United States today, over 65 percent of people are either overweight or obese, and now it's a big problem with our children as well. And we know that as you get older in life, if you're obese when you're younger, that can lead to chronic diseases that not only reduce your quality of life, but are a tremendous economic burden on our health care system. But if robots can be engaging, if we like to cooperate with robots, if robots are persuasive, maybe a robot can help you maintain a diet and exercise program, maybe they can help you manage your weight. Sort of like a digital Jiminy — as in the well-known fairy tale — a kind of friendly, supportive presence that's always there to be able to help you make the right decision in the right way at the right time to help you form healthy habits. So we actually explored this idea in our lab. This is a robot, Autom. Cory Kidd developed this robot for his doctoral work. And it was designed to be a robot diet-and-exercise coach. It had a couple of simple non-verbal skills it could do. It could make eye contact with you. It could share information looking down at a screen. You'd use a screen interface to enter information, like how many calories you ate that day, how much exercise you got. And then it could help track that for you. And the robot spoke with a synthetic voice to engage you in a coaching dialogue modeled after trainers and patients and so forth. And it would build a working alliance with you through that dialogue. It could help you set goals and track your progress, and it would help motivate you. So an interesting question is, does the social embodiment really matter? Does it matter that it's a robot? Is it really just the quality of advice and information that matters? To explore that question, we did a study in the Boston area where we put one of three interventions in people's homes for a period of several weeks. One case was the robot you saw there, Autom. Another was a computer that ran the same touch-screen interface, ran exactly the same dialogues. The quality of advice was identical. And the third was just a pen and paper log, because that's the standard intervention you typically get when you start a diet-and-exercise program. So one of the things we really wanted to look at was not how much weight people lost, but really how long they interacted with the robot. Because the challenge is not losing weight, it's actually keeping it off. And the longer you could interact with one of these interventions, well that's indicative, potentially, of longer-term success. So the first thing I want to look at is how long, how long did people interact with these systems. It turns out that people interacted with the robot significantly more, even though the quality of the advice was identical to the computer. When it asked people to rate it on terms of the quality of the working alliance, people rated the robot higher and they trusted the robot more. (Laughter) And when you look at emotional engagement, it was completely different. People would name the robots. They would dress the robots. (Laughter) And even when we would come up to pick up the robots at the end of the study, they would come out to the car and say good-bye to the robots. They didn't do this with a computer. The last thing I want to talk about today is the future of children's media. We know that kids spend a lot of time behind screens today, whether it's television or computer games or whatnot. My sons, they love the screen. They love the screen. But I want them to play; as a mom, I want them to play, like, real-world play. And so I have a new project in my group I wanted to present to you today called Playtime Computing that's really trying to think about how we can take what's so engaging about digital media and literally bring it off the screen into the real world of the child, where it can take on many of the properties of real-world play. So here's the first exploration of this idea, where characters can be physical or virtual, and where the digital content can literally come off the screen into the world and back. I like to think of this as the Atari Pong of this blended-reality play. But we can push this idea further. What if — (Game) Nathan: Here it comes. Yay! CB: — the character itself could come into your world? It turns out that kids love it when the character becomes real and enters into their world. And when it's in their world, they can relate to it and play with it in a way that's fundamentally different from how they play with it on the screen. Another important idea is this notion of persistence of character across realities. So changes that children make in the real world need to translate to the virtual world. So here, Nathan has changed the letter A to the number 2. You can imagine maybe these symbols give the characters special powers when it goes into the virtual world. So they are now sending the character back into that world. And now it's got number power. And then finally, what I've been trying to do here is create a really immersive experience for kids, where they really feel like they are part of that story, a part of that experience. And I really want to spark their imaginations the way mine was sparked as a little girl watching ""Star Wars."" But I want to do more than that. I actually want them to create those experiences. I want them to be able to literally build their imagination into these experiences and make them their own. So we've been exploring a lot of ideas in telepresence and mixed reality to literally allow kids to project their ideas into this space where other kids can interact with them and build upon them. I really want to come up with new ways of children's media that foster creativity and learning and innovation. I think that's very, very important. So this is a new project. We've invited a lot of kids into this space, and they think it's pretty cool. But I can tell you, the thing that they love the most is the robot. What they care about is the robot. Robots touch something deeply human within us. And so whether they're helping us to become creative and innovative, or whether they're helping us to feel more deeply connected despite distance, or whether they are our trusted sidekick who's helping us attain our personal goals in becoming our highest and best selves, for me, robots are all about people. Thank you. (Applause)"	"從我還是一個小女孩第一次觀看星球大戰開始，我就被個人機器人這個概念所吸引。當我是小女孩時，我就愛這主意-機器人可以與我們互動就像我們身邊有益值得信賴的助手，能逗樂我們，豐富我們的生活還能助我們拯救一兩個星系。所以當那時我知道這樣的機器人還不存在時，我就知道-我想要建造它們。 20年過去了，我進入麻省理工學院的研究院學習人工智能，那一年是1997年，NASA剛剛登陸了第一個在火星的機器人。但是，諷刺的是，機器人仍然不在我們的家中。我還記得考慮過所有爲什麽如此的原因。其中一個原因特別使我震驚。機器人技術一度就是關於如何和實物互動，而不是與人類-尤其不可能以一種對我們而言自然的社交方式幫助我們真正接受機器人進入我們的日常生活。對我而言，那就是空缺-那就是機器人尚且不能做的。所以那一年，我開始建造機器人Kismet,世界上第一個社交型機器人。三年后-許多的編程，和與其他博士生在實驗室的一同工作后-Kismet 開始能夠和他人互動。 (錄像）科學家：我要給你看一個東西。 Kismet： 科學家：這是我女友給我的手錶 Kismet： 科學家：看，它這還有個小藍燈在裏面。這周我差點丟了它。 辛西婭：所以Kismet和人們交流有點像一個不會說話或說話前的孩童，我認為這很合適，因為Kismet正是第一個這類機器人。它不能說話，但這無所謂。這個小機器人不知怎麼地，能夠深深觸動我們內心的交際性。於是，這預示了一種我們能與機器人交流的全新方式。 所以在過去的這些年中，我繼續探索著機器人的人際交流方向，現在在麻省理工學院媒體實驗室我建立一個團隊，由許多無比天才的學生組成。我最喜歡的機器人之一是里納多(Leonardo).我們與Stan Winston工作室合作研發了里納多。現在我想向你們展示一個對我和里納多特別的時刻。這是Matt Berlin 和里納多的互動，給里納多介紹一種新事物。因為是新事物，里納多並不知道對此該怎麼做。但有點像我們，他可以通過觀察Matt的反應來學習。 (錄像）Matt Berlin：你好，里納多。里納多，這是餅乾怪獸。你能找到餅乾怪獸嗎？里納多，餅乾怪獸非常壞。他非常壞，里納多。餅乾怪獸非常非常壞。他是一個可怕的怪獸。他想搶走你的餅乾。 (笑聲） CB: 好，所以里納多和餅乾交往的開始有點艱難但他們現在相處的很好。 所以從建造這些系統我學到機器人事實上是一種有趣的社會科技。機器人有能力觸動我們的交際按鈕像我們的夥伴一樣與我們交流這是他們功能的核心。有了這種思考上的變化，我們現在可以開始想像對於機器人我們不曾想過的新問題和新的可能性。但什麽是我所說的""觸動我們的交際按鈕""呢？我們學到的一樣東西是當我們設計這些機器人用同樣的身體語言與我們交流，既人們所用的同一種非言語暗示-像Nexi,我們的類人機器人在這裡所作的-我們發現，我們回應機器人十分類似于我們回應他人。人們通過這些非言語暗示來確定一個人多有說服力，多討人喜歡，多迷人，多值得信賴。而原來，對於機器人也同樣如此， 結果是現在機器人正在成為一種用來理解人類行為的有趣的科學工具。從一次簡短的相見，我們是怎麼能夠判斷另一個人有多值得信任的呢？模仿被認為是因素之一，但究竟如何呢？是不是模仿一種特定的姿勢有影響？結果發現想要從觀察他人中學習和理解這非常困難因為當我們與人交流時，一切暗示信號都自然發生我們不能仔細控制它們，因為它們是潛意識的但是對於機器人你可以。 所以這有個視頻 —這是一個在西北大學David DeSteno的實驗室錄製的視頻David 是一個我們合作的心理學家。有科學家在仔細控制著Nexi的肢體暗示信號來能研究這個問題。所以底線是-爲什麽這樣有效的原因是-因為人們即使在和機器人互動時，表現的和平時也一樣。所以有了這個關鍵的理解，我們現在可以想像新種類的機器人應用。比如，如果機器人可以回應我們的非言語信號，那麼它們可以用在新型超酷的傳媒科技上。所以想像：設計一個機器人手機配件如何？你給朋友打電話，她把聽筒放在機器人里，哇哦，你變成了一個自我機器人—你們可以眼神交流，你可以和朋友說話，你可以走動，你可以做手勢—這可能就是下一個真正會發生的了不起的事，不是嗎？ 來探索這個問題我的學生，Siggy Adalgeirsson，做了一項研究我們召集了參與者-人來我們的實驗室，與一個遠程合作者一同完成一個合作任務。任務包括像看桌子上放置的一系列東西，然后討論這些東西對於完成一個特定任務-最終是一個生存任務-的相關性和重要性然後根據他們認為這樣東西多有價值多重要來打分。遠程合作者是一個來自我們組的實驗人員他們使用三種不同的科技手段來和參與者交流。第一種是屏幕，就像如今的視屏會議一樣。第二種我們加入了移動性，一個會移動的屏幕就像，如果你熟悉的話，現在存在的任何遠程呈現機器人一樣—這反應了那種情況。下一類就是有完全表達性的自我機器人。 所以在交流后，我們讓參與者給他們與遠程合作者交流所使用的科技手段在不同方面打分。我們考慮了心理的投入度—多設身處地他們為另一個人（遠程合作者）考慮？我們看了整體的參與度。我們考慮了他們合作的慾望度。這是他們只使用屏幕的結果。如果你加入移動性-在桌子上轉動的能力-你能得到一點提高但如果加入完全的表達，你得到更多的提高所以看上去實體的交流化身能起重要的作用。 現在把這個放入大一點的社會環境。我們知道如今家族之間住得越來越遠，這距離確實給我們的家庭關係和家庭聯結打了折扣。對我而言，我有三個小兒子我想讓他們和他們的爺爺奶奶有真正好的關係。但是我父母住的遠隔千里所以他們并不能那麼經常見到彼此。我們試過電話，Skype(網路視頻電話)，但是我的孩子還小-他們並不想說話他們想玩。他們會喜歡這個機器人成為一種遠程遊戲科技的概念。所以我想像不遠的將來—我的媽媽可以到她的電腦前，打開瀏覽器，化身為一個小機器人。作為奶奶機器人她可以真正和我的兒子她孫子一起玩在真實的世界和他們真正的玩具一起玩我可以想像祖母們和他們的孫子孫女朋友，一起社交遊戲一起分享在屋子里各種各樣的活動，比如，分享床頭故事通過這種科技他們能夠以成為他們孫子孫女生活中的活躍的一部份而這在今日尚不可能。 讓我們再考慮一下其他方面，比如健康醫療。在今日的美國超過百分之65的人超重，肥胖這也正成為我們孩子中的大問題。我們知道當你漸漸變老時，如果你早年肥胖的話，可能會導致愈多慢性病這不僅降低我們生活的質量，也正成為我們醫療系統的重大經濟負擔。所以如果機器人可以是有趣的，如果我們喜歡和機器人合作，同時機器人是有說服力的，那麼也許機器人可以幫助你保持你的健康飲食和鍛煉計劃，也許他們能幫你控制你的體重。這有點像那個有名童話故事中的電子吉米尼，機器人作為一種友好支持的存在總能在那裡幫你做出正確抉擇以合適的方式，在合適的時間幫你養成健康的習慣。我們事實上已經探索了這個主意。 這是一個機器人，叫Autom.Cory Kidd為他的博士論文發明了這個機器人。它被設計為一個機器人健康飲食鍛煉教練。它有一些簡單的非語言技巧。它可以與你眼神交流它可以低頭看屏幕與你分享信息。你將用一個屏幕介面輸入信息，像你今天吃了多少卡路里運動了多少它就能追蹤記錄那些同時機器人可以用它人造的合成聲音與你進行指導對話。這對話模擬真實的訓練者與病人的交流。所以通過對話，它可以與你形成一種工作同盟。它幫你建立目標，記錄你的進展，鼓勵你。 所以一個有趣的問題是這種實體化的交流化身真那麼不同嗎？機器人真有影響嗎？還是只是建議和信息的質量有影響？來解決這個問題，我們在波斯頓做了一項研究在幾周的時間里，我們把三種介入方式的一種放入人們的家中。一種是你看過的機器人，Autom.一種是一個有同樣觸目屏介面會運行同樣對話的電腦。建議的質量也完全相同。第三種只是筆和紙日誌，因為這是你傳統上開始一項飲食鍛煉計劃典型的介入方式。 我們特別關注的不是人們減少了多少體重而是他們與機器人能維持交流多久。因為挑戰不是減去重量，而是保持重量下降所以你能越長時間與這些介入方式互動，預示著越可能得到長久的成功。所以我看的第一件事就是人們能與這些這三種系統互動多久。結果是人們與機器人的互動明顯的更多即使電腦提供完全相同質量的建議。當人們被要求根據工作同盟的質量打分人們給機器人更高分，他們更信任機器人。(笑聲）當你看情感上的投入，結果更是大不相同。人們給機器人命名給機器人著裝。（笑聲）甚至當最後我們在研究結束后取回機器人時，他們從汽車裡走出，給機器人再見。他們不會對電腦做這些。 最後我想討論的是兒童媒體的未來。我們知道如今孩子們花許多時間在屏幕前，無論是電視，電腦遊戲們還是其它我的兒子們也喜歡屏幕。他們喜歡屏幕，但我想讓他們玩，作為一個母親，我想讓他們玩在真實世界里玩。所以我想向你們展示一個我小組的新項目叫做遊戲時間計算技術。這技術想要把電子媒體中最有趣吸引的東西真實地帶出屏幕來到孩子們真實的世界，擁有現實中遊戲的許多性質。所以這是這種理念的第一個探索-遊戲角色可以是實體的和虛擬的，其中，電子的內容能走出屏幕進入現實然後回去。我喜歡把這想像成這種虛擬現實遊戲的Atari Pong(“乓”，第一台街機遊戲機）。 但是我們可以深入這種理念。如果-(遊戲)内森：它來了，Yay！卡通人物本身能進入你的世界？結果是孩子們很喜歡卡通能變得真實，進入他們的世界當這卡通形象在他們的世界時，他們可以與它建立聯繫，用一種與他們在屏幕里玩完全不同的方式，在現實里與它玩。另一個重要的概念是卡通形象穿越現實的一致性。所以孩子們在現實中做的變化也需要進入虛擬世界。所以這裡，内森把字母A改成了數字2.你可惜想像這些是信號標誌可以給卡通人物特別的能力當他們重返虛擬世界。所以他們把卡通人物送回了那個世界，現在它有了數字能力。 最後，我一直想做的是為孩子們創造一種真正沉浸其中的體驗，他們能感到他們是故事中的一部份，是那經歷中的一部份。我想激發他們的想像力正如我小女孩時觀看星球大戰被啓發那樣。但我想做的更多。我想讓他們能創造那些經歷。我想讓他們確實地能在那些經歷里建立他們的想像力，使那些經歷成為他們自己的。所以我們在遠程呈現和混合現實領域探索了許多理念能夠允許孩子把他們的想法投射在這個空間，在那里，其他孩子可以與之互動，進一步發揮想像。我想找到孩童媒體的新方向能培養創造力，學習能力，和創新能力。我認為這非常非常重要。 所以這是一個新項目。我們邀請了許多孩子進這個空間，他們認為那非常酷。但我可以告訴你們，他們最喜歡的東西，還是機器人。他們最在乎的也是機器人。機器人觸動了我們內心深處的人性。所以無論機器人是幫助我們變得更有創造力，還是幫助我們彼此跨越距離，更加聯結，還是它們是我們可信賴的好幫手幫我們實現我們的個人目標，實現更高更好的自我，對我而言，機器人完全關乎人類。 謝謝。 (掌聲)"
