Talk	en	zh-tw
damon_horowitz	"Power. That is the word that comes to mind. We're the new technologists. We have a lot of data, so we have a lot of power. How much power do we have? Scene from a movie: ""Apocalypse Now"" — great movie. We've got to get our hero, Captain Willard, to the mouth of the Nung River so he can go pursue Colonel Kurtz. The way we're going to do this is fly him in and drop him off. So the scene: the sky is filled with this fleet of helicopters carrying him in. And there's this loud, thrilling music in the background, this wild music. ♫ Dum da ta da dum ♫ ♫ Dum da ta da dum ♫ ♫ Da ta da da ♫ That's a lot of power. That's the kind of power I feel in this room. That's the kind of power we have because of all of the data that we have. Let's take an example. What can we do with just one person's data? What can we do with that guy's data? I can look at your financial records. I can tell if you pay your bills on time. I know if you're good to give a loan to. I can look at your medical records; I can see if your pump is still pumping — see if you're good to offer insurance to. I can look at your clicking patterns. When you come to my website, I actually know what you're going to do already because I've seen you visit millions of websites before. And I'm sorry to tell you, you're like a poker player, you have a tell. I can tell with data analysis what you're going to do before you even do it. I know what you like. I know who you are, and that's even before I look at your mail or your phone. Those are the kinds of things we can do with the data that we have. But I'm not actually here to talk about what we can do. I'm here to talk about what we should do. What's the right thing to do? Now I see some puzzled looks like, ""Why are you asking us what's the right thing to do? We're just building this stuff. Somebody else is using it."" Fair enough. But it brings me back. I think about World War II — some of our great technologists then, some of our great physicists, studying nuclear fission and fusion — just nuclear stuff. We gather together these physicists in Los Alamos to see what they'll build. We want the people building the technology thinking about what we should be doing with the technology. So what should we be doing with that guy's data? Should we be collecting it, gathering it, so we can make his online experience better? So we can make money? So we can protect ourselves if he was up to no good? Or should we respect his privacy, protect his dignity and leave him alone? Which one is it? How should we figure it out? I know: crowdsource. Let's crowdsource this. So to get people warmed up, let's start with an easy question — something I'm sure everybody here has an opinion about: iPhone versus Android. Let's do a show of hands — iPhone. Uh huh. Android. You'd think with a bunch of smart people we wouldn't be such suckers just for the pretty phones. (Laughter) Next question, a little bit harder. Should we be collecting all of that guy's data to make his experiences better and to protect ourselves in case he's up to no good? Or should we leave him alone? Collect his data. Leave him alone. You're safe. It's fine. (Laughter) Okay, last question — harder question — when trying to evaluate what we should do in this case, should we use a Kantian deontological moral framework, or should we use a Millian consequentialist one? Kant. Mill. Not as many votes. (Laughter) Yeah, that's a terrifying result. Terrifying, because we have stronger opinions about our hand-held devices than about the moral framework we should use to guide our decisions. How do we know what to do with all the power we have if we don't have a moral framework? We know more about mobile operating systems, but what we really need is a moral operating system. What's a moral operating system? We all know right and wrong, right? You feel good when you do something right, you feel bad when you do something wrong. Our parents teach us that: praise with the good, scold with the bad. But how do we figure out what's right and wrong? And from day to day, we have the techniques that we use. Maybe we just follow our gut. Maybe we take a vote — we crowdsource. Or maybe we punt — ask the legal department, see what they say. In other words, it's kind of random, kind of ad hoc, how we figure out what we should do. And maybe, if we want to be on surer footing, what we really want is a moral framework that will help guide us there, that will tell us what kinds of things are right and wrong in the first place, and how would we know in a given situation what to do. So let's get a moral framework. We're numbers people, living by numbers. How can we use numbers as the basis for a moral framework? I know a guy who did exactly that. A brilliant guy — he's been dead 2,500 years. Plato, that's right. Remember him — old philosopher? You were sleeping during that class. And Plato, he had a lot of the same concerns that we did. He was worried about right and wrong. He wanted to know what is just. But he was worried that all we seem to be doing is trading opinions about this. He says something's just. She says something else is just. It's kind of convincing when he talks and when she talks too. I'm just going back and forth; I'm not getting anywhere. I don't want opinions; I want knowledge. I want to know the truth about justice — like we have truths in math. In math, we know the objective facts. Take a number, any number — two. Favorite number. I love that number. There are truths about two. If you've got two of something, you add two more, you get four. That's true no matter what thing you're talking about. It's an objective truth about the form of two, the abstract form. When you have two of anything — two eyes, two ears, two noses, just two protrusions — those all partake of the form of two. They all participate in the truths that two has. They all have two-ness in them. And therefore, it's not a matter of opinion. What if, Plato thought, ethics was like math? What if there were a pure form of justice? What if there are truths about justice, and you could just look around in this world and see which things participated, partook of that form of justice? Then you would know what was really just and what wasn't. It wouldn't be a matter of just opinion or just appearances. That's a stunning vision. I mean, think about that. How grand. How ambitious. That's as ambitious as we are. He wants to solve ethics. He wants objective truths. If you think that way, you have a Platonist moral framework. If you don't think that way, well, you have a lot of company in the history of Western philosophy, because the tidy idea, you know, people criticized it. Aristotle, in particular, he was not amused. He thought it was impractical. Aristotle said, ""We should seek only so much precision in each subject as that subject allows."" Aristotle thought ethics wasn't a lot like math. He thought ethics was a matter of making decisions in the here-and-now using our best judgment to find the right path. If you think that, Plato's not your guy. But don't give up. Maybe there's another way that we can use numbers as the basis of our moral framework. How about this: What if in any situation you could just calculate, look at the choices, measure out which one's better and know what to do? That sound familiar? That's a utilitarian moral framework. John Stuart Mill was a great advocate of this — nice guy besides — and only been dead 200 years. So basis of utilitarianism — I'm sure you're familiar at least. The three people who voted for Mill before are familiar with this. But here's the way it works. What if morals, what if what makes something moral is just a matter of if it maximizes pleasure and minimizes pain? It does something intrinsic to the act. It's not like its relation to some abstract form. It's just a matter of the consequences. You just look at the consequences and see if, overall, it's for the good or for the worse. That would be simple. Then we know what to do. Let's take an example. Suppose I go up and I say, ""I'm going to take your phone."" Not just because it rang earlier, but I'm going to take it because I made a little calculation. I thought, that guy looks suspicious. And what if he's been sending little messages to Bin Laden's hideout — or whoever took over after Bin Laden — and he's actually like a terrorist, a sleeper cell. I'm going to find that out, and when I find that out, I'm going to prevent a huge amount of damage that he could cause. That has a very high utility to prevent that damage. And compared to the little pain that it's going to cause — because it's going to be embarrassing when I'm looking on his phone and seeing that he has a Farmville problem and that whole bit — that's overwhelmed by the value of looking at the phone. If you feel that way, that's a utilitarian choice. But maybe you don't feel that way either. Maybe you think, it's his phone. It's wrong to take his phone because he's a person and he has rights and he has dignity, and we can't just interfere with that. He has autonomy. It doesn't matter what the calculations are. There are things that are intrinsically wrong — like lying is wrong, like torturing innocent children is wrong. Kant was very good on this point, and he said it a little better than I'll say it. He said we should use our reason to figure out the rules by which we should guide our conduct, and then it is our duty to follow those rules. It's not a matter of calculation. So let's stop. We're right in the thick of it, this philosophical thicket. And this goes on for thousands of years, because these are hard questions, and I've only got 15 minutes. So let's cut to the chase. How should we be making our decisions? Is it Plato, is it Aristotle, is it Kant, is it Mill? What should we be doing? What's the answer? What's the formula that we can use in any situation to determine what we should do, whether we should use that guy's data or not? What's the formula? There's not a formula. There's not a simple answer. Ethics is hard. Ethics requires thinking. And that's uncomfortable. I know; I spent a lot of my career in artificial intelligence, trying to build machines that could do some of this thinking for us, that could give us answers. But they can't. You can't just take human thinking and put it into a machine. We're the ones who have to do it. Happily, we're not machines, and we can do it. Not only can we think, we must. Hannah Arendt said, ""The sad truth is that most evil done in this world is not done by people who choose to be evil. It arises from not thinking."" That's what she called the ""banality of evil."" And the response to that is that we demand the exercise of thinking from every sane person. So let's do that. Let's think. In fact, let's start right now. Every person in this room do this: think of the last time you had a decision to make where you were worried to do the right thing, where you wondered, ""What should I be doing?"" Bring that to mind, and now reflect on that and say, ""How did I come up that decision? What did I do? Did I follow my gut? Did I have somebody vote on it? Or did I punt to legal?"" Or now we have a few more choices. ""Did I evaluate what would be the highest pleasure like Mill would? Or like Kant, did I use reason to figure out what was intrinsically right?"" Think about it. Really bring it to mind. This is important. It is so important we are going to spend 30 seconds of valuable TEDTalk time doing nothing but thinking about this. Are you ready? Go. Stop. Good work. What you just did, that's the first step towards taking responsibility for what we should do with all of our power. Now the next step — try this. Go find a friend and explain to them how you made that decision. Not right now. Wait till I finish talking. Do it over lunch. And don't just find another technologist friend; find somebody different than you. Find an artist or a writer — or, heaven forbid, find a philosopher and talk to them. In fact, find somebody from the humanities. Why? Because they think about problems differently than we do as technologists. Just a few days ago, right across the street from here, there was hundreds of people gathered together. It was technologists and humanists at that big BiblioTech Conference. And they gathered together because the technologists wanted to learn what it would be like to think from a humanities perspective. You have someone from Google talking to someone who does comparative literature. You're thinking about the relevance of 17th century French theater — how does that bear upon venture capital? Well that's interesting. That's a different way of thinking. And when you think in that way, you become more sensitive to the human considerations, which are crucial to making ethical decisions. So imagine that right now you went and you found your musician friend. And you're telling him what we're talking about, about our whole data revolution and all this — maybe even hum a few bars of our theme music. ♫ Dum ta da da dum dum ta da da dum ♫ Well, your musician friend will stop you and say, ""You know, the theme music for your data revolution, that's an opera, that's Wagner. It's based on Norse legend. It's Gods and mythical creatures fighting over magical jewelry."" That's interesting. Now it's also a beautiful opera, and we're moved by that opera. We're moved because it's about the battle between good and evil, about right and wrong. And we care about right and wrong. We care what happens in that opera. We care what happens in ""Apocalypse Now."" And we certainly care what happens with our technologies. We have so much power today, it is up to us to figure out what to do, and that's the good news. We're the ones writing this opera. This is our movie. We figure out what will happen with this technology. We determine how this will all end. Thank you. (Applause)"	權力。這就是在我腦海呈現的詞語。我們是新的科技專家。我們有很多數據資料，所以我們有很多權力。我們究竟有幾大威力？這是從電影＜現代啟示錄＞其中一幕—很棒的電影。我們必須讓我們的英雄，韋勒上尉，到儂河的河口去追尋寇茲上校。我們要帶他飛往目的地然後讓他前行。場景如下：天空佈滿了運載他的直升機艦隊。附帶這個響亮，驚險的背景音樂，這瘋狂的音樂。♫ 音樂聲 ♫♫ 音樂聲 ♫♫ 音樂聲 ♫這是強勁的威力。這就是在我在這個房間感覺到的力量。這就我們擁有的一種力量，因為我們有所有的資料數據。 讓我們舉一個例子。若我們有著一個人的資料數據,我們可以用它做什麼？我們可以用此人的資料做什麼？我可以看看你的財務記錄。我可知道你是否按時支付帳單。我會知道應否給你予貸款。我可以看看你的醫療記錄，看看你的身體機能是否運行如常—看看應否給你推銷健康保險。我可以看看你的點擊模式。當你來到我的網站，其實我已經知道你要做的事情，因為我已經看過你之前到過的數百萬個網站。而且我很抱歉地告訴你，你像一個撲克玩家，你有一個「偷雞」破綻。我可以使用分析你的數據來知道你的下一步。我知道你的喜嗜。我知道你是誰。而且我還未看你的電郵或手機。 這都我們可以用數據達到的事情。但其實我不是來談我們能夠做些什麼。我是來談談我們應該做什麼。什麼是正確的事情？ 我看到你們有些困惑的樣子像在問：「你為何問我們應該做什麼?我們只是建造這種東西供給別人所用。」合理的。但它使我回到這一點。我想到第二次世界大戰 —我們有一些重要的技術人員，我們的一些偉大的物理學家，研究核裂變和核聚變 —只是核子的科學。我們聚集這些物理學家在洛斯阿拉莫斯國家實驗室，看看他們將構建些什麼。我們要建設技術的人想想我們應該用技術建做些什麼。 那麼，我們應該用那傢伙的數據做什麼？我們是否應該收集它，薈集它，用來使他有更好的上網體驗？用來使我們可以賺錢？用來保護我們自己，若假他實行一些壞主意？或我們應該尊重他的隱私，保護他的尊嚴，讓他獨自自我？我們該怎樣?我們應該如何看著辦？ 我知道：眾包。讓我們用眾包的方法解決問題。好，為了讓你們做好準備就绪，讓我們先從一個簡單的問題開始 —一個我敢肯定在座每個人都有異議的問題：iPhone 抑或 Android電話。讓我們舉手 — iPhone。嗯。Android。哼,還以為一班聰明人我們不會出現這種只顧漂亮手機的人。接下來的問題，有點更困難。我們應否該收集那傢伙所有的資料數據使他有更好的上網體驗並用來保護我們自己若假他實行一些壞主意？或我們應該讓他獨自自我？收集他的資料數據。讓他獨自自我。你是安全的。沒有問題。好吧，最後一個問題—更困難的問題。當我們在這種情況下試圖評估我們應該如何，我們應否使用康德的道義論的道德框架，或我們應否使用莉恩結果主義的道德框架，康德的。莉恩的。比上一次少表決。是的，這是一個可怕的結果。可怕，因為我們對手機的意見比我們對用來指導我們決定的道德框架的意見更強。 如果我們沒有一個道德框架，我們怎麼知道用我們所有的力量該怎麼做？我們對關於手機的操作系統知道更十分多，但我們真正需要的是一個道德的操作系統。什麼是道德的操作系統?我們都知道是,非。你做一些好的事會有好的感覺，你做一些錯事會有不好的感覺。我們的父母教導我們：讚美好的，罵壞的。但是，我們究境如何找出什麼是正確的和錯誤的？而每過一天又一天，我們用我們的方法權衡。也許我們只要按照我們的膽量。也許我們需要投票 - 我們的人群的來源。或者，也許我們用篙撐 —問問法律部門，看他們說些什麼。換句話說，它是一種隨機的，即席的,的權衡方法。也或許，若我們想在基礎上更有把握，我們真正需要的是一種道德框架，有助於引導我們到那裡，指導我們從一開始什麼樣是正確和錯誤的,以及指導我們在特定情況下該怎麼辦。 因此，讓我們弄一個道德框架。我們數字的人，生活於數字裡。我們如何使用數字作為道德框架的基礎？我知道一個傢伙正恰恰如此辦，一個傑出的傢伙 —他已經死了2500年。不錯, 是柏拉圖。老哲學家—記得他嗎？你在那課時正在睡覺。柏拉圖，他有很多和我們相同的問題。他憂慮着對與錯。他想知道什麼是正義的。但他擔心，似乎我們所做的只是交流有關這一點的意見。公說公有理。 婆說婆有理。雙方首都非常有說服力。來來回回; 沒有結果。我不想要意見，我想要知識。我想知道公義的真相 —像我們在數學有的真理。在數學，我們知道客觀的事實。例如一個數字，任何數字 — 「二」。最喜愛的數字。我愛這個數字。有關於「二」的真理。如果你有兩個東西，你加兩個，你會得到四個。這是真的，無論你在說什麼事情。這是一個有關「二」客觀的真理，抽象的形式。當你有兩個東西 — 兩隻眼睛，兩隻耳朵，兩個鼻子，只有兩個突起的物體 —所有參與「二」的形式。他們都參與了「二」。「二」是他們所有。因此，它不是一個見仁見智的局勢。 如果，柏拉圖在想，道德是好比數學？假如有一個純粹的正義形式呢？如果公義有真理，你可以看看周圍環顧這個世界，看看哪些東西參與，參加這種形式的正義？那你便會知道什麼是真正公正，什麼不是。這不會是只有關意見或表面的問題。這是一個驚人的遠見。試想想,這一點。這是如何宏偉, 如何雄心勃勃。這是如我們的雄心勃勃。他要解決道德。他要客觀真理。如果你這樣思想，你便擁有一個柏拉圖主義的道德框架。 如果你不認為這樣，那，你在歷史上西方哲學史便有很多支持者，因為整齊的想法 —- 眾所週知，人們會批評。尤其是亞里士多德，他便不覺得有趣。他認為這是不切實際的。亞里士多德說，「我們只應該尋求每個主題允許我們能夠尋求的問題。」亞里士多德不認為道德好比數學。他認為道德是一個在此時此地用我們最好的判斷決策的問題,來找到正確的道路。如果你這樣認為，柏拉圖不是你的同道。但不要放棄。也許有另一種方式，我們可以使用數字作為我們道德框架的依據。 這樣如何：如果在任何情況下你可以計算，看看選擇，測算出哪一個更好，知道該怎麼辦？這聽起來很熟悉？這是一個功利主義的道德框架。穆勒是便主張這一點 —好好的傢伙 —而且只死了200年。所以功利主義的基礎 —我敢肯定你會熟悉。至少剛才那三個舉手贊同穆勒的人對他熟悉。現在讓我說說該怎麼樣。若果我說道德，或某一件擁有道德的東西,只不過是擴大快樂限度以及減少痛苦？這種思想方式便有一些固定性。它不好比一些抽象的形式。這只是一個後果的問題。你只要看看後果，看看總體而言，它是好還是壞。這便簡單。我們知道該怎麼做。 讓我們舉一個例子。假如我說，「我要拿帶走你的手機。」不是因為它剛才響過，而是因為我做了一個小小的計算。我想，那傢伙看起來有可疑。如果他一直有消息發送到拉登藏身之處 —或誰接手拉登之位 —或者他實際上像個恐怖分子，臥底細胞。我會去了解，當我查出了，我將會防止他構成的巨大損害。具有很高的實用工具，以防止該傷害。這相比於小小不便的痛苦—因為這將會是個令人尷尬的時候,當我在他的電話，看到他竟然沉迷於Farmville遊戲 —這是不堪相比於看他手機的價值。如果你這樣認為，這是一個功利思想的選擇。 但也許你覺得都不應該是這樣。也許你認為，這是他的電話。拿他的電話看是不對，因為他是一個人，他有他的權利和尊嚴，我們不能干擾。他有自主權。什麼計算根本不緊要。有些事情是一件固的壞事 —例如說謊是不對的，例如虐待無辜的孩子是錯的。康德於這一點非常滿意，而且他說這一點比我會說得較好。他說我們應該用我們的原因找出規律，應該以這種方式引導我們的行為。然後，我們有責任遵循這些規則。這不是一個計算的問題。 因此，讓我們停下來。我們就在它的要緊點，在這哲學叢林內。而這任其發展了千百年，因為這些都是難以回答的問題，而我只有15分鐘。因此，讓我們切入正題。我們應該如何營造我們的決策？是柏拉圖，亞里士多德，是康德，抑或是密爾？我們應該怎麼做？答案該是什麼？什麼是我們可以在任何情況下都使用的公式,來確定了我們應該做的，我們是否應該使用那傢伙的數據?有什麼公式？根本沒有一個公式。沒有一個簡單的答案。 道德是艱難的。道德要求思想。這是不舒服的地帶。我知道，在我的職業生涯中我花了很多時間在人工智能上，試圖建立一些可以替我們做這些思想的機器，給我們一些答案。但它們不能。你不能拿人的思想把它輸入機器。那些是我們要自己做。令人高興的是，我們不是機器，我們可以做到這一點。我們不僅可以思想，我們必須要思想。漢娜阿倫特說:「可悲的是，這個世界最邪惡的事不是由選擇作惡的人所做。而它是產生於不思想。」這就是她所謂的「平庸的邪惡」。而根據這一要求，是我們要要求每一個思維健全的人鍛煉思想。 因此，讓我們這樣做。讓我們思考。事實上，我們現在開始。每個人在這個房間裡要這樣做：想起你上次要做出決定，當你擔心是否做正確的決定，你在想，「我應該怎樣做？」想想。反思一下並問，「我是怎麼作出這個決定？我做了什麼？難道我跟著我的直覺？是否有人投票呢？還是我舉法律？」或者，現在我們有更多些選擇。「我是否會使用穆勒的最高快樂來評價決定？或像康德，我是否會使用因由弄清楚什麼是本質？」真正想想看。這一點很重要。它是如此的重要，我們將要花30秒寶貴的TEDTalk時間什麼也不做，並去思考這一點。你準備好嗎？開始。 停止。好。你剛才做的，這就用是我們所有力量的責任,承擔對於我們應該做的第一步。 現在，試試這下一個步驟。去找一個朋友，向他們解釋你如何作出這個決定。不是現在。等到我談話結束。可以在午餐談談。而且不要只是找另一個技師朋友;找一個與你不同的人。找一個藝術家或作家 —或者，上天保佑，找到一個哲學家交談。或者，找一個從事文科學的人。為什麼？因為他們思考問題不同於我們做技術的人。就在數天前，從這裡在對面街，有數百人聚集在一起。這是技術人員和人道主義者在那個BiblioTech大會議。他們聚集在一起，因為技術人員想了解從文人會有什麼樣的視角遠景。有人從谷歌與做比較文學的人交談。你在考慮17世紀法國戲劇的相關性 —如何會對風險投資有影響？這是有趣的。這是一個不同的思維方式。而當你以這種方式思想，你變得更加對人的考慮敏感，這是對決策倫理至關重要的。 所以現在想想你去找你的音樂家朋友。告訴他我們在說什麼，有關我們整個數據革命的一切 —甚至哼了幾節我們的主題音樂。♫音樂♫那麼，你的音樂家朋友會對你說，「你要知道，為你數據的革命的主題音樂,是一部歌劇，是瓦格納的。它是基於北歐傳說。是神和神話動物爭奪神奇首飾。」那很有意思。當然，它也是一個美麗的歌劇。而我們對歌劇感動。我們很感動，因為它是對善惡之間的戰鬥，對與錯的戰鬥。而我們是關心是與非。我們關心在歌劇會發生什麼。我們關心在會發生什麼。我們當然關心我們的技術會發生什麼。 我們今天有這麼大的權力，它是由我們來搞清楚怎樣做。這就是好消息。我們是寫這部歌劇的作家。這是我們的電影。我們會弄清楚這種技術將會發生什麼。我們確定全部如何將結束。 謝謝。 (掌聲)
