Talk	en	zh-tw
dennis_hong_making_a_car_for_blind_drivers	"Many believe driving is an activity solely reserved for those who can see. A blind person driving a vehicle safely and independently was thought to be an impossible task, until now. Hello, my name is Dennis Hong, and we're bringing freedom and independence to the blind by building a vehicle for the visually impaired. So before I talk about this car for the blind, let me briefly tell you about another project that I worked on called the DARPA Urban Challenge. Now this was about building a robotic car that can drive itself. You press start, nobody touches anything, and it can reach its destination fully autonomously. So in 2007, our team won half a million dollars by placing third place in this competition. So about that time, the National Federation of the Blind, or NFB, challenged the research committee about who can develop a car that lets a blind person drive safely and independently. We decided to give it a try, because we thought, ""Hey, how hard could it be?"" We have already an autonomous vehicle. We just put a blind person in it and we're done, right? (Laughter) We couldn't have been more wrong. What NFB wanted was not a vehicle that can drive a blind person around, but a vehicle where a blind person can make active decisions and drive. So we had to throw everything out the window and start from scratch. So to test this crazy idea, we developed a small dune buggy prototype vehicle to test the feasibility. And in the summer of 2009, we invited dozens of blind youth from all over the country and gave them a chance to take it for a spin. It was an absolutely amazing experience. But the problem with this car was it was designed to only be driven in a very controlled environment, in a flat, closed-off parking lot — even the lanes defined by red traffic cones. So with this success, we decided to take the next big step, to develop a real car that can be driven on real roads. So how does it work? Well, it's a rather complex system, but let me try to explain it, maybe simplify it. So we have three steps. We have perception, computation and non-visual interfaces. Now obviously the driver cannot see, so the system needs to perceive the environment and gather information for the driver. For that, we use an initial measurement unit. So it measures acceleration, angular acceleration — like a human ear, inner ear. We fuse that information with a GPS unit to get an estimate of the location of the car. We also use two cameras to detect the lanes of the road. And we also use three laser range finders. The lasers scan the environment to detect obstacles — a car approaching from the front, the back and also any obstacles that run into the roads, any obstacles around the vehicle. So all this vast amount of information is then fed into the computer, and the computer can do two things. One is, first of all, process this information to have an understanding of the environment — these are the lanes of the road, there's the obstacles — and convey this information to the driver. The system is also smart enough to figure out the safest way to operate the car. So we can also generate instructions on how to operate the controls of the vehicle. But the problem is this: How do we convey this information and instructions to a person who cannot see fast enough and accurate enough so he can drive? So for this, we developed many different types of non-visual user interface technology. So starting from a three-dimensional ping sound system, a vibrating vest, a click wheel with voice commands, a leg strip, even a shoe that applies pressure to the foot. But today we're going to talk about three of these non-visual user interfaces. Now the first interface is called a DriveGrip. So these are a pair of gloves, and it has vibrating elements on the knuckle part so you can convey instructions about how to steer — the direction and the intensity. Another device is called SpeedStrip. So this is a chair — as a matter of fact, it's actually a massage chair. We gut it out, and we rearrange the vibrating elements in different patterns, and we actuate them to convey information about the speed, and also instructions how to use the gas and the brake pedal. So over here, you can see how the computer understands the environment, and because you cannot see the vibration, we actually put red LED's on the driver so that you can see what's happening. This is the sensory data, and that data is transferred to the devices through the computer. So these two devices, DriveGrip and SpeedStrip, are very effective. But the problem is these are instructional cue devices. So this is not really freedom, right? The computer tells you how to drive — turn left, turn right, speed up, stop. We call this the ""backseat-driver problem."" So we're moving away from the instructional cue devices, and we're now focusing more on the informational devices. A good example for this informational non-visual user interface is called AirPix. So think of it as a monitor for the blind. So it's a small tablet, has many holes in it, and compressed air comes out, so it can actually draw images. So even though you are blind, you can put your hand over it, you can see the lanes of the road and obstacles. Actually, you can also change the frequency of the air coming out and possibly the temperature. So it's actually a multi-dimensional user interface. So here you can see the left camera, the right camera from the vehicle and how the computer interprets that and sends that information to the AirPix. For this, we're showing a simulator, a blind person driving using the AirPix. This simulator was also very useful for training the blind drivers and also quickly testing different types of ideas for different types of non-visual user interfaces. So basically that's how it works. So just a month ago, on January 29th, we unveiled this vehicle for the very first time to the public at the world-famous Daytona International Speedway during the Rolex 24 racing event. We also had some surprises. Let's take a look. (Music) (Video) Announcer: This is an historic day in January. He's coming up to the grandstand, fellow Federationists. (Cheering) (Honking) There's the grandstand now. And he's [unclear] following that van that's out in front of him. Well there comes the first box. Now let's see if Mark avoids it. He does. He passes it on the right. Third box is out. The fourth box is out. And he's perfectly making his way between the two. He's closing in on the van to make the moving pass. Well this is what it's all about, this kind of dynamic display of audacity and ingenuity. He's approaching the end of the run, makes his way between the barrels that are set up there. (Honking) (Applause) Dennis Hong: I'm so happy for you. Mark's going to give me a ride back to the hotel. Mark Riccobono: Yes. (Applause) DH: So since we started this project, we've been getting hundreds of letters, emails, phone calls from people from all around the world. Letters thanking us, but sometimes you also get funny letters like this one: ""Now I understand why there is Braille on a drive-up ATM machine."" (Laughter) But sometimes — (Laughter) But sometimes I also do get — I wouldn't call it hate mail — but letters of really strong concern: ""Dr. Hong, are you insane, trying to put blind people on the road? You must be out of your mind."" But this vehicle is a prototype vehicle, and it's not going to be on the road until it's proven as safe as, or safer than, today's vehicle. And I truly believe that this can happen. But still, will the society, would they accept such a radical idea? How are we going to handle insurance? How are we going to issue driver's licenses? There's many of these different kinds of hurdles besides technology challenges that we need to address before this becomes a reality. Of course, the main goal of this project is to develop a car for the blind. But potentially more important than this is the tremendous value of the spin-off technology that can come from this project. The sensors that are used can see through the dark, the fog and rain. And together with this new type of interfaces, we can use these technologies and apply them to safer cars for sighted people. Or for the blind, everyday home appliances — in the educational setting, in the office setting. Just imagine, in a classroom a teacher writes on the blackboard and a blind student can see what's written and read using these non-visual interfaces. This is priceless. So today, the things I've showed you today, is just the beginning. Thank you very much. (Applause)"	"很多人認為開車是一項只有明眼人才能從事的活動讓全盲的人安全地獨自開車是不可能的任務，直到現在哈囉，我是丹尼斯．洪（音譯）為視力受損人士造車，我們可以帶給他們獨立與自由 在我開始講為盲人打造的這輛車以前我想先簡單的分享一下我先前的另一個計畫叫美國國防先進研究計劃局(DARPA)都市挑戰是要造出一輛全機械化可以自動駕駛的汽車按下""開始""，然後什麼都不碰車子就會自動開往目的地在2007年，我們團隊贏得五十萬美元因為在這項競賽裡得了第三名所以那時候全國盲人聯合會(NFB)對研究委員們提出挑戰看誰能夠開發出能讓盲人安全地獨自駕駛的汽車我們決定試試看因為我們覺得這應該不大難啊既然已經有可以自動駕駛的汽車只要讓盲人坐進去不就大功告成了嗎？（笑）結果我們完全搞錯了他們要的不是能帶著盲人四處轉轉的載具而是能讓盲人即時做出判斷來駕駛的車所以我們得把一切都拋諸腦後重頭開始 為了測試這個瘋狂的想法我們做出一輛小型的沙灘車原型車來了解計畫是否可行在2009年的夏天我們邀請數十個全國各地的失明青年給他們機會上車去試試那經驗超棒的問題是這車子的設計，只能在極度受到控制的環境下駕駛像是平坦無人的停車場連車道都是用紅色三角錐圍起來 這項成功促使我們決定更邁進一步研發出能在真實道路上駕駛的汽車那又是怎麼做到的呢？嗯，這系統有點複雜但我會試著用最簡單的話來解釋一共分成三部份也就是知覺、計算和非視覺介面既然駕駛人看不見這個系統就要感覺周遭環境的變化並為駕駛人蒐集資訊因此，我們使用初步測量單元來測量加速度、角加速度就像人類耳朵和內耳的作用一樣這些訊息和GPS單元結合來估計汽車目前位置我們也用了兩架攝影機來偵測道路兩側還有三台雷射測距儀用來掃描周遭環境的障礙物像是前方和後方來車進入道路的障礙物以及在車子附近的其他障礙物 這些資料全部都會傳進電腦裡然後電腦會作兩件事首先，電腦會處理所有資訊來了解周遭環境道路有幾線，哪裡有障礙物然後傳達給駕駛人這系統聰明到可以找出最安全的駕駛方式所以我們還能產生指引來指導駕駛人如何控制汽車但問題來了，我們要怎樣傳達這些資訊和指引給看不見的人們又快又準，讓他們可以開車呢？所以，我們發展出許多不同的非視覺使用介面科技首先是三維聲響系統還有振動背心聲控點擊輪，大腿繫帶甚至是可以在腳掌上施壓的鞋子但今天我們要講的是以下三種非視覺使用介面 首先是DriveGrip（駕駛握把）那是一雙手套在指關節的部份有振動元件就可以傳達操作方向盤的指示要往哪個方向，轉多少另外一個裝置是SpeedStrip這是一張椅子，事實上是一張按摩椅我們把它拆開，再把振動元件排列組合成別的樣式啟動以後，利用它們傳達速度的訊息還有踩油門跟煞車踏板的指引從這裡你可以看到電腦怎樣了解周遭環境的因為肉眼看不見振動所以我們放了紅色的LED，讓駕駛可以知道發生什麼事這些都是感應元件輸出的資料之後會透過電腦傳送到裝置上 DriveGrip 和 SpeedStrip這兩個裝置效率很高但問題是這些都是引導裝置並不是真正的自由駕駛，對吧？是由電腦告訴你該怎麼開車左轉、右轉、加速、煞車我們稱之為「後座駕駛問題」所以，我們得把這些引導裝置擺在一邊然後把精力放在訊息提供裝置上一個非視覺訊息提供使用者介面的例子是AirPix這就像是盲人的螢幕就是一個小面板，上面有很多小洞壓縮空氣會從洞裡噴出來所以能夠描繪圖像即使眼睛看不見，把手放在板子上也可以看到車道和障礙物而且，還可以改變空氣噴出的頻率甚至溫度這其實是一個多維度的使用者介面在這裡你可以看到汽車的左右攝影機鏡頭還有電腦如何解讀並傳送訊息到AirPix為了這個，我們弄了個模擬器讓盲人在駕駛時使用AirPix模擬器對訓練盲人駕駛也很有用還可以快速測試不同的點子不同的非視覺使用者介面這模擬器大概就是這樣 大約一個月前也就是一月二十九號我們第一次公開展示這輛車是在全球知名的德通那國際賽車場的勞力士24車賽裡我們也準備了一些驚喜，讓大家來看看 （音樂） （影片）司儀：這是歷史性的一天他正接近主看台，跟著Federistas （歡呼） （鳴喇叭） 他到主看台了而且正跟著前方那輛廂型車然後第一個箱子出現讓我們看看馬克能不能避開它們他躲過了，閃到右邊去第三第四個箱子也出現了他完美的從中間穿過接近廂型車然後超車就是這麼回事勇敢和創造力的展現現在他正接近終點躲開那些跑道上的桶子 （鳴喇叭） （鼓掌） 丹尼斯：我好高興馬克會載我回旅館 對 （鼓掌） 丹尼斯：自從我們開始這項計畫以來接到數以百計的信件、電子郵件和電話從世界各地來的感謝信，但有時候會收到一些有趣的像是""我現在知道為什麼得來速提款機上會有點字了""（眾笑）但有時候（眾笑）有時候我也會收到不能說是黑特信但卻表示強烈關注的""洪博士你瘋了嗎讓盲人開車上路？你一定是發瘋了""但這輛車其實只是原型車也不會真正上路直到確定它跟縣在的車輛一樣安全，甚至更安全我真的相信有一天這回成真 但是，社會大眾會接受這樣的想法嗎？我們該怎樣處理保險？怎樣發駕照？除了技術挑戰以外，還有很多困難必須在理想成真以前面對當然，這計畫的主要目標是發展盲人用汽車但比這個更有潛力的是相關科技的龐大價值從這個計畫中誕生感應器能穿透黑暗大霧和雨加上新式介面我們可以將這些科技應用在給明眼人開的車上，增加安全性或者給盲人，用在日常生活中在學校環境或辦公室裡你想，老師在教室裡的黑板上寫了東西然後盲人學生可以看見老師寫的東西，並讀出來正是透過這些非視覺介面這是無價之寶因此，我今天講得這些，只是一個開端而已 非常感謝大家 （鼓掌）"
