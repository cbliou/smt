Talk	en	zh-tw
pw_singer_on_robots_of_war	"I thought I'd begin with a scene of war. There was little to warn of the danger ahead. The Iraqi insurgent had placed the IED, an Improvised Explosive Device, along the side of the road with great care. By 2006, there were more than 2,500 of these attacks every single month, and they were the leading cause of casualties among American soldiers and Iraqi civilians. The team that was hunting for this IED is called an EOD team— Explosives Ordinance Disposal—and they're the pointy end of the spear in the American effort to suppress these roadside bombs. Each EOD team goes out on about 600 of these bomb calls every year, defusing about two bombs a day. Perhaps the best sign of how valuable they are to the war effort, is that the Iraqi insurgents put a $50,000 bounty on the head of a single EOD soldier. Unfortunately, this particular call would not end well. By the time the soldier advanced close enough to see the telltale wires of the bomb, it exploded in a wave of flame. Now, depending how close you are and how much explosive has been packed into that bomb, it can cause death or injury. You have to be as far as 50 yards away to escape that. The blast is so strong it can even break your limbs, even if you're not hit. That soldier had been on top of the bomb. And so when the rest of the team advanced they found little left. And that night the unit's commander did a sad duty, and he wrote a condolence letter back to the United States, and he talked about how hard the loss had been on his unit, about the fact that they had lost their bravest soldier, a soldier who had saved their lives many a time. And he apologized for not being able to bring them home. But then he talked up the silver lining that he took away from the loss. ""At least,"" as he wrote, ""when a robot dies, you don't have to write a letter to its mother."" That scene sounds like science fiction, but is battlefield reality already. The soldier in that case was a 42-pound robot called a PackBot. The chief's letter went, not to some farmhouse in Iowa like you see in the old war movies, but went to the iRobot Company, which is named after the Asimov novel and the not-so-great Will Smith movie, and... um... (Laughter)... if you remember that in that fictional world, robots started out carrying out mundane chores, and then they started taking on life-and-death decisions. That's a reality we face today. What we're going to do is actually just flash a series of photos behind me that show you the reality of robots used in war right now or already at the prototype stage. It's just to give you a taste. Another way of putting it is you're not going to see anything that's powered by Vulcan technology, or teenage wizard hormones or anything like that. This is all real. So why don't we go ahead and start those pictures. Something big is going on in war today, and maybe even the history of humanity itself. The U.S. military went into Iraq with a handful of drones in the air. We now have 5,300. We went in with zero unmanned ground systems. We now have 12,000. And the tech term ""killer application"" takes on new meaning in this space. And we need to remember that we're talking about the Model T Fords, the Wright Flyers, compared to what's coming soon. That's where we're at right now. One of the people that I recently met with was an Air Force three-star general, and he said basically, where we're headed very soon is tens of thousands of robots operating in our conflicts, and these numbers matter, because we're not just talking about tens of thousands of today's robots, but tens of thousands of these prototypes and tomorrow's robots, because of course, one of the things that's operating in technology is Moore's Law, that you can pack in more and more computing power into those robots, and so flash forward around 25 years, if Moore's Law holds true, those robots will be close to a billion times more powerful in their computing than today. And so what that means is the kind of things that we used to only talk about at science fiction conventions like Comic-Con have to be talked about in the halls of power and places like the Pentagon. A robots revolution is upon us. Now, I need to be clear here. I'm not talking about a revolution where you have to worry about the Governor of California showing up at your door, a la the Terminator. (Laughter) When historians look at this period, they're going to conclude that we're in a different type of revolution: a revolution in war, like the invention of the atomic bomb. But it may be even bigger than that, because our unmanned systems don't just affect the ""how"" of war-fighting, they affect the ""who"" of fighting at its most fundamental level. That is, every previous revolution in war, be it the machine gun, be it the atomic bomb, was about a system that either shot faster, went further, had a bigger boom. That's certainly the case with robotics, but they also change the experience of the warrior and even the very identity of the warrior. Another way of putting this is that mankind's 5,000-year-old monopoly on the fighting of war is breaking down in our very lifetime. I've spent the last several years going around meeting with all the players in this field, from the robot scientists to the science fiction authors who inspired them to the 19-year-old drone pilots who are fighting from Nevada, to the four-star generals who command them, to even the Iraqi insurgents who they are targeting and what they think about our systems, and what I found interesting is not just their stories, but how their experiences point to these ripple effects that are going outwards in our society, in our law and our ethics, etc. And so what I'd like to do with my remaining time is basically flesh out a couple of these. So the first is that the future of war, even a robotics one, is not going to be purely an American one. The U.S. is currently ahead in military robotics right now, but we know that in technology there's no such thing as a permanent first move or advantage. In a quick show of hands, how many people in this room still use Wang Computers? (Laughter) It's the same thing in war. The British and the French invented the tank. The Germans figured out how to use it right, and so what we have to think about for the U.S. is that we are ahead right now, but you have 43 other countries out there working on military robotics, and they include all the interesting countries like Russia, China, Pakistan, Iran. And this raises a bigger worry for me. How do we move forward in this revolution given the state of our manufacturing and the state of our science and mathematics training in our schools? Or another way of thinking about this is, what does it mean to go to war increasingly with soldiers whose hardware is made in China and software is written in India? But just as software has gone open-source, so has warfare. Unlike an aircraft carrier or an atomic bomb, you don't need a massive manufacturing system to build robotics. A lot of it is off the shelf. A lot of it's even do-it-yourself. One of those things you just saw flashed before you was a raven drone, the handheld tossed one. For about a thousand dollars, you can build one yourself, equivalent to what the soldiers use in Iraq. That raises another wrinkle when it comes to war and conflict. Good guys might play around and work on these as hobby kits, but so might bad guys. This cross between robotics and things like terrorism is going to be fascinating and even disturbing, and we've already seen it start. During the war between Israel, a state, and Hezbollah, a non-state actor, the non-state actor flew four different drones against Israel. There's already a jihadi website that you can go on and remotely detonate an IED in Iraq while sitting at your home computer. And so I think what we're going to see is two trends take place with this. First is, you're going to reinforce the power of individuals against governments, but then the second is that we are going to see an expansion in the realm of terrorism. The future of it may be a cross between al Qaeda 2.0 and the next generation of the Unabomber. And another way of thinking about this is the fact that, remember, you don't have to convince a robot that they're gonna receive 72 virgins after they die to convince them to blow themselves up. But the ripple effects of this are going to go out into our politics. One of the people that I met with was a former Assistant Secretary of Defense for Ronald Reagan, and he put it this way: ""I like these systems because they save American lives, but I worry about more marketization of wars, more shock-and-awe talk, to defray discussion of the costs. People are more likely to support the use of force if they view it as costless."" Robots for me take certain trends that are already in play in our body politic, and maybe take them to their logical ending point. We don't have a draft. We don't have declarations of war anymore. We don't buy war bonds anymore. And now we have the fact that we're converting more and more of our American soldiers that we would send into harm's way into machines, and so we may take those already lowering bars to war and drop them to the ground. But the future of war is also going to be a YouTube war. That is, our new technologies don't merely remove humans from risk. They also record everything that they see. So they don't just delink the public: they reshape its relationship with war. There's already several thousand video clips of combat footage from Iraq on YouTube right now, most of it gathered by drones. Now, this could be a good thing. It could be building connections between the home front and the war front as never before. But remember, this is taking place in our strange, weird world, and so inevitably the ability to download these video clips to, you know, your iPod or your Zune gives you the ability to turn it into entertainment. Soldiers have a name for these clips. They call it war porn. The typical one that I was sent was an email that had an attachment of video of a Predator strike taking out an enemy site. Missile hits, bodies burst into the air with the explosion. It was set to music. It was set to the pop song ""I Just Want To Fly"" by Sugar Ray. This ability to watch more but experience less creates a wrinkle in the public's relationship with war. I think about this with a sports parallel. It's like the difference between watching an NBA game, a professional basketball game on TV, where the athletes are tiny figures on the screen, and being at that basketball game in person and realizing what someone seven feet really does look like. But we have to remember, these are just the clips. These are just the ESPN SportsCenter version of the game. They lose the context. They lose the strategy. They lose the humanity. War just becomes slam dunks and smart bombs. Now the irony of all this is that while the future of war may involve more and more machines, it's our human psychology that's driving all of this, it's our human failings that are leading to these wars. So one example of this that has big resonance in the policy realm is how this plays out on our very real war of ideas that we're fighting against radical groups. What is the message that we think we are sending with these machines versus what is being received in terms of the message. So one of the people that I met was a senior Bush Administration official, who had this to say about our unmanning of war: ""It plays to our strength. The thing that scares people is our technology."" But when you go out and meet with people, for example in Lebanon, it's a very different story. One of the people I met with there was a news editor, and we're talking as a drone is flying above him, and this is what he had to say. ""This is just another sign of the coldhearted cruel Israelis and Americans, who are cowards because they send out machines to fight us. They don't want to fight us like real men, but they're afraid to fight, so we just have to kill a few of their soldiers to defeat them."" The future of war also is featuring a new type of warrior, and it's actually redefining the experience of going to war. You can call this a cubicle warrior. This is what one Predator drone pilot described of his experience fighting in the Iraq War while never leaving Nevada. ""You're going to war for 12 hours, shooting weapons at targets, directing kills on enemy combatants, and then you get in the car and you drive home and within 20 minutes, you're sitting at the dinner table talking to your kids about their homework."" Now, the psychological balancing of those experiences is incredibly tough, and in fact those drone pilots have higher rates of PTSD than many of the units physically in Iraq. But some have worries that this disconnection will lead to something else, that it might make the contemplation of war crimes a lot easier when you have this distance. ""It's like a video game,"" is what one young pilot described to me of taking out enemy troops from afar. As anyone who's played Grand Theft Auto knows, we do things in the video world that we wouldn't do face to face. So much of what you're hearing from me is that there's another side to technologic revolutions, and that it's shaping our present and maybe will shape our future of war. Moore's Law is operative, but so's Murphy's Law. The fog of war isn't being lifted. The enemy has a vote. We're gaining incredible new capabilities, but we're also seeing and experiencing new human dilemmas. Now, sometimes these are just ""oops"" moments, which is what the head of a robotics company described it, you just have ""oops"" moments. Well, what are ""oops"" moments with robots in war? Well, sometimes they're funny. Sometimes, they're like that scene from the Eddie Murphy movie ""Best Defense,"" playing out in reality, where they tested out a machine gun-armed robot, and during the demonstration it started spinning in a circle and pointed its machine gun at the reviewing stand of VIPs. Fortunately the weapon wasn't loaded and no one was hurt, but other times ""oops"" moments are tragic, such as last year in South Africa, where an anti-aircraft cannon had a ""software glitch,"" and actually did turn on and fired, and nine soldiers were killed. We have new wrinkles in the laws of war and accountability. What do we do with things like unmanned slaughter? What is unmanned slaughter? We've already had three instances of Predator drone strikes where we thought we got bin Laden, and it turned out not to be the case. And this is where we're at right now. This is not even talking about armed, autonomous systems with full authority to use force. And do not believe that that isn't coming. During my research I came across four different Pentagon projects on different aspects of that. And so you have this question: what does this lead to issues like war crimes? Robots are emotionless, so they don't get upset if their buddy is killed. They don't commit crimes of rage and revenge. But robots are emotionless. They see an 80-year-old grandmother in a wheelchair the same way they see a T-80 tank: they're both just a series of zeroes and ones. And so we have this question to figure out: How do we catch up our 20th century laws of war, that are so old right now that they could qualify for Medicare, to these 21st century technologies? And so, in conclusion, I've talked about what seems the future of war, but notice that I've only used real world examples and you've only seen real world pictures and videos. And so this sets a great challenge for all of us that we have to worry about well before you have to worry about your Roomba sucking the life away from you. Are we going to let the fact that what's unveiling itself right now in war sounds like science fiction and therefore keeps us in denial? Are we going to face the reality of 21st century war? Is our generation going to make the same mistake that a past generation did with atomic weaponry, and not deal with the issues that surround it until Pandora's box is already opened up? Now, I could be wrong on this, and one Pentagon robot scientist told me that I was. He said, ""There's no real social, ethical, moral issues when it comes to robots. That is,"" he added, ""unless the machine kills the wrong people repeatedly. Then it's just a product recall issue."" And so the ending point for this is that actually, we can turn to Hollywood. A few years ago, Hollywood gathered all the top characters and created a list of the top 100 heroes and top 100 villains of all of Hollywood history, the characters that represented the best and worst of humanity. Only one character made it onto both lists: The Terminator, a robot killing machine. And so that points to the fact that our machines can be used for both good and evil, but for me it points to the fact that there's a duality of humans as well. This week is a celebration of our creativity. Our creativity has taken our species to the stars. Our creativity has created works of arts and literature to express our love. And now, we're using our creativity in a certain direction, to build fantastic machines with incredible capabilities, maybe even one day an entirely new species. But one of the main reasons that we're doing that is because of our drive to destroy each other, and so the question we all should ask: is it our machines, or is it us that's wired for war? Thank you. (Applause)"	"我想從一個戰爭的場景來開始談。這裡看不出任何徵兆來得知前方隱藏的危險。事實上伊拉克反抗軍已經在路旁很小心的裝置了 IED，那是一種簡易爆炸裝置。在 2006 這一年中，每個月有超過 2500 件這類攻擊事件，而這些正是造成美國士兵以及伊拉克居民死傷的主要原因。 搜尋這種 IED 的小組被稱為 EOD 小組 —爆破性武器處理( Explosive Ordnance Disposal )他們是美軍部隊中專門對付路旁炸彈的尖兵。每個 EOD 小組每年會進行大約 600 次這類炸彈任務，每天大概要拆兩個炸彈。也許對他們來說，伊拉克反抗軍用5萬美金懸賞一個EOD士兵的人頭這件事，可以看出他們有多珍貴。 很不幸的，這種特殊任務不一定能安全完成。某次一位資深士兵為了看訊號線過度接近一枚炸彈，結果它炸出了一道火牆。依據你靠得多近，以及炸彈中裝置了多少火藥，它會導致人員死亡或受傷。你必須要保持距離在 50 碼以上才能不受波及。沖擊波強大到足以震斷你的四肢，即使你沒有被炸彈擊中。這位士兵正身處於炸彈上方。 而這個資深隊伍的其他人員只在稍微左邊一點的位置。而在當晚，這個隊伍的指揮官做了一件令人難過的任務，他寫了一封哀悼的信回美國，他描述關於失去他的隊伍他有多傷心，而且事實上，他們失去了最勇敢的士兵，一位曾經多次拯救他們性命的士兵。並且，他感到抱歉因為他無法將這個人帶回家。但是從這個事件中，他提到了一絲希望。如他所寫的，「至少當一個機器人死亡時，你不用寫信給他的母親。」 這聽起來像是科幻電影的場景，但這是戰場上真實的事情。在這個例子中的士兵，是一個重達 42 磅，名為 PackBot 的機器人。這位長官的信，不像你在一些老舊戰爭電影所見寄給愛荷華州的某個家園，而是寄給這家 iRobot 公司，名字取自 Asimov 小說以及不怎麼樣的 Will Smith 電影，還有 ... ( 笑聲 ) ...如果你還記得在那個科幻世界中，機器人一開始只會幫我們做家事，接著，它們可以決定我們的生死。這就是今日我們面對的真實狀況。 接下來，我將會用我身後的投影片來播放一些照片給大家看，讓大家看看目前被用於戰場以及那些已經有原型機(prototype)的機器人。這只是稍微做個介紹。另外要提一下，你們現在看見的這些，並不是瓦肯人的外星技術，或是少年巫師賀爾蒙作祟變出來的東西。這一切都是真實的。我們開始看看這些照片吧 人性在現今的戰爭中出現有史以來的重大改變。當初美軍進入伊拉克時，只有少數的無人飛機，現在已經增加到 5300 架。當時我們沒有無人的地面系統，現在已經有 12000 架了。而 ""殺手級應用"" 這個技術名詞在這兒將會有新的定義。請記住我們現在所談的是拿福特的Model T4 車,與萊特兄弟的飛機和即將推出的最新款比較的那種巨大差異。這就是我們現在即將看見的。 我最近遇到一位空軍三星上將，他說，基本上我們即將面對的是，將會有成千上萬的機器人在戰場上作戰，而這個數字之所以重要，是因為我們不是談論成千上萬的現有機器人，而是成千上萬的原型機，以及未來機器人，因為，在現今科技裡面有個叫做摩爾定律的東西，就是說你將可以替機器人裝入更多強力的運算能力，所以往後推算 25 年的話，如果摩爾定律依然正確的話，這些機器人在運算能力上將會比今日強上十幾億倍。這樣的話，我們本來在一些漫畫同人展中討論的一些科幻小說內容，將會改在掌權者的會議室中談論，像是五角大廈這種地方。機器人的巨大轉變正在發生。 在這兒我必須先說清楚。我並不是在說某天加州州長會以魔鬼終結者型態出現在你家門前那種令你擔心的事。(笑聲)以後的歷史學家看我們這段時期時，他們會寫說我們正處於一種不同的轉變期，一種戰爭型態的轉變，就像是原子彈的發明一般。但可能還會更加重大，因為我們擁有的無人系統並不只是影響""如何""去作戰，它們將影響在機器人最重要的原則，它是""和誰""在作戰。就是說，在以往的戰爭型態改變中，不論是機關槍，或是原子彈，都只是關於如何作到射得更快，前進得更遠，或是爆炸威力更大。這些當然也和機器人有關係，但這將會改變士兵們的經歷，甚至是士兵們的身份。 另外一部分就是，人類在近5000年來在戰場上作戰的專利將會在我們這個世代中結束。過去幾年來，我到各地去拜訪這個領域的人們，包括了製作機器人的科學家，提供靈感的那些科幻小說作者，那些身在內華達州負責操縱無人飛機的19歲駕駛們，負責指揮這些人的四星上將，甚至是被攻擊的伊拉克反抗軍，詢問他們對這套系統的看法，令我感興趣的並不只是他們自身的故事，而是他們所經歷的這些將如何影響我們的社會，我們的法律以及道德觀之類的。我會利用剩餘的時間，將這些作一個簡單的說明。 首先，戰爭的未來型態，甚至是利用機器人的戰爭，將不再只是美國的問題。確實現在美國在軍事機器人方面佔有領先的地位，但是我們知道科技這種東西不會有永遠保持領先這種事。這樣說吧，請問這裡有多少人還在使用王安電腦? (笑聲)戰爭也是一樣。英國以及法國發明了坦克。而德國人發現該如何正確的使用它，所以我們現在要思考的是，雖然美國現在領先，但世界上還有其他43個國家正在努力開發軍事機器人，包括了那些值得注意的國家例如俄羅斯、中國、巴基斯坦和伊朗。 這讓我更加擔憂。我們該如何利用現有的製造技術、現有的學校科學與數學教育，在這個戰爭型態轉變中繼續向前?換個想法的話就是，越來越多士兵在戰場上使用中國製的硬體設備，以及印度所寫的電腦軟體，這將會是什麼情況呢？但正如同軟體逐漸趨向開放式原始碼(open source)，戰爭也是如此。不同於飛機或是原子彈，你不需要有大型生產系統來製造機器人。大部分都有現成品，有些甚至可以讓你DIY的。像是各位在剛才的影片中看見的烏鴉號無人飛機，手持拋擲的那台，只要大約1千美金，你就可以自己做一台，和那些在伊拉克的士兵們所用的完全一樣。 當關係到戰爭和衝突時，這東西就會有不同的用法，好人可能只是拿來玩玩，把這些當作興趣而已，但壞人也會拿來玩。這個介於機器人技術與恐怖主義行為的東西，將會變得相當迷人，但又相當令人困擾，我們已經看見它發生了。在以色列這個國家，與真主黨這個非國家組織的戰爭中，真主黨操縱了四架無人飛機來對抗以色列。你甚至可以坐在家裡，使用電腦連到一個Jehadi網站，遙控引爆在伊拉克的簡易爆炸裝置。 因此，我想這個將會導致兩種趨勢的發生。第一個是，個人對抗政府的力量將會變得更加強大，但第二個則是，我們將會看見恐怖份子的勢力範圍逐漸擴大。未來可能將是蓋達組織2.0與次世代郵包炸彈客聯手的情況。另外一方面的問題是，請記住，你並不需要去說服機器人相信在犧牲後會獲得72個處女，以說服它們執行自殺炸彈任務。 但這件事將會在政治上產生一些影響。我曾經遇到雷根時代的前國防部助理秘書長。他曾經這樣說過，""我喜歡這些系統，因為它可以拯救許多美國人的性命，但是我擔心這將會使得戰爭變得更加自由市場化，會出現更多談論代價的驚人言論。當人們認為某種方式是幾乎不需付出代價時，人們會比較傾向去使用它。""對我來說，機器人化是必然的趨勢，甚至已經在政治體系中出現，也許已經讓它們變得相當合理化。對於這個我們並沒有任何草案。我們不再有任何戰爭宣言。我們不再買任何戰爭公債。但事實上，我們正在持續將那些原本要送往危險區域的美國士兵們盡量以機器人替代，這樣我們就可以讓那些反對戰爭的民調數字降至最低。 但是未來的戰爭，也將會變成YouTube型態的戰爭。就是說，我們的機器人不只可以讓人們遠離危險。同時也會紀錄下它們所看見的一切。所以它們不只是讓人群遠離戰爭，它們也重新塑造它與戰爭的關係。現在YouTube上已經有數以千計的短片紀錄著伊拉克戰爭的狀況，大部分都是由機器人所拍攝。這也許是一件好事，它可以讓一般家庭與戰場之間形成一種前所未有的連結。但是，請記住，這正發生在我們所存在的詭異世界，因此，它們勢必會被人們下載到他們的iPod或Zune裡面，甚至會變成一種娛樂。士兵們給了這種短片一個名字。他們稱呼它為戰爭色情片。我曾經收到一則經典的影片，是封e-mail，夾帶了一段掠奪者攻擊的影片，紀錄著攻擊敵人的陣地，飛彈擊中目標時，敵軍的身體因為爆破而飛上空中。它被配上了音樂。它被配上了一段流行音樂Sugar Ray的""我只想飛""。 這種看得更多、但親身經歷更少的情況，導致大眾與戰爭產生一種奇怪的關係。我想這就像是觀看運動比賽一樣。這就像是在看一場NBA比賽一樣，在電視上看職業籃球賽時，畫面上的運動員看起來都小小的，但是親自在籃球比賽現場時，你才知道那些身高超過200公分的人真正是什麼樣子。但是我們必須記住，這些只是短片。這些是ESPN運動中心版本的比賽。它沒有故事背景，它沒有戰略，它沒有人性，戰爭變成了像灌籃或是發射飛彈那麼簡單。 諷刺的是，當未來戰爭有更多機器人加入時，那是被人們的心理因素所驅使，那是因為人們的缺陷導致這些戰爭發生。有一個激起了政治上很大迴響的案例，就是當我們對抗激進份子時，我們對於真實戰爭的想法會有什麼改變。在什麼情況下，我們會決定要派出這些機器人，以及派出這些機器人之後會有什麼結果。我曾經遇到一位布希內閣的高級官員，他曾經對於這種無人的戰爭方式這麼說：""它讓我們的力量變大，令敵人害怕的是我們的科技"" 但是當你走出去，遇到其他人，例如在黎巴嫩，這就變成另外一件事。在那裡我遇到一個新聞記者，當我們在談話時，有一架無人飛機正在空中飛行著。他這麼說：""這是只是冷酷無情的另一種象徵，殘忍的以色列和美國人們，他們很膽小，因為他們只敢派機器人來攻擊我們。他們不願意像個男人一樣作戰，因為他們害怕戰鬥。所以我們必須要殺掉一些他們的士兵來打敗他們。"" 未來的戰爭也造就了不同型態的戰士，這確實重新定義了上戰場的經歷，你可以稱之為臥房戰士。以下是一位掠奪者無人飛機的駕駛描述關於他在伊拉克戰爭中的經歷，而期間他從未離開過內華達州。""你將會前進至戰場上12小時，對著目標物射擊，直接殺掉敵人的戰鬥員，之後你開著車回到家，在20分鐘之內你就可以坐在餐桌上，和你的孩子們談論他們的回家作業。"" 對於這些經歷，在心理上要達到平衡是極為困難的。事實上這些無人飛機的駕駛員比起那些在伊拉克作戰的人們更容易得到創傷後壓力症候群。但是有些人會擔心這種遠距作戰會導致一些其它問題，這將會讓企圖進行戰爭犯罪當你有這種遠距能力時會更加容易。一個年輕的無人飛機駕駛告訴我，在遠距射殺敵人的部隊""感覺就像是電動玩具一樣""。玩過""俠盜獵車手""的人應該會知道，任何我們在真實世界不會做的事在電玩世界裡我們可以任意進行。 所以，你剛聽到我所說的這些內容，都是科技革命的另外一面，它正改變現在的我們，也許將會改變我們未來的戰爭型態。摩爾定律在這裡是可行的，同樣的，墨菲定律也是如此。戰爭的硝煙還未散去，敵人進行了投票，我們將會得到驚人的新能力，但是我們同時也在經歷人類新的困境。有的時候，這些只是一種""令人驚訝""的時刻，這是製造機器人的公司所描述的""你將會有一些令人驚訝的時刻。""那麼，對於機器人和戰爭而言，什麼是令人驚訝的時刻呢? 有的時候它們會很好笑。有時候，它們就像是艾迪‧墨菲的電影 ""兵來將擋""裡面所演的那樣，當他們測試武裝機器人的機關槍時，在展示的期間，它開始轉圈圈，然後將它的機關槍瞄準觀眾席上的貴賓們。所幸這些武器並沒有子彈，所以沒有人受傷。但是其他令人驚訝的時刻則會變成悲劇，例如去年在南非，一架防空加農砲出現了官方宣稱的""軟體故障""，結果它啟動了，並且開火，結果殺死了九個士兵。 我們在戰爭規則和責任上出現了新的問題。我們要怎麼處理這些無人的屠殺工具呢?什麼是無人的屠殺工具呢?我們已經有三次的例子，當掠奪者攻擊時，我們以為已經殺了賓拉登，但結果並不是如此。這就是我們所面臨的問題。這並不只是在說，武裝的自動化系統擁有完整的權利去使用武器，還有，不要以為這不會發生。在我的研究中，我接觸了五角大廈針對不同領域進行的四個專案。 那麼你會有這個疑問。是什麼導致這些變得像是戰爭犯罪?機器人是沒有感情的，所以它們不會因為同伴被殺而打亂思緒。它們不會因為憤怒而犯罪或進行報復。但正因為機器人是沒有感情的，對它們來說，坐在輪椅上的80歲老婆婆，和T80坦克是沒有兩樣的。他們都只是一連串 0 和 1 的訊號。因此我們必須想辦法解決這個問題，我們該怎麼讓20世紀的戰爭規則跟上時代，對於21世紀的科技而言，只剩下醫療保險還能延用而已。 總結而言，我已經談論了未來戰爭的樣子，但是請注意，我舉的都是真實世界的例子，你看見的都是真實世界的照片和影片。對我們來說這將是一大挑戰，在你開始擔心你的自動吸塵器殺掉你之前，我們必須趕快想好對策。難道我們要讓戰爭中的事實真相，繼續被當成是科幻電影一般，而不願意去面對嗎?我們是否要面對21世紀戰爭的真相呢?我們這一代是否要像上一代一樣，繼續犯下那種使用原子彈的錯誤呢?然後一直不願意去面對這些問題，直到潘朵拉的盒子被打開為止嗎? 也許我的觀點是錯的，一位五角大廈的機器人科學家說我錯了，他說，""對於機器人來說沒有真假，社會意識，倫理道德等問題。唯一的問題是，除非這台機器連續殺錯了人，這樣的話，那就是要回廠維修的問題。"" 所以，談論到最後，我們來說說好萊塢。幾年前好萊塢聚集了許多頂尖的演員，並且列出了好萊塢歷史上前100名英雄人物，還有前100名壞蛋角色，這些角色代表著人性中最好和最壞的特質，其中只有一個角色同時存在於名單之中，就是魔鬼終結者，一個機器人型態的殺人機器。這就點出了我們的機器可以同時被用於好事和邪惡的事，但是對我來說，事實上它也點出了人類同時具有善和惡的雙重特性。 本週我們有個創造力的慶祝會。我們的創造力已經讓人類登上別的星球。我們的創造力製造出藝術品，以及文學作品來表現我們的愛，而現在我們正在使用我們的創造力，去製造出奇妙的機器，讓它們具有不可思議的能力，也許有一天，會出現一種全新的物種。但是，令我們這麼做的其中一個主要因素，就是因為我們想要毀掉彼此。所以，我們必須要問的是，操縱戰爭的是我們的機器，還是我們自己？謝謝大家。(掌聲)"
