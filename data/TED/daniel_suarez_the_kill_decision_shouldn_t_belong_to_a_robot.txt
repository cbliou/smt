Talk	en	zh-tw
daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot	"I write fiction sci-fi thrillers, so if I say ""killer robots,"" you'd probably think something like this. But I'm actually not here to talk about fiction. I'm here to talk about very real killer robots, autonomous combat drones. Now, I'm not referring to Predator and Reaper drones, which have a human making targeting decisions. I'm talking about fully autonomous robotic weapons that make lethal decisions about human beings all on their own. There's actually a technical term for this: lethal autonomy. Now, lethally autonomous killer robots would take many forms — flying, driving, or just lying in wait. And actually, they're very quickly becoming a reality. These are two automatic sniper stations currently deployed in the DMZ between North and South Korea. Both of these machines are capable of automatically identifying a human target and firing on it, the one on the left at a distance of over a kilometer. Now, in both cases, there's still a human in the loop to make that lethal firing decision, but it's not a technological requirement. It's a choice. And it's that choice that I want to focus on, because as we migrate lethal decision-making from humans to software, we risk not only taking the humanity out of war, but also changing our social landscape entirely, far from the battlefield. That's because the way humans resolve conflict shapes our social landscape. And this has always been the case, throughout history. For example, these were state-of-the-art weapons systems in 1400 A.D. Now they were both very expensive to build and maintain, but with these you could dominate the populace, and the distribution of political power in feudal society reflected that. Power was focused at the very top. And what changed? Technological innovation. Gunpowder, cannon. And pretty soon, armor and castles were obsolete, and it mattered less who you brought to the battlefield versus how many people you brought to the battlefield. And as armies grew in size, the nation-state arose as a political and logistical requirement of defense. And as leaders had to rely on more of their populace, they began to share power. Representative government began to form. So again, the tools we use to resolve conflict shape our social landscape. Autonomous robotic weapons are such a tool, except that, by requiring very few people to go to war, they risk re-centralizing power into very few hands, possibly reversing a five-century trend toward democracy. Now, I think, knowing this, we can take decisive steps to preserve our democratic institutions, to do what humans do best, which is adapt. But time is a factor. Seventy nations are developing remotely-piloted combat drones of their own, and as you'll see, remotely-piloted combat drones are the precursors to autonomous robotic weapons. That's because once you've deployed remotely-piloted drones, there are three powerful factors pushing decision-making away from humans and on to the weapon platform itself. The first of these is the deluge of video that drones produce. For example, in 2004, the U.S. drone fleet produced a grand total of 71 hours of video surveillance for analysis. By 2011, this had gone up to 300,000 hours, outstripping human ability to review it all, but even that number is about to go up drastically. The Pentagon's Gorgon Stare and Argus programs will put up to 65 independently operated camera eyes on each drone platform, and this would vastly outstrip human ability to review it. And that means visual intelligence software will need to scan it for items of interest. And that means very soon drones will tell humans what to look at, not the other way around. But there's a second powerful incentive pushing decision-making away from humans and onto machines, and that's electromagnetic jamming, severing the connection between the drone and its operator. Now we saw an example of this in 2011 when an American RQ-170 Sentinel drone got a bit confused over Iran due to a GPS spoofing attack, but any remotely-piloted drone is susceptible to this type of attack, and that means drones will have to shoulder more decision-making. They'll know their mission objective, and they'll react to new circumstances without human guidance. They'll ignore external radio signals and send very few of their own. Which brings us to, really, the third and most powerful incentive pushing decision-making away from humans and onto weapons: plausible deniability. Now we live in a global economy. High-tech manufacturing is occurring on most continents. Cyber espionage is spiriting away advanced designs to parts unknown, and in that environment, it is very likely that a successful drone design will be knocked off in contract factories, proliferate in the gray market. And in that situation, sifting through the wreckage of a suicide drone attack, it will be very difficult to say who sent that weapon. This raises the very real possibility of anonymous war. This could tilt the geopolitical balance on its head, make it very difficult for a nation to turn its firepower against an attacker, and that could shift the balance in the 21st century away from defense and toward offense. It could make military action a viable option not just for small nations, but criminal organizations, private enterprise, even powerful individuals. It could create a landscape of rival warlords undermining rule of law and civil society. Now if responsibility and transparency are two of the cornerstones of representative government, autonomous robotic weapons could undermine both. Now you might be thinking that citizens of high-tech nations would have the advantage in any robotic war, that citizens of those nations would be less vulnerable, particularly against developing nations. But I think the truth is the exact opposite. I think citizens of high-tech societies are more vulnerable to robotic weapons, and the reason can be summed up in one word: data. Data powers high-tech societies. Cell phone geolocation, telecom metadata, social media, email, text, financial transaction data, transportation data, it's a wealth of real-time data on the movements and social interactions of people. In short, we are more visible to machines than any people in history, and this perfectly suits the targeting needs of autonomous weapons. What you're looking at here is a link analysis map of a social group. Lines indicate social connectedness between individuals. And these types of maps can be automatically generated based on the data trail modern people leave behind. Now it's typically used to market goods and services to targeted demographics, but it's a dual-use technology, because targeting is used in another context. Notice that certain individuals are highlighted. These are the hubs of social networks. These are organizers, opinion-makers, leaders, and these people also can be automatically identified from their communication patterns. Now, if you're a marketer, you might then target them with product samples, try to spread your brand through their social group. But if you're a repressive government searching for political enemies, you might instead remove them, eliminate them, disrupt their social group, and those who remain behind lose social cohesion and organization. Now in a world of cheap, proliferating robotic weapons, borders would offer very little protection to critics of distant governments or trans-national criminal organizations. Popular movements agitating for change could be detected early and their leaders eliminated before their ideas achieve critical mass. And ideas achieving critical mass is what political activism in popular government is all about. Anonymous lethal weapons could make lethal action an easy choice for all sorts of competing interests. And this would put a chill on free speech and popular political action, the very heart of democracy. And this is why we need an international treaty on robotic weapons, and in particular a global ban on the development and deployment of killer robots. Now we already have international treaties on nuclear and biological weapons, and, while imperfect, these have largely worked. But robotic weapons might be every bit as dangerous, because they will almost certainly be used, and they would also be corrosive to our democratic institutions. Now in November 2012 the U.S. Department of Defense issued a directive requiring a human being be present in all lethal decisions. This temporarily effectively banned autonomous weapons in the U.S. military, but that directive needs to be made permanent. And it could set the stage for global action. Because we need an international legal framework for robotic weapons. And we need it now, before there's a devastating attack or a terrorist incident that causes nations of the world to rush to adopt these weapons before thinking through the consequences. Autonomous robotic weapons concentrate too much power in too few hands, and they would imperil democracy itself. Now, don't get me wrong, I think there are tons of great uses for unarmed civilian drones: environmental monitoring, search and rescue, logistics. If we have an international treaty on robotic weapons, how do we gain the benefits of autonomous drones and vehicles while still protecting ourselves against illegal robotic weapons? I think the secret will be transparency. No robot should have an expectation of privacy in a public place. (Applause) Each robot and drone should have a cryptographically signed I.D. burned in at the factory that can be used to track its movement through public spaces. We have license plates on cars, tail numbers on aircraft. This is no different. And every citizen should be able to download an app that shows the population of drones and autonomous vehicles moving through public spaces around them, both right now and historically. And civic leaders should deploy sensors and civic drones to detect rogue drones, and instead of sending killer drones of their own up to shoot them down, they should notify humans to their presence. And in certain very high-security areas, perhaps civic drones would snare them and drag them off to a bomb disposal facility. But notice, this is more an immune system than a weapons system. It would allow us to avail ourselves of the use of autonomous vehicles and drones while still preserving our open, civil society. We must ban the deployment and development of killer robots. Let's not succumb to the temptation to automate war. Autocratic governments and criminal organizations undoubtedly will, but let's not join them. Autonomous robotic weapons would concentrate too much power in too few unseen hands, and that would be corrosive to representative government. Let's make sure, for democracies at least, killer robots remain fiction. Thank you. (Applause) Thank you. (Applause)"	我寫驚悚科幻小說所以如果我談到「殺手機器人」你可能會覺得是這樣的東西但事實上我不是來這裡談論小說的我是來這裡談論真正的殺手機器人自主的無人戰機 我的意思不是掠奪者或是收割者無人戰機由人類來決定目標我說的是全自動的機械武器能有自主性的對人類做出致命性的決策不倚靠人類這有個專門術語：致命自主 致命性自主殺手機器人有多種模式－飛行、陸行或只是待命事實上它們很快就要問世了這是兩座自動狙擊台目前部署在南北韓非軍事區這兩台機器都是自動的能夠辨識人類的位置並開火射擊左邊這台能瞄準超過一公里這兩座狙擊台都還是有人力介入來下達致命攻擊的決策但並不是技術上的需要，而是選項這個選項就是我的重點因為當我們將致命決策權由人類轉移到軟體設備我們冒的風險不僅是將人性抽離戰爭同時也完全改變了我們的社會景觀遠遠不是戰場可以形容的因為人類解決衝突的方法塑造了我們社會的樣貌自古以來皆是如此 好比說這些是西元1400年時最先進的武器系統儘管建造、保養代價高昂但是透過這些武器我們可以統治群眾封建社會下政治力量的分布顯示了這一點力量集中在最頂端什麼改變了？科技革新火藥、大砲不久之後，盔甲和城堡就被淘汰了戰場上有什麼士兵不重要數量有多少才是關鍵當軍隊壯大之後，出現了民族國家來滿足政治及後勤方面在防禦上的需求當領導人必須更加倚靠他們的人民就會開始分權代議政府開始成形 再一次，我們用來解決衝突的工具塑造了我們社會的樣貌自主機械武器就是這種工具但是因為發動戰爭所需的人數不多有極少數人再度集權統治的風險可能讓五百年來民主化的趨勢走回頭路 我想，了解了之後我們可以果斷的維持民主制度來做我們人類最擅長的事，那就是適應環境但時間是一個因素有七十個國家正在研發他們自己的遠程無人戰鬥機如你所見，遠程無人戰鬥機正是自主機械武器的前身因為一旦部屬了遠程無人戰鬥機就會有三個強而有力的因素迫使人們把決定權交給武器平台本身 第一個因素是無人戰機所拍攝的大量影像像是在2004年，美國的無人機艦隊拍攝了長達71小時的影像監控以供分析之用到了2011年，影像長度增為30萬小時超出人類檢視所有影像的能力但即使數字之大，它依然大幅成長五角大廈的「戈爾貢之眼(Gorgon Stare)」和「百眼巨人(Argus)」計畫將會有65台獨立運作的攝影機安裝在每架無人飛機上而這將大幅超越人類所能檢視的能力這意味著視覺智慧軟體必須掃描影像找出我們感興趣的部分這表示不久後無人飛機將會告訴人類該看哪些部分而非由人類來決定 還有第二個動機迫使我們把決定權交給機器那就是電磁干擾它會切斷無人飛機和操作員的連線我們現在看到的例子是在2011年美國的RQ-170哨兵式(Sentinel)無人飛機在伊朗上空因為GPS受到欺騙攻擊而陷入混亂這種攻擊對任何遠程無人飛機都有效這表示無人飛機必須去承擔更多決策它們會知道它們的任務目標沒有人類指導也能對新的狀況作出反應它們會忽視外來的無線電訊號只發出極少量的無線電訊號 這牽扯到第三個因素也是最強烈的誘因促使我們將決定權交給武器那就是貌似合理的推託我們生活在一個全球經濟體下大部分的地方都有高科技工業網路間諜正在將先進的科技帶到未知的地方在這種環境下很有可能成功的無人飛機設計，在灰市中量產擊敗取得授權的工廠如此一來，即使仔細調查無人機自殺攻擊的殘骸也難以斷定是誰發射這個武器 這就很有可能會引起匿名戰爭可能會讓地緣政治傾向一頭讓一個國家難以將它的炮火對準攻擊者也會讓21世紀的維持的平衡由防禦轉為侵略使得軍事行動變成可行的選項不只是小國還有犯罪組織、私人企業甚至是有權力的人都能這麼做這樣可能會引發軍閥割據的混戰破壞法律規範及文明社會如果責任感以及透明度是代議政治的兩塊基石自主機械武器會破壞這兩者 你現在可能會覺得高科技國家的人民在機械戰爭中佔有優勢這些國家的人民比較不容易受傷害尤其是對抗發展中國家的時候但是我認為事實剛好相反我認為高科技社會的人民更容易受到機械武器傷害其原因可以用兩個字來說明：資料資料壯大了高科技社會手機定位、電訊後設資料社交媒體、電子郵件、簡訊、金融交易資料和運輸資料等，都是大量的即時資料記載著人類的社交活動簡單來說，比其任何其他時代機器對人類來說更顯而易見而這正好符合了自動武器的目標需求 大家現在看到的是社會團體的連結分析圖線段代表著人與人之間的社會連結這類的圖只要依據現代人所留下的資料就能夠自動產生現在它應用於商品與服務的行銷來統計目標群體，但這是雙面科技因為目標的鎖定可應用於另外一種情況我們注意到某些人是特別顯著的他們是社會網絡的樞紐他們是組織者、輿論製造者、領導者而這些人依據他們的溝通模式我們也能夠自動辨識如果現在你是一位營銷員，你可能將試用產品鎖定這些人，試著把你的品牌推廣到他們的社會團體中但如果你是專制的政府在搜尋政敵，你可能反而會除掉他們消滅他們、破壞他們的社會團體而剩下來的人就會失去他們的社會連結以及社群組織在一個機械武器便宜、氾濫的世界國界的保護微不足道無法防衛遠方政府的批評者或是跨國犯罪組織鼓吹改革的群眾運動在大眾充分了解其訴求之前就會被察覺，並將其領導人消滅而充分的把想法傳達給大眾正是一般政治激進主義政府所追求的匿名的致命武器能夠讓致命行動變成所有競爭者一個簡單的選項這會讓民主的核心－言論自由及民眾在政治上行動轉為冷漠 這也就是為什麼我們需要國際公約來規範機械武器，特別是全球皆禁止研發及部屬殺手機器人現在我們已經有國際公約來規範核武及生物武器，雖然並不完美但卻很有效但是機械武器完全就是個危險的東西因為它們幾乎一定會被使用也會侵蝕我們的民主制度 2012年11月，美國國防部直接要求所有致命決策都必須有人類參與其中這暫時有效防止美軍的自主武器但是這個要求必須永久有效它也可以為全球立法行動鋪路因為我們需要國際性的法律架構來規範機械武器我們現在就需要，以免毀滅性的恐怖攻擊事件讓世界上的國家爭相採用這些武器完全不考慮後果自動機械武器把太強大的力量集中在太少人手中，而他們會威脅到民主本身 別誤解了我的意思，我認為這些非武裝的民用無人飛機好用途不少環境監控、搜救、後勤如果我們有機械武器的國際公約我們要如何從自主無人飛機及載具中獲得好處同時又能夠保護我們自己免於違法機械武器的侵害呢 我認為機密會變得透明化任何的機器人在公共場所都不得有隱私 (掌聲) 每一台機器人或無人飛機在工廠裡都要烙上一個加密的身分可以用來追蹤它在公共場所的動向我們的車子有車牌，飛機有機尾編號這是同樣的道理每個市民都可以下載應用程式來顯示無人飛機及自動載具在他們附近的公共空間移動的數量不論是過去或是現在領導者應該要部屬感應器還有民用無人飛機來偵測圖謀不軌的無人飛機而且不是直接派自己的無人攻擊機將它們擊落而是應該告知人們這些無人飛機的存在在確定是高安全性的地區或許民用無人飛機可以將它們引導到炸彈處理設施 但要注意的是，這比較像是免疫系統而不是武器系統如此就可以讓我們獲得自主載具與無人飛機所帶來的好處同時保有我們開放、文明的社會 我們必須禁止研發及部屬殺手機器人我們不會屈服於自動化戰爭的誘惑專制政府及犯罪組織一定會屈服但是我們不會加入他們自主機械武器將過多權力集中到極少數看不見的手中而那會侵蝕代議政府我們要保證，至少為了民主的理由讓殺手機器人留在小說裡吧 謝謝 (掌聲)謝謝 (掌聲)
