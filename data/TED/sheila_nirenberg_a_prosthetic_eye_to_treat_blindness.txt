Talk	en	zh-tw
sheila_nirenberg_a_prosthetic_eye_to_treat_blindness	"I study how the brain processes information. That is, how it takes information in from the outside world, and converts it into patterns of electrical activity, and then how it uses those patterns to allow you to do things — to see, hear, to reach for an object. So I'm really a basic scientist, not a clinician, but in the last year and a half I've started to switch over, to use what we've been learning about these patterns of activity to develop prosthetic devices, and what I wanted to do today is show you an example of this. It's really our first foray into this. It's the development of a prosthetic device for treating blindness. So let me start in on that problem. There are 10 million people in the U.S. and many more worldwide who are blind or are facing blindness due to diseases of the retina, diseases like macular degeneration, and there's little that can be done for them. There are some drug treatments, but they're only effective on a small fraction of the population. And so, for the vast majority of patients, their best hope for regaining sight is through prosthetic devices. The problem is that current prosthetics don't work very well. They're still very limited in the vision that they can provide. And so, you know, for example, with these devices, patients can see simple things like bright lights and high contrast edges, not very much more, so nothing close to normal vision has been possible. So what I'm going to tell you about today is a device that we've been working on that I think has the potential to make a difference, to be much more effective, and what I wanted to do is show you how it works. Okay, so let me back up a little bit and show you how a normal retina works first so you can see the problem that we were trying to solve. Here you have a retina. So you have an image, a retina, and a brain. So when you look at something, like this image of this baby's face, it goes into your eye and it lands on your retina, on the front-end cells here, the photoreceptors. Then what happens is the retinal circuitry, the middle part, goes to work on it, and what it does is it performs operations on it, it extracts information from it, and it converts that information into a code. And the code is in the form of these patterns of electrical pulses that get sent up to the brain, and so the key thing is that the image ultimately gets converted into a code. And when I say code, I do literally mean code. Like this pattern of pulses here actually means ""baby's face,"" and so when the brain gets this pattern of pulses, it knows that what was out there was a baby's face, and if it got a different pattern it would know that what was out there was, say, a dog, or another pattern would be a house. Anyway, you get the idea. And, of course, in real life, it's all dynamic, meaning that it's changing all the time, so the patterns of pulses are changing all the time because the world you're looking at is changing all the time too. So, you know, it's sort of a complicated thing. You have these patterns of pulses coming out of your eye every millisecond telling your brain what it is that you're seeing. So what happens when a person gets a retinal degenerative disease like macular degeneration? What happens is is that, the front-end cells die, the photoreceptors die, and over time, all the cells and the circuits that are connected to them, they die too. Until the only things that you have left are these cells here, the output cells, the ones that send the signals to the brain, but because of all that degeneration they aren't sending any signals anymore. They aren't getting any input, so the person's brain no longer gets any visual information — that is, he or she is blind. So, a solution to the problem, then, would be to build a device that could mimic the actions of that front-end circuitry and send signals to the retina's output cells, and they can go back to doing their normal job of sending signals to the brain. So this is what we've been working on, and this is what our prosthetic does. So it consists of two parts, what we call an encoder and a transducer. And so the encoder does just what I was saying: it mimics the actions of the front-end circuitry — so it takes images in and converts them into the retina's code. And then the transducer then makes the output cells send the code on up to the brain, and the result is a retinal prosthetic that can produce normal retinal output. So a completely blind retina, even one with no front-end circuitry at all, no photoreceptors, can now send out normal signals, signals that the brain can understand. So no other device has been able to do this. Okay, so I just want to take a sentence or two to say something about the encoder and what it's doing, because it's really the key part and it's sort of interesting and kind of cool. I'm not sure ""cool"" is really the right word, but you know what I mean. So what it's doing is, it's replacing the retinal circuitry, really the guts of the retinal circuitry, with a set of equations, a set of equations that we can implement on a chip. So it's just math. In other words, we're not literally replacing the components of the retina. It's not like we're making a little mini-device for each of the different cell types. We've just abstracted what the retina's doing with a set of equations. And so, in a way, the equations are serving as sort of a codebook. An image comes in, goes through the set of equations, and out comes streams of electrical pulses, just like a normal retina would produce. Now let me put my money where my mouth is and show you that we can actually produce normal output, and what the implications of this are. Here are three sets of firing patterns. The top one is from a normal animal, the middle one is from a blind animal that's been treated with this encoder-transducer device, and the bottom one is from a blind animal treated with a standard prosthetic. So the bottom one is the state-of-the-art device that's out there right now, which is basically made up of light detectors, but no encoder. So what we did was we presented movies of everyday things — people, babies, park benches, you know, regular things happening — and we recorded the responses from the retinas of these three groups of animals. Now just to orient you, each box is showing the firing patterns of several cells, and just as in the previous slides, each row is a different cell, and I just made the pulses a little bit smaller and thinner so I could show you a long stretch of data. So as you can see, the firing patterns from the blind animal treated with the encoder-transducer really do very closely match the normal firing patterns — and it's not perfect, but it's pretty good — and the blind animal treated with the standard prosthetic, the responses really don't. And so with the standard method, the cells do fire, they just don't fire in the normal firing patterns because they don't have the right code. How important is this? What's the potential impact on a patient's ability to see? So I'm just going to show you one bottom-line experiment that answers this, and of course I've got a lot of other data, so if you're interested I'm happy to show more. So the experiment is called a reconstruction experiment. So what we did is we took a moment in time from these recordings and asked, what was the retina seeing at that moment? Can we reconstruct what the retina was seeing from the responses from the firing patterns? So, when we did this for responses from the standard method and from our encoder and transducer. So let me show you, and I'm going to start with the standard method first. So you can see that it's pretty limited, and because the firing patterns aren't in the right code, they're very limited in what they can tell you about what's out there. So you can see that there's something there, but it's not so clear what that something is, and this just sort of circles back to what I was saying in the beginning, that with the standard method, patients can see high-contrast edges, they can see light, but it doesn't easily go further than that. So what was the image? It was a baby's face. So what about with our approach, adding the code? And you can see that it's much better. Not only can you tell that it's a baby's face, but you can tell that it's this baby's face, which is a really challenging task. So on the left is the encoder alone, and on the right is from an actual blind retina, so the encoder and the transducer. But the key one really is the encoder alone, because we can team up the encoder with the different transducer. This is just actually the first one that we tried. I just wanted to say something about the standard method. When this first came out, it was just a really exciting thing, the idea that you even make a blind retina respond at all. But there was this limiting factor, the issue of the code, and how to make the cells respond better, produce normal responses, and so this was our contribution. Now I just want to wrap up, and as I was mentioning earlier of course I have a lot of other data if you're interested, but I just wanted to give this sort of basic idea of being able to communicate with the brain in its language, and the potential power of being able to do that. So it's different from the motor prosthetics where you're communicating from the brain to a device. Here we have to communicate from the outside world into the brain and be understood, and be understood by the brain. And then the last thing I wanted to say, really, is to emphasize that the idea generalizes. So the same strategy that we used to find the code for the retina we can also use to find the code for other areas, for example, the auditory system and the motor system, so for treating deafness and for motor disorders. So just the same way that we were able to jump over the damaged circuitry in the retina to get to the retina's output cells, we can jump over the damaged circuitry in the cochlea to get the auditory nerve, or jump over damaged areas in the cortex, in the motor cortex, to bridge the gap produced by a stroke. I just want to end with a simple message that understanding the code is really, really important, and if we can understand the code, the language of the brain, things become possible that didn't seem obviously possible before. Thank you. (Applause)"	我研究大腦如何處理信息。也就是說，它如何從外界採取信息，並將之變換成電能動性的模式，然後它是如何使用這些模式讓你做種種事情 —看得到，聽得到，伸出以觸摸到物體。所以我只是一個基本的科學家，而不是一個發聲學家，但在過去一年半中，我已經開始發生變化，以使用着我們一直在學習的活動模式，來發展義眼裝置，而我今天想要做的便是告訴你這樣的一個例子。這真是我們首次涉足這個。它是一項為治療失明的義眼裝置的發展。 讓我開始談談這個問題。在美國有10萬和在全球有更多的人是盲人，或由於視網膜疾病，黃斑變性等疾病正面臨失明，可以為幫助他們做的事情並不多。是有一些藥物治療，但只在一小部分人的有效。因此大多數患者，他們最有希望重新恢復視力便是通過義眼的裝置。問題是, 目前的義眼的運作不是很好。它們仍然只可以提供非常有限的視野。所以你知道，例如，有了這些設備，患者可以看到基本的東西如明亮的燈光和高對比度的邊緣，幾乎是此已以，一直沒有接近正常視力的可能。 那麼今天我要告訴你的是一個我們一直在研製的設備，我認為它有可能大大有所作為，更要有效得多，我想做的是要向你展示它是如何運作的。好，第一，讓我返回一點，並且告訴你正常的視網膜是如何運作，是以你可以看到我們要試圖解決的問題。這裡是一塊視網膜。有一個圖像，一塊視網膜和一個腦。當你看着東西，像這樣的嬰兒面孔的影像，它進入你眼睛,到達你的視網膜上的前端細胞，這裡的受感光器。然後將會發生的是視網膜電路，中間的部分，會去勞動，執行着它的操作工作，從中提取信息，並將之轉換成代碼的信息。而代碼是在以這些模式的電脈被發送到大腦，所以關鍵是該圖像最終要被轉換成代碼的形式。而當我說代碼，我意思確實是指代碼。例如這種模式的脈搏在這兒實際上表示「寶寶的臉」，所以當大腦得到這種模式的脈搏時，它便知道在這裡是一個嬰兒的臉，而如果它得到了不同的模式，它就知道，在這裡是，比方說，一隻狗，或另一種模式將是一所房子。總之，你明白這是怎麼一回事。 當然，在現實生活中，它是活躍的，它每時每刻都在變化，所以模式的脈搏每時每刻也在改變，因為你看到的世界每時每刻都在變化。可想而知道，這是一個複雜的事情。你的眼睛每毫秒會發出這些脈搏的模式告訴你的大腦你看到的是什麼。當一個人的視網膜得到像黃斑變性的退行性疾病會怎麼？情況會是，前端細胞死亡，光感接收器死亡，隨著時間流逝，所有連接到它們的細胞和線路，它們也會死掉。直到你剩下唯一的這些細胞,這些輸出的細胞，負責發送信號到大腦的細胞，但因為所有的退化使得它們沒有再發出任何信號。它們沒有得到任何輸入的信號，所以大腦不再得到任何視覺的信息 —也就是說，他或她是盲的。 因此，問題的解決方法便是，要建立一個可以模仿前端線路的動作和發送信號到視網膜的輸出細胞的裝置，以至它們可以重回做其正常的工作—發送信號到大腦。這便是我們一直在做的工作，我們的義眼便是會這樣做。它由兩部分組成，我們稱一個為編碼器和一個傳感器。那編碼器就正如我說的：它會模擬前端線路的作用 — 將圖像轉換成視網膜的代碼。然後那傳感器會製造輸出代碼的細胞發送到大腦，結果便是一個義體的視網膜可以產生正常的視網膜輸出。因此，一個完全失明的視網膜，甚至沒有任何前端線路，沒有感光器，現在便可以發送出正常的信號，大腦可以理解的信號。沒有其他的設備已經能夠做到這一點。 好, 我只是想用一兩句話來說說編碼器和它在做什麼，因為它是真正的關鍵部分，它很有趣和酷。我不知道「酷」是否正確的用詞，但你明白我的意思。它在做什麼呢，它在取代視網膜線路，真正視網膜線路的腸道，以一個方程組，一個我們可以實現在一塊芯片上的方程組。那只不過是數學。換句話說，我們不是取代視網膜的組成部分。我們不是像為每個不同類型的細胞正在製造一個小小的設備。我們只不過是摘要視網膜在做什麼的一組方程。因此，在某種程度上，方程是作為碼本的一個排序。一個圖像進來，會通過方程組，走出來的是電脈衝流，就像一個正常視網膜會產生的。 現在讓我實際的演示給你看，我們事實上是可以製造正常的輸出，而且這會有什麼影響。這裡有三種發射的模式。在最上面是從一隻正常的動物，中間的是從一隻被此編碼器傳感設備處理過的盲的動物，而最下面的是一隻被設置標準義眼的盲的動物。最下面的是外面可得到的最新水平的設備，基本上是由光探測器製作，但沒有編碼器。我們所做的就是我們放映日常瑣事的短片—人，嬰兒，公園長椅，你所知道的，經常發生 的事情—我們記錄了這三組動物的視網膜的反應。現在只是在引導你，每個方塊呈現出幾個細胞的放電模式，就像在之前的幻燈片，每一行是一個不同的細胞，而我只是將脈搏弄小一點，薄一點，以便我可以演示給你看到一串長長的數據。 正如你可以看到，從有編碼器傳感處理的盲的動物的發射模式與正常發射模式確實非常密切的相稱 —它並不是完美，但實在是相當不錯 —看看被設置標準義眼的盲的動物，反應真的不怎樣發射。標準的方法，細胞是有發射，但它們不發射出正常的模式, 因為它們到從發射模式的反應呢？沒有正確的代碼。這是有多重要呢？對一個病人視力的能力有什麼潛在影響呢？所以我要給你看看一個回答了這個問題的底線實驗，當然我還有很多其他的數據，如果你有興趣我會很高興地顯示更多。這個實驗被稱為一個重建實驗。我們做的是從這些錄像抽出一刻然後問,究竟那一刻視網膜看到的是什麼？我們可否重建視網膜看到的是從發射模式的反應呢？ 因此，當我們便實驗在用標準的方法,和用我們的編碼器和傳感器。讓我給你看看，我要首先給你看標準的方法。你可以看到它是相當有限，因為發射模式不是正確的代碼，它們可以告訴你的東西是十分有限。你可以看到，是有東西有，但那東西是什麼不是非常清楚，這正如我在開始時所說的,用標準的方法，病人可以看到高對比度的邊緣，但頂多就是這樣。那麼究竟是什麼形象？這是一個嬰兒的面孔。那, 用我們的方法，添加代碼, 會如何？你可以看到它是好得多。你不僅可以看到這是一個嬰兒的面孔，你可以看到，是這一個嬰兒的臉孔，這是一個非常具有挑戰性的任務。在左邊的是單獨的編碼器，在右邊是從實際的盲的視網膜，使用編碼器和傳感器。但真正的重點是單獨在編碼器，因為我們可以與不同的傳感器聯合組隊。 這只是我們試用的第一個。我只想說一些有關標準的方法。當這個結果出來時，它只是一個令人非常興奮的事情，一個使盲人視網膜有回應的概念。但當時是有限制因素，代碼的問題，以及如何使細胞有更好地反應，產生出正常的反應，等等，這便是我們的貢獻。現在，我只是想結尾，如我以前提到,當然我還有很多其他的數據，如果你有興趣知道，但我只是想給你看看這種能夠與大腦思路溝通的基本語言，並能夠做到這一點的潛在力量。因此，這是不同於用義馬達的設置從大腦到設備的通信假肢。我們這個的溝通是來自外部世界，進入腦和被理解，被大腦理解。 最後我想說的一件事，真的，是要強調推廣的想法。因而使我們找到代碼的方法，我們也可以使用視網膜同樣的策略找到在其他地區的代碼，例如，聽覺系統和機動系統，來治療耳聾和運動障礙。因此，以相同的方式，我們能夠飛越過在視網膜損壞了的輸出細胞的線路，我們可以飛越過在耳蝸裡被損壞的聽覺神經的線路，或飛越過大腦皮層下破壞的，運動皮層的地區，架橋渡過中風所產生的影響。 我只是想以一個簡單的信息結束，理解代碼是真的，真的很重要，如果我們能理解代碼，大腦的語言，以往似乎明顯不可能的事情便會成為有可能。謝謝。 (掌聲)
