Talk	en	zh-tw
meron_gribetz_a_glimpse_of_the_future_through_an_augmented_reality_headset	"Today's computers are so amazing that we fail to notice how terrible they really are. I'd like to talk to you today about this problem, and how we can fix it with neuroscience. First, I'd like to take you back to a frosty night in Harlem in 2011 that had a profound impact on me. I was sitting in a dive bar outside of Columbia University, where I studied computer science and neuroscience, and I was having this great conversation with a fellow student about the power of holograms to one day replace computers. And just as we were getting to the best part of the conversation, of course, his phone lights up. And he pulls it towards himself, and he looks down and he starts typing. And then he forces his eyeballs back up to mine and he goes, ""Keep going. I'm with you."" But of course his eyes were glazed over, and the moment was dead. Meanwhile across the bar, I noticed another student holding his phone, this time towards a group. He was swiping through pictures on Instagram, and these kids were laughing hysterically. And that dichotomy between how crappy I was feeling and how happy they were feeling about the same technology, really got me thinking. And the more I thought of it, the more I realized it was clearly not the digital information that was the bad guy here, it was simply the display position that was separating me from my friend and that was binding those kids together. See, they were connected around something, just like our ancestors who evolved their social cognitions telling stories around the campfire. And that's exactly what tools should do, I think. They should extend our bodies. And I think computers today are doing quite the opposite. Whether you're sending an email to your wife or you're composing a symphony or just consoling a friend, you're doing it in pretty much the same way. You're hunched over these rectangles, fumbling with buttons and menus and more rectangles. And I think this is the wrong way, I think we can start using a much more natural machine. We should use machines that bring our work back into the world. We should use machines that use the principles of neuroscience to extend our senses versus going against them. Now it just so happens that I have such a machine here. It's called the Meta 2. Let's try it out. Now in front of me right now, I can see the audience, and I can see my very hands. And in three, two, one, we're going to see an immersive hologram appear, a very realistic hologram appear in front of me, of our very glasses I'm wearing on my head right now. And of course this could be anything that we're shopping for or learning from, and I can use my hands to very nicely kind of move it around with fine control. And I think Iron Man would be proud. We're going to come back to this in just a bit. (Applause) Now if you're anything like me, your mind is already reeling with the possibilities of what we can do with this kind of technology, so let's look at a few. My mom is an architect, so naturally the first thing I imagined was laying out a building in 3D space instead of having to use these 2D floor plans. She's actually touching graphics right now and selecting an interior decor. This was all shot through a GoPro through our very glasses. And this next use case is very personal to me, it's Professor Adam Gazzaley's glass brain project, courtesy of UCSF. As a neuroscience student, I would always fantasize about the ability to learn and memorize these complex brain structures with an actual machine, where I could touch and play with the various brain structures. Now what you're seeing is called augmented reality, but to me, it's part of a much more important story — a story of how we can begin to extend our bodies with digital devices, instead of the other way around. Now ... in the next few years, humanity's going to go through a shift, I think. We're going to start putting an entire layer of digital information on the real world. Just imagine for a moment what this could mean for storytellers, for painters, for brain surgeons, for interior decorators and maybe for all of us here today. And what I think we need to do as a community, is really try and make an effort to imagine how we can create this new reality in a way that extends the human experience, instead of gamifying our reality or cluttering it with digital information. And that's what I'm very passionate about. Now, I want to tell you a little secret. In about five years — this is not the smallest device — in about five years, these are all going to look like strips of glass on our eyes that project holograms. And just like we don't care so much about which phone we buy in terms of the hardware — we buy it for the operating system — as a neuroscientist, I always dreamt of building the iOS of the mind, if you will. And it's very, very important that we get this right, because we might be living inside of these things for at least as long as we've lived with the Windows graphical user interface. And I don't know about you, but living inside of Windows scares me. (Laughter) To isolate the single most intuitive interface out of infinity, we use neuroscience to drive our design guidelines, instead of letting a bunch of designers fight it out in the boardroom. And the principle we all revolve around is what's called the ""Neural Path of Least Resistance."" At every turn, we're connecting the iOS of the brain with our brain on, for the first time, our brain's terms. In other words, we're trying to create a zero learning-curve computer. We're building a system that you've always known how to use. Here are the first three design guidelines that we employ in this brand-new form of user experience. First and foremost, you are the operating system. Traditional file systems are complex and abstract, and they take your brain extra steps to decode them. We're going against the Neural Path of Least Resistance. Meanwhile, in augmented reality, you can of course place your holographic TED panel over here, and your holographic email on the other side of the desk, and your spatial memory evolved just fine to go ahead and retrieve them. You could put your holographic Tesla that you're shopping for — or whatever model my legal team told me to put in right before the show. (Laughter) Perfect. And your brain knows exactly how to get it back. The second interface guideline we call ""touch to see."" What do babies do when they see something that grabs their interest? They try and reach out and touch it. And that's exactly how the natural machine should work as well. Turns out the visual system gets a fundamental boost from a sense we call proprioception — that's the sense of our body parts in space. So by touching our work directly, we're not only going to control it better, we're also going to understand it much more deeply. Hence, touch to see. But it's not enough to experience things ourselves. We're inherently these social primates. And this leads me to our third guideline, the holographic campfire from our first story. Our mirror-neuron subsystem suggests that we can connect with each other and with our work much better if we can see each other's faces and hands in 3D. So if you look at the video behind me, you can see two Meta users playing around with the same hologram, making eye contact, connected around this thing, instead of being distracted by external devices. Let's go ahead and try this again with neuroscience in mind. So again, our favorite interface, the iOS of the mind. I'm going to now take a step further and go ahead and grab this pair of glasses and leave it right here by the desk. I'm now with you, I'm in the moment, we're connecting. My spatial memory kicks in, and I can go ahead and grab it and bring it right back here, reminding me that I am the operating system. And now my proprioception is working, and I can go ahead and explode these glasses into a thousand parts and touch the very sensor that is currently scanning my hand. But it's not enough to see things alone, so in a second, my co-founder Ray is going to make a 3D call — Ray? (Ringing) Hey Ray, how's it going? Guys, I can see this guy in front me in full 3D. And he is photo-realistic. (Applause) Thank you. My mirror-neuron subsystem suggests that this is going to replace phones in not too long. Ray, how's it going? Ray: Great. We're live today. (Applause) MG: Ray, give the crowd a gift of the holographic brain we saw from the video earlier. Guys, this is not only going to change phones, it's also going to change the way we collaborate. Thank you so much. Thanks, Ray. Ray: You're welcome. (Applause) MG: So folks, this is the message that I discovered in that bar in 2011: The future of computers is not locked inside one of these screens. It's right here, inside of us. (Applause) So if there's one idea that I could leave you with here today, it's that the natural machine is not some figment of the future, it's right here in 2016. Which is why all hundred of us at Meta, including the administrative staff, the executives, the designers, the engineers — before TED2017, we're all going to be throwing away our external monitors and replacing them with a truly and profoundly more natural machine. Thank you very much. (Applause) Thank you, appreciate it. Thanks, guys. Chris Anderson: So help me out on one thing, because there've been a few augmented reality demos shown over the last year or so out there. And there's sometimes a debate among technologists about, are we really seeing the real thing on-screen? There's this issue of field of view, that somehow the technology is showing a broader view than you would actually see wearing the glasses. Were we seeing the real deal there? MG: Absolutely the real deal. Not only that, we took extra measures to shoot it with a GoPro through the actual lens in the various videos that you've seen here. We want to try to simulate the experience for the world that we're actually seeing through the glasses, and not cut any corners. CA: Thank you so much for showing us that. MG: Thanks so much, I appreciate that."	現在的電腦實在太神奇了，神奇到讓我們沒注意到它們有多恐怖。今天我想和各位談談這個問題，還有該怎麼用神經科學來解決它。 首先我想把場景拉回2011年一個寒冷的夜晚，紐約的哈林區。當時發生一件對我影響很深的事。當時我坐在一個地下酒吧裡，就在我研究資訊科學和神經科學的哥倫比亞大學外面，我跟一個同學聊得正開心，討論全像投影的力量有一天可能會取代電腦。而在我們聊到正精彩的部分時，不意外地，他的手機亮了起來。他把手機拿近一看，就低頭開始打字，但隨即強迫自己眼珠向上重新看著我，然後他說：「繼續講，我有在聽。」不過想當然爾，他的眼神開始渙散，氣氛就全沒了。 同時酒吧的另一邊，我注意到另一個學生也拿著他的手機，但卻是對面一群人，他正滑著Instagram上的照片，這群孩子邊看邊瘋狂大笑。同樣的科技，讓我感覺如此糟糕，卻讓他們覺得如此開心，這樣的強烈對比讓我陷入沉思。而我想得越深入，就越發覺罪魁禍首顯然不是數位資訊本身，只不過因為顯示的位置不同，在我和我朋友之間是個區隔，在那群孩子面前卻形成一種凝聚力。 看吧，他們正被某些事物聯結在一起，就如同我們的祖先圍繞著營火說故事，藉此發展他們的社會認知。我想這是任何工具應有的功能：讓我們的身體能向外延伸。而我認為當今電腦所做的恰好相反，無論你是在寄信給你太太，寫一首交響曲，或者只是在安慰你的朋友，幾乎都是用一樣的方式。你都是弓著背面對這些方框，笨拙地敲著按鈕和選單，或是其他更多的方框。我認為這是錯誤的做法。我認為我們該開始使用更自然的機器。我們該使用能讓所做的事重新和世界結合的機器。我們使用的機器應該符合神經科學的原則，延伸我們的感官而非限制它們。 現在碰巧我剛好有一台這樣的機器。它叫做米塔二號。讓我們來試試。現在就在我面前，我可以看到觀眾，也可以看到自己的手。然後3, 2, 1,我們即將看到一個擬真的全像投影，一個非常真實的全像投影出現在我面前，透過我正戴在頭上的這副眼鏡。當然出現的也可以是任何我們要買的東西或是學習的教材。而我可以用我的手將它移來移去，精密的控制它。我想鋼鐵人會感到很驕傲的。等等我們再來好好展示。 (掌聲) 如果你們的想法跟我一樣，應該已經為這類科技可能帶來什麼應用而感到暈頭轉向了，所以我們來看看一些範例。 我的母親是位建築師，所以很自然地，我想到的第一件事是建構一棟建築的立體影像，而不必再使用平面的樓層設計圖。她是真的在碰觸那些圖像，並選擇其中一種室內裝飾。這些影片都是用GoPro相機透過這副眼鏡所錄製的。 下一個應用範例是我個人興趣，這是亞當‧葛茲利教授的3D動態大腦影像專案，由加州大學舊金山分校提供。身為一個神經科學的學生，我經常在幻想是否有一台實體的機器，能幫助我們學習並記住複雜的大腦結構，讓我們可以直接碰觸和把玩它們。 現在你看到的是一種叫做擴增實境的技術，但對我來說這只是另一個更重要的故事的其中一部分 －這個故事是關於我們能如何開始透過數位裝置延伸我們的身體，而不是限制它。 那麼，在我看來，人類在未來幾年內將會經歷一次轉變。我們將會開始將一整片的數位資訊直接披在現實世界上。想像一下，這對說故事的人代表什麼，對畫家代表什麼，對腦科醫生代表什麼，對室內裝潢工人代表什麼，甚至對今天所有在座各位代表什麼。而我認為我們需要一起完成的是真正試著努力，想像我們如何用延伸人類經驗的方式創造這種新的現實世界，而不是把它變得像遊戲一樣充滿混亂的數位資訊。這就是我非常熱切想做的事。 跟你們分享一個小秘密。在大概五年內 －它的體積還能更小 －在大概五年內，它們會像覆蓋在眼睛上的一片玻璃片，播放著全像投影。而就像我們並不那麼在乎要買哪一款手機，我是說硬體上 － 我們想買的是作業系統 －身為神經科學家，我總是夢想著可以為心智建立一套iOS － 如果可能的話。但非常、非常重要的是，我們得把它做好，因為我們跟它一起生活的時間可能會和我們跟Windows圖形介面一起生活的時間一樣長。我不知道各位怎麼想，但活在Windows介面裡真是嚇壞我了。 (笑聲) 為了要從無限多種可能性中找出最直覺的介面，我們以神經科學為設計的指導原則，而不是讓一堆設計師在會議室裡吵得不可開交。我們反覆推敲後找出一個準則，稱為「最小神經阻礙路徑」。 我們將這套大腦的iOS隨時隨地和大腦保持連結，並史無前例地按照大腦的模式運作。換句話說，我們正試著創造一台讓你不需要學習如何使用的電腦。我們正在建立一套你永遠知道如何使用的系統。 為了創造這種全新的使用者體驗，我們採用了三個重要的設計指導原則。第一、也是最重要的一個：你就是作業系統。傳統的檔案系統既複雜又抽象，讓你的大腦需要耗費額外的精力進行解碼。這違背了神經最小阻礙原則，同時，在擴增實境中，你顯然可以把全像投影的TED 控制面板放在這裡，然後把全像投影的郵件系統放在桌面的另一邊，你的空間記憶會讓你很自然地找到它們的位置。你可以把你正在選購的特斯拉全像投影放在這 －或任何我的法律團隊要我在演講前放在這裡的款式。 (笑聲) 太完美了。而且你的大腦完全知道如何去哪裡找它。 第二個界面指導原則，我們稱為「接觸可視」。嬰兒看到引起他們興趣的東西時會做什麼？他會試著伸手去摸它。自然的機器也應該這樣運作才對。事實說明視覺系統有個很基本的推動力來自我們稱為本體知覺的感官 －也就是身體各部位在空間裡的感覺。所以透過直接觸摸正在處理的東西，我們不僅能做更好的控制，還能對它有更深入許多的瞭解。這也就是「接觸可視」。 但只有我們自己體驗這些東西是不夠的。我們天生就是社會型的靈長類動物。這就帶出了我們的第三個指導原則，如同我們早先故事的營火，但卻是全像投影的版本。 我們的鏡像神經元系統使得我們在能看到彼此的臉和手的情況下，可以和對方或者合作事項產生更好的連結。所以在我後面的這段錄影裡，你可以看到兩個米塔使用者同時使用同一個全像投影，讓他們眼神互相接觸，彼此密切結合，而不是因外在裝置而分心。 讓我們把神經科學放在心裡，再試一次這個東西。一樣地，我們最愛的介面，心智的iOS。這次我要更進一步開始抓住這副眼鏡然後把它放在桌子上。而此刻我和你們在一起，彼此聯結。我的空間記憶發揮作用，讓我能去抓住它並把它拉回來這裡，提醒著我我就是作業系統。現在我的本體知覺發揮作用，我可以將這副眼鏡拆成一千個零件，並碰觸這個現在正在掃描我的手的感應器。 但獨自看到這些東西是不夠的，所以很快地，我的共同創辦人 － 雷會打一通3D電話給我 －雷? (鈴聲) 嗨，雷，你好嗎？各位，我可以看到他在面前，完全立體。而且是真實的影像。 (掌聲) 謝謝你們。 我的鏡像神經元系統認為這即將取代電話，而且不會太久。雷，你好嗎？ 雷：好得很。我們正直播呢。 (掌聲) MG：雷，為觀眾們送上禮物吧，讓他們看看稍早影片裡那個全像投影大腦。各位，這帶來的改變不僅僅是電話，而是整個我們彼此合作的方式。 謝謝你們。 謝謝，雷。 雷：不客氣。 (掌聲) MG：朋友們，這就是2011年我在那間酒吧得到的訊息：電腦的未來絕對不是藏在那些螢幕後面，而是在這裡，藏在我們身體裡。 (掌聲) 所以如果今天能讓各位帶走一個想法，那就是自然機器並不是未來虛構的東西，它就在2016年的這裡。這也是為什麼我們米塔上百名員工。包含行政人員、管理層、設計師、工程師 －在2017年的TED大會之前，我們要摒棄所有的外接螢幕，然後用真正更加自然的機器取代它們。非常感謝各位。 (掌聲) 謝謝，由衷感謝。 謝謝你們。克里斯·安德森：請解答我的一個小疑惑， 過去一年甚至更久之前就出現過許多擴增實境的展示，科技人之間有時會互相爭論「我們是否真的在螢幕上看到真實物件？」這個問題。這是這個領域存在的一個議題，就是這個科技似乎讓我們在戴上眼鏡時顯示的東西比實際看到的還多。那我們看到的東西是否真實呢？MG：絕對是真實的。 不僅如此，我們還額外測試，利用GoPro相機透過真實鏡頭拍攝之前放映的那幾段影片。我們想藉由透過這個眼鏡所看到的一切模擬這個世界的體驗，不漏掉任何一個鏡頭。CA：感謝你與我們分享這些。 MG：非常感謝。
